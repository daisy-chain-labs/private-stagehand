var __defProp = Object.defineProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};

// src/node.ts
import { AsyncLocalStorage } from "async_hooks";
import * as path from "path";
import * as fs from "fs/promises";

// src/isomorph.ts
var DefaultAsyncLocalStorage = class {
  constructor() {
  }
  enterWith(_) {
  }
  run(_, callback) {
    return callback();
  }
  getStore() {
    return void 0;
  }
};
var iso = {
  getRepoInfo: async (_settings) => void 0,
  getPastNAncestors: async () => [],
  getEnv: (_name) => void 0,
  getCallerLocation: () => void 0,
  newAsyncLocalStorage: () => new DefaultAsyncLocalStorage(),
  processOn: (_0, _1) => {
  }
};
var isomorph_default = iso;

// src/gitutil.ts
import { simpleGit } from "simple-git";
var COMMON_BASE_BRANCHES = ["main", "master", "develop"];
async function currentRepo() {
  try {
    const git = simpleGit();
    if (await git.checkIsRepo()) {
      return git;
    } else {
      return null;
    }
  } catch (e) {
    return null;
  }
}
var _baseBranch = null;
async function getBaseBranch(remote = void 0) {
  if (_baseBranch === null) {
    const git = await currentRepo();
    if (git === null) {
      throw new Error("Not in a git repo");
    }
    const remoteName = remote ?? (await git.getRemotes())[0]?.name;
    if (!remoteName) {
      throw new Error("No remote found");
    }
    let branch = null;
    const repoBranches = new Set((await git.branchLocal()).all);
    const matchingBaseBranches = COMMON_BASE_BRANCHES.filter(
      (b) => repoBranches.has(b)
    );
    if (matchingBaseBranches.length === 1) {
      branch = matchingBaseBranches[0];
    } else {
      try {
        const remoteInfo = await git.remote(["show", remoteName]);
        if (!remoteInfo) {
          throw new Error(`Could not find remote ${remoteName}`);
        }
        const match = remoteInfo.match(/\s*HEAD branch:\s*(.*)$/m);
        if (!match) {
          throw new Error(`Could not find HEAD branch in remote ${remoteName}`);
        }
        branch = match[1];
      } catch {
        branch = "main";
      }
    }
    _baseBranch = { remote: remoteName, branch };
  }
  return _baseBranch;
}
async function getBaseBranchAncestor(remote = void 0) {
  const git = await currentRepo();
  if (git === null) {
    throw new Error("Not in a git repo");
  }
  const { remote: remoteName, branch: baseBranch } = await getBaseBranch(remote);
  const isDirty = (await git.diffSummary()).files.length > 0;
  const head = isDirty ? "HEAD" : "HEAD^";
  try {
    const ancestor = await git.raw([
      "merge-base",
      head,
      `${remoteName}/${baseBranch}`
    ]);
    return ancestor.trim();
  } catch (e) {
    return void 0;
  }
}
async function getPastNAncestors(n = 10, remote = void 0) {
  const git = await currentRepo();
  if (git === null) {
    return [];
  }
  let ancestor = void 0;
  try {
    ancestor = await getBaseBranchAncestor(remote);
  } catch (e) {
    console.warn(
      "Skipping git metadata. This is likely because the repository has not been published to a remote yet.",
      `${e}`
    );
  }
  if (!ancestor) {
    return [];
  }
  const commits = await git.log({ from: ancestor, to: "HEAD" });
  return commits.all.map((c) => c.hash);
}
async function attempt(fn) {
  try {
    return await fn();
  } catch (e) {
    return void 0;
  }
}
function truncateToByteLimit(s, byteLimit = 65536) {
  const encoded = new TextEncoder().encode(s);
  if (encoded.length <= byteLimit) {
    return s;
  }
  const truncated = encoded.subarray(0, byteLimit);
  return new TextDecoder().decode(truncated);
}
async function getRepoInfo(settings) {
  if (settings && settings.collect === "none") {
    return void 0;
  }
  const repo = await repoInfo();
  if (!repo || !settings || settings.collect === "all") {
    return repo;
  }
  let sanitized = {};
  settings.fields?.forEach((field) => {
    sanitized = { ...sanitized, [field]: repo[field] };
  });
  return sanitized;
}
async function repoInfo() {
  const git = await currentRepo();
  if (git === null) {
    return void 0;
  }
  let commit = void 0;
  let commit_message = void 0;
  let commit_time = void 0;
  let author_name = void 0;
  let author_email = void 0;
  let tag = void 0;
  let branch = void 0;
  let git_diff = void 0;
  const dirty = (await git.diffSummary()).files.length > 0;
  commit = await attempt(async () => await git.revparse(["HEAD"]));
  commit_message = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%B"])).trim()
  );
  commit_time = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%cI"])).trim()
  );
  author_name = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%aN"])).trim()
  );
  author_email = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%aE"])).trim()
  );
  tag = await attempt(
    async () => (await git.raw(["describe", "--tags", "--exact-match", "--always"])).trim()
  );
  branch = await attempt(
    async () => (await git.raw(["rev-parse", "--abbrev-ref", "HEAD"])).trim()
  );
  if (dirty) {
    git_diff = await attempt(
      async () => truncateToByteLimit(await git.raw(["diff", "HEAD"]))
    );
  }
  return {
    commit,
    branch,
    tag,
    dirty,
    author_name,
    author_email,
    commit_message,
    commit_time,
    git_diff
  };
}

// src/stackutil.ts
function getStackTrace() {
  const trace = new Error().stack;
  if (trace === void 0) {
    return [];
  }
  const traceLines = trace.split("\n");
  const out = [];
  const stackFrameRegex = /at(.*)\((.*):(\d+):(\d+)\)/;
  for (const traceLine of traceLines.slice(1)) {
    const matches = traceLine.match(stackFrameRegex);
    if (matches === null || matches.length !== 5) {
      continue;
    }
    const entry = {
      functionName: matches[1].trim(),
      fileName: matches[2],
      lineNo: parseInt(matches[3])
    };
    if (!isNaN(entry.lineNo)) {
      out.push(entry);
    }
  }
  return out;
}
function getCallerLocation() {
  let thisDir = void 0;
  const entries = getStackTrace();
  for (const frame of entries) {
    if (thisDir === void 0) {
      thisDir = isomorph_default.pathDirname?.(frame.fileName);
    }
    if (isomorph_default.pathDirname?.(frame.fileName) !== thisDir) {
      return {
        caller_functionname: frame.functionName,
        caller_filename: frame.fileName,
        caller_lineno: frame.lineNo
      };
    }
  }
  return void 0;
}

// src/logger.ts
import { v4 as uuidv4 } from "uuid";
import {
  IS_MERGE_FIELD,
  TRANSACTION_ID_FIELD,
  mergeDicts,
  mergeRowBatch,
  VALID_SOURCES,
  AUDIT_SOURCE_FIELD,
  AUDIT_METADATA_FIELD,
  mergeGitMetadataSettings,
  DEFAULT_IS_LEGACY_DATASET,
  ensureDatasetRecord,
  makeLegacyEvent,
  constructJsonArray,
  SpanTypeAttribute,
  batchItems,
  SpanComponentsV3,
  SpanObjectTypeV3,
  spanObjectTypeV3ToString,
  _urljoin
} from "@braintrust/core";
import {
  BRAINTRUST_PARAMS,
  promptDataSchema,
  promptSchema,
  toolsSchema,
  gitMetadataSettingsSchema,
  BRAINTRUST_ATTACHMENT
} from "@braintrust/core/typespecs";

// src/util.ts
var GLOBAL_PROJECT = "Global";
function runCatchFinally(f, catchF, finallyF) {
  let runSyncCleanup = true;
  try {
    const ret = f();
    if (ret instanceof Promise) {
      runSyncCleanup = false;
      return ret.catch(catchF).finally(finallyF);
    } else {
      return ret;
    }
  } catch (e) {
    return catchF(e);
  } finally {
    if (runSyncCleanup) {
      finallyF();
    }
  }
}
function getCurrentUnixTimestamp() {
  return (/* @__PURE__ */ new Date()).getTime() / 1e3;
}
function isEmpty(a) {
  return a === void 0 || a === null;
}
var LazyValue = class {
  callable;
  value = {
    hasComputed: false
  };
  constructor(callable) {
    this.callable = callable;
  }
  get() {
    if (this.value.hasComputed) {
      return this.value.val;
    }
    this.value = { hasComputed: true, val: this.callable() };
    return this.value.val;
  }
  get hasComputed() {
    return this.value.hasComputed;
  }
};

// src/logger.ts
import Mustache from "mustache";
import { z as z2, ZodError } from "zod";

// src/functions/stream.ts
import {
  callEventSchema,
  sseConsoleEventDataSchema,
  sseProgressEventDataSchema
} from "@braintrust/core/typespecs";
import {
  createParser
} from "eventsource-parser";
import { z } from "zod";
var braintrustStreamChunkSchema = z.union([
  z.object({
    type: z.literal("text_delta"),
    data: z.string()
  }),
  z.object({
    type: z.literal("json_delta"),
    data: z.string()
  }),
  z.object({
    type: z.literal("error"),
    data: z.string()
  }),
  z.object({
    type: z.literal("console"),
    data: sseConsoleEventDataSchema
  }),
  z.object({
    type: z.literal("progress"),
    data: sseProgressEventDataSchema
  }),
  z.object({
    type: z.literal("start"),
    data: z.string()
  }),
  z.object({
    type: z.literal("done"),
    data: z.string()
  })
]);
var BraintrustStream = class _BraintrustStream {
  stream;
  memoizedFinalValue;
  constructor(baseStream) {
    this.stream = baseStream.pipeThrough(btStreamParser());
  }
  /**
   * Copy the stream. This returns a new stream that shares the same underlying
   * stream (via `tee`). Since streams are consumed in Javascript, use `copy()` if you
   * need to use the stream multiple times.
   *
   * @returns A new stream that you can independently consume.
   */
  copy() {
    const [newStream, copyStream] = this.stream.tee();
    this.stream = copyStream;
    return new _BraintrustStream(newStream);
  }
  /**
   * Get the underlying ReadableStream.
   *
   * @returns The underlying ReadableStream<BraintrustStreamChunk>.
   */
  toReadableStream() {
    return this.stream;
  }
  /**
   * Returns an async iterator for the BraintrustStream.
   * This allows for easy consumption of the stream using a for-await...of loop.
   *
   * @returns An async iterator that yields BraintrustStreamChunk objects.
   */
  [Symbol.asyncIterator]() {
    const reader = this.stream.getReader();
    return {
      async next() {
        const { done, value } = await reader.read();
        if (done) {
          reader.releaseLock();
          return { done: true, value: void 0 };
        }
        return { done: false, value };
      },
      async return() {
        reader.releaseLock();
        return { done: true, value: void 0 };
      },
      async throw(error2) {
        reader.releaseLock();
        throw error2;
      }
    };
  }
  /**
   * Get the final value of the stream. The final value is the concatenation of all
   * the chunks in the stream, deserialized into a string or JSON object, depending on
   * the value's type.
   *
   * This function returns a promise that resolves when the stream is closed, and
   * contains the final value. Multiple calls to `finalValue()` will return the same
   * promise, so it is safe to call this multiple times.
   *
   * This function consumes the stream, so if you need to use the stream multiple
   * times, you should call `copy()` first.
   *
   * @returns A promise that resolves with the final value of the stream or `undefined` if the stream is empty.
   */
  finalValue() {
    if (this.memoizedFinalValue) {
      return this.memoizedFinalValue;
    }
    this.memoizedFinalValue = new Promise((resolve, reject2) => {
      this.stream.pipeThrough(createFinalValuePassThroughStream(resolve, reject2)).pipeTo(devNullWritableStream());
    });
    return this.memoizedFinalValue;
  }
};
function btStreamParser() {
  const decoder = new TextDecoder();
  let parser;
  return new TransformStream({
    async start(controller) {
      parser = createParser((event) => {
        if (event.type === "reconnect-interval") {
          return;
        }
        const parsed = callEventSchema.safeParse(event);
        if (!parsed.success) {
          throw new Error(`Failed to parse event: ${parsed.error}`);
        }
        switch (parsed.data.event) {
          case "text_delta":
            controller.enqueue({
              type: "text_delta",
              data: JSON.parse(event.data)
            });
            break;
          case "json_delta":
            controller.enqueue({
              type: "json_delta",
              data: event.data
            });
            break;
          case "error":
            controller.enqueue({
              type: "error",
              data: JSON.parse(event.data)
            });
            break;
          case "progress":
            controller.enqueue({
              type: "progress",
              data: sseProgressEventDataSchema.parse(JSON.parse(event.data))
            });
            break;
          case "console":
            controller.enqueue({
              type: "console",
              data: sseConsoleEventDataSchema.parse(JSON.parse(event.data))
            });
            break;
          case "start":
            controller.enqueue({
              type: "start",
              data: ""
            });
            break;
          case "done":
            controller.enqueue({
              type: "done",
              data: ""
            });
            break;
          default: {
            const _event = parsed.data;
            throw new Error(`Unknown event type ${JSON.stringify(_event)}`);
          }
        }
      });
    },
    async transform(chunk, controller) {
      if (chunk instanceof Uint8Array) {
        parser.feed(decoder.decode(chunk));
      } else if (typeof chunk === "string") {
        parser.feed(chunk);
      } else {
        controller.enqueue(chunk);
      }
    },
    async flush(controller) {
      controller.terminate();
    }
  });
}
function createFinalValuePassThroughStream(onFinal, onError) {
  const decoder = new TextDecoder();
  const textChunks = [];
  const jsonChunks = [];
  const transformStream = new TransformStream({
    transform(chunk, controller) {
      if (typeof chunk === "string") {
        textChunks.push(chunk);
        controller.enqueue({
          type: "text_delta",
          data: chunk
        });
      } else if (chunk instanceof Uint8Array) {
        textChunks.push(decoder.decode(chunk));
        controller.enqueue({
          type: "text_delta",
          data: decoder.decode(chunk)
        });
      } else if (braintrustStreamChunkSchema.safeParse(chunk).success) {
        const chunkType = chunk.type;
        switch (chunkType) {
          case "text_delta":
            textChunks.push(chunk.data);
            break;
          case "json_delta":
            jsonChunks.push(chunk.data);
            break;
          case "error":
            onError(chunk.data);
            break;
          case "progress":
          case "start":
          case "done":
          case "console":
            break;
          default:
            const _type = chunkType;
            throw new Error(`Unknown chunk type ${_type}`);
        }
        controller.enqueue(chunk);
      } else {
        throw new Error(`Unknown chunk type ${chunk}`);
      }
    },
    flush(controller) {
      if (jsonChunks.length > 0) {
        onFinal(JSON.parse(jsonChunks.join("")));
      } else if (textChunks.length > 0) {
        onFinal(textChunks.join(""));
      } else {
        onFinal(void 0);
      }
      controller.terminate();
    }
  });
  return transformStream;
}
function devNullWritableStream() {
  return new WritableStream({
    write(chunk) {
    },
    close() {
    },
    abort(reason) {
    },
    start(controller) {
    }
  });
}

// src/logger.ts
import { waitUntil } from "@vercel/functions";
var NoopSpan = class {
  id;
  kind = "span";
  constructor() {
    this.id = "";
  }
  log(_) {
  }
  logFeedback(_event) {
  }
  traced(callback, _1) {
    return callback(this);
  }
  startSpan(_1) {
    return this;
  }
  end(args) {
    return args?.endTime ?? getCurrentUnixTimestamp();
  }
  async export() {
    return "";
  }
  async permalink() {
    return "";
  }
  async flush() {
  }
  close(args) {
    return this.end(args);
  }
  setAttributes(_args) {
  }
};
var NOOP_SPAN = new NoopSpan();
var loginSchema = z2.strictObject({
  appUrl: z2.string(),
  appPublicUrl: z2.string(),
  orgName: z2.string(),
  apiUrl: z2.string(),
  proxyUrl: z2.string(),
  loginToken: z2.string(),
  orgId: z2.string().nullish(),
  gitMetadataSettings: gitMetadataSettingsSchema.nullish()
});
var stateNonce = 0;
var BraintrustState = class _BraintrustState {
  constructor(loginParams) {
    this.loginParams = loginParams;
    this.id = `${(/* @__PURE__ */ new Date()).toLocaleString()}-${stateNonce++}`;
    this.currentExperiment = void 0;
    this.currentLogger = void 0;
    this.currentSpan = isomorph_default.newAsyncLocalStorage();
    if (loginParams.fetch) {
      this.fetch = loginParams.fetch;
    }
    const defaultGetLogConn = async () => {
      await this.login({});
      return this.apiConn();
    };
    this._bgLogger = new BackgroundLogger(
      new LazyValue(defaultGetLogConn),
      loginParams
    );
    this.resetLoginInfo();
  }
  id;
  currentExperiment;
  // Note: the value of IsAsyncFlush doesn't really matter here, since we
  // (safely) dynamically cast it whenever retrieving the logger.
  currentLogger;
  currentSpan;
  // Any time we re-log in, we directly update the apiConn inside the logger.
  // This is preferable to replacing the whole logger, which would create the
  // possibility of multiple loggers floating around, which may not log in a
  // deterministic order.
  _bgLogger;
  appUrl = null;
  appPublicUrl = null;
  loginToken = null;
  orgId = null;
  orgName = null;
  apiUrl = null;
  proxyUrl = null;
  loggedIn = false;
  gitMetadataSettings;
  fetch = globalThis.fetch;
  _appConn = null;
  _apiConn = null;
  _proxyConn = null;
  resetLoginInfo() {
    this.appUrl = null;
    this.appPublicUrl = null;
    this.loginToken = null;
    this.orgId = null;
    this.orgName = null;
    this.apiUrl = null;
    this.proxyUrl = null;
    this.loggedIn = false;
    this.gitMetadataSettings = void 0;
    this._appConn = null;
    this._apiConn = null;
    this._proxyConn = null;
  }
  copyLoginInfo(other) {
    this.appUrl = other.appUrl;
    this.appPublicUrl = other.appPublicUrl;
    this.loginToken = other.loginToken;
    this.orgId = other.orgId;
    this.orgName = other.orgName;
    this.apiUrl = other.apiUrl;
    this.proxyUrl = other.proxyUrl;
    this.loggedIn = other.loggedIn;
    this.gitMetadataSettings = other.gitMetadataSettings;
    this._appConn = other._appConn;
    this._apiConn = other._apiConn;
    this._proxyConn = other._proxyConn;
  }
  serialize() {
    if (!this.loggedIn) {
      throw new Error(
        "Cannot serialize BraintrustState without being logged in"
      );
    }
    if (!this.appUrl || !this.appPublicUrl || !this.apiUrl || !this.proxyUrl || !this.orgName || !this.loginToken || !this.loggedIn) {
      throw new Error(
        "Cannot serialize BraintrustState without all login attributes"
      );
    }
    return {
      appUrl: this.appUrl,
      appPublicUrl: this.appPublicUrl,
      loginToken: this.loginToken,
      orgId: this.orgId,
      orgName: this.orgName,
      apiUrl: this.apiUrl,
      proxyUrl: this.proxyUrl,
      gitMetadataSettings: this.gitMetadataSettings
    };
  }
  static deserialize(serialized, opts) {
    const serializedParsed = loginSchema.safeParse(serialized);
    if (!serializedParsed.success) {
      throw new Error(
        `Cannot deserialize BraintrustState: ${serializedParsed.error.errors}`
      );
    }
    const state = new _BraintrustState({ ...opts });
    for (const key of Object.keys(loginSchema.shape)) {
      state[key] = serializedParsed.data[key];
    }
    if (!state.loginToken) {
      throw new Error(
        "Cannot deserialize BraintrustState without a login token"
      );
    }
    state.apiConn().set_token(state.loginToken);
    state.apiConn().make_long_lived();
    state.appConn().set_token(state.loginToken);
    if (state.proxyUrl) {
      state.proxyConn().make_long_lived();
      state.proxyConn().set_token(state.loginToken);
    }
    state.loggedIn = true;
    state.loginReplaceApiConn(state.apiConn());
    return state;
  }
  setFetch(fetch2) {
    this.loginParams.fetch = fetch2;
    this.fetch = fetch2;
    this._apiConn?.setFetch(fetch2);
    this._appConn?.setFetch(fetch2);
  }
  async login(loginParams) {
    if (this.apiUrl && !loginParams.forceLogin) {
      return;
    }
    const newState = await loginToState({
      ...this.loginParams,
      ...Object.fromEntries(
        Object.entries(loginParams).filter(([k, v]) => !isEmpty(v))
      )
    });
    this.copyLoginInfo(newState);
  }
  appConn() {
    if (!this._appConn) {
      if (!this.appUrl) {
        throw new Error("Must initialize appUrl before requesting appConn");
      }
      this._appConn = new HTTPConnection(this.appUrl, this.fetch);
    }
    return this._appConn;
  }
  apiConn() {
    if (!this._apiConn) {
      if (!this.apiUrl) {
        throw new Error("Must initialize apiUrl before requesting apiConn");
      }
      this._apiConn = new HTTPConnection(this.apiUrl, this.fetch);
    }
    return this._apiConn;
  }
  proxyConn() {
    if (!this.proxyUrl) {
      return this.apiConn();
    }
    if (!this._proxyConn) {
      if (!this.proxyUrl) {
        throw new Error("Must initialize proxyUrl before requesting proxyConn");
      }
      this._proxyConn = new HTTPConnection(this.proxyUrl, this.fetch);
    }
    return this._proxyConn;
  }
  bgLogger() {
    return this._bgLogger;
  }
  // Should only be called by the login function.
  loginReplaceApiConn(apiConn) {
    this._bgLogger.internalReplaceApiConn(apiConn);
  }
};
var _globalState;
function _internalSetInitialState() {
  if (_globalState) {
    throw new Error("Cannot set initial state more than once");
  }
  _globalState = globalThis.__inherited_braintrust_state || new BraintrustState({
    /*empty login options*/
  });
}
var _internalGetGlobalState = () => _globalState;
var FailedHTTPResponse = class extends Error {
  status;
  text;
  data;
  constructor(status, text, data = null) {
    super(`${status}: ${text}`);
    this.status = status;
    this.text = text;
    this.data = data;
  }
};
async function checkResponse(resp) {
  if (resp.ok) {
    return resp;
  } else {
    throw new FailedHTTPResponse(
      resp.status,
      resp.statusText,
      await resp.text()
    );
  }
}
var HTTPConnection = class _HTTPConnection {
  base_url;
  token;
  headers;
  fetch;
  constructor(base_url, fetch2) {
    this.base_url = base_url;
    this.token = null;
    this.headers = {};
    this._reset();
    this.fetch = fetch2;
  }
  setFetch(fetch2) {
    this.fetch = fetch2;
  }
  async ping() {
    try {
      const resp = await this.get("ping");
      return resp.status === 200;
    } catch (e) {
      return false;
    }
  }
  make_long_lived() {
    this._reset();
  }
  static sanitize_token(token) {
    return token.trim();
  }
  set_token(token) {
    token = _HTTPConnection.sanitize_token(token);
    this.token = token;
    this._reset();
  }
  // As far as I can tell, you cannot set the retry/backoff factor here
  _reset() {
    this.headers = {};
    if (this.token) {
      this.headers["Authorization"] = `Bearer ${this.token}`;
    }
  }
  async get(path3, params = void 0, config) {
    const { headers, ...rest } = config || {};
    const url = new URL(_urljoin(this.base_url, path3));
    url.search = new URLSearchParams(
      params ? Object.entries(params).filter(([_, v]) => v !== void 0).flatMap(
        ([k, v]) => v !== void 0 ? typeof v === "string" ? [[k, v]] : v.map((x) => [k, x]) : []
      ) : []
    ).toString();
    const this_fetch = this.fetch;
    const this_headers = this.headers;
    return await checkResponse(
      // Using toString() here makes it work with isomorphic fetch
      await this_fetch(url.toString(), {
        headers: {
          Accept: "application/json",
          ...this_headers,
          ...headers
        },
        keepalive: true,
        ...rest
      })
    );
  }
  async post(path3, params, config) {
    const { headers, ...rest } = config || {};
    const this_fetch = this.fetch;
    const this_base_url = this.base_url;
    const this_headers = this.headers;
    return await checkResponse(
      await this_fetch(_urljoin(this_base_url, path3), {
        method: "POST",
        headers: {
          Accept: "application/json",
          "Content-Type": "application/json",
          ...this_headers,
          ...headers
        },
        body: typeof params === "string" ? params : params ? JSON.stringify(params) : void 0,
        keepalive: true,
        ...rest
      })
    );
  }
  async get_json(object_type, args = void 0, retries = 0) {
    const tries = retries + 1;
    for (let i = 0; i < tries; i++) {
      try {
        const resp = await this.get(`${object_type}`, args);
        return await resp.json();
      } catch (e) {
        if (i < tries - 1) {
          console.log(
            `Retrying API request ${object_type} ${JSON.stringify(args)} ${e.status} ${e.text}`
          );
          continue;
        }
        throw e;
      }
    }
  }
  async post_json(object_type, args = void 0) {
    const resp = await this.post(`${object_type}`, args, {
      headers: { "Content-Type": "application/json" }
    });
    return await resp.json();
  }
};
var Attachment = class {
  /**
   * The object that replaces this `Attachment` at upload time.
   */
  reference;
  uploader;
  _data;
  state;
  // For debug logging only.
  dataDebugString;
  /**
   * Construct an attachment.
   *
   * @param data A string representing the path of the file on disk, or a
   * `Blob`/`ArrayBuffer` with the file's contents. The caller is responsible
   * for ensuring the file/blob/buffer is not modified until upload is complete.
   *
   * @param filename The desired name of the file in Braintrust after uploading.
   * This parameter is for visualization purposes only and has no effect on
   * attachment storage.
   *
   * @param contentType The MIME type of the file.
   *
   * @param state (Optional) For internal use.
   */
  constructor({ data, filename, contentType, state }) {
    this.reference = {
      type: BRAINTRUST_ATTACHMENT,
      filename,
      content_type: contentType,
      key: newId()
    };
    this.state = state;
    this.dataDebugString = typeof data === "string" ? data : "<in-memory data>";
    this._data = this.initData(data);
    this.uploader = this.initUploader();
  }
  /**
   * On first access, (1) reads the attachment from disk if needed, (2)
   * authenticates with the data plane to request a signed URL, (3) uploads to
   * object store, and (4) updates the attachment.
   *
   * @returns The attachment status.
   */
  async upload() {
    return await this.uploader.get();
  }
  /**
   * The attachment contents. This is a lazy value that will read the attachment contents from disk or memory on first access.
   */
  async data() {
    return this._data.get();
  }
  /**
   * A human-readable description for logging and debugging.
   *
   * @returns The debug object. The return type is not stable and may change in
   * a future release.
   */
  debugInfo() {
    return {
      inputData: this.dataDebugString,
      reference: this.reference,
      state: this.state
    };
  }
  initUploader() {
    const doUpload = async (conn, orgId) => {
      const requestParams = {
        key: this.reference.key,
        filename: this.reference.filename,
        content_type: this.reference.content_type,
        org_id: orgId
      };
      const [metadataPromiseResult, dataPromiseResult] = await Promise.allSettled([
        conn.post("/attachment", requestParams),
        this._data.get()
      ]);
      if (metadataPromiseResult.status === "rejected") {
        const errorStr = JSON.stringify(metadataPromiseResult.reason);
        throw new Error(
          `Failed to request signed URL from API server: ${errorStr}`
        );
      }
      if (dataPromiseResult.status === "rejected") {
        const errorStr = JSON.stringify(dataPromiseResult.reason);
        throw new Error(`Failed to read file: ${errorStr}`);
      }
      const metadataResponse = metadataPromiseResult.value;
      const data = dataPromiseResult.value;
      let signedUrl;
      let headers;
      try {
        ({ signedUrl, headers } = z2.object({
          signedUrl: z2.string().url(),
          headers: z2.record(z2.string())
        }).parse(await metadataResponse.json()));
      } catch (error2) {
        if (error2 instanceof ZodError) {
          const errorStr = JSON.stringify(error2.flatten());
          throw new Error(`Invalid response from API server: ${errorStr}`);
        }
        throw error2;
      }
      let objectStoreResponse;
      try {
        objectStoreResponse = await checkResponse(
          await fetch(signedUrl, {
            method: "PUT",
            headers,
            body: data
          })
        );
      } catch (error2) {
        if (error2 instanceof FailedHTTPResponse) {
          throw new Error(
            `Failed to upload attachment to object store: ${error2.status} ${error2.text} ${error2.data}`
          );
        }
        throw error2;
      }
      return { signedUrl, metadataResponse, objectStoreResponse };
    };
    const errorWrapper = async () => {
      const status = { upload_status: "done" };
      const state = this.state ?? _globalState;
      await state.login({});
      const conn = state.apiConn();
      const orgId = state.orgId ?? "";
      try {
        await doUpload(conn, orgId);
      } catch (error2) {
        status.upload_status = "error";
        status.error_message = error2 instanceof Error ? error2.message : JSON.stringify(error2);
      }
      const requestParams = {
        key: this.reference.key,
        org_id: orgId,
        status
      };
      const statusResponse = await conn.post(
        "/attachment/status",
        requestParams
      );
      if (!statusResponse.ok) {
        const errorStr = JSON.stringify(statusResponse);
        throw new Error(`Couldn't log attachment status: ${errorStr}`);
      }
      return status;
    };
    return new LazyValue(errorWrapper);
  }
  initData(data) {
    if (typeof data === "string") {
      const readFile2 = isomorph_default.readFile;
      if (!readFile2) {
        throw new Error(
          `This platform does not support reading the filesystem. Construct the Attachment
with a Blob/ArrayBuffer, or run the program on Node.js.`
        );
      }
      return new LazyValue(async () => new Blob([await readFile2(data)]));
    } else {
      return new LazyValue(async () => new Blob([data]));
    }
  }
};
function logFeedbackImpl(state, parentObjectType, parentObjectId, {
  id,
  expected,
  scores,
  metadata: inputMetadata,
  tags,
  comment,
  source: inputSource
}) {
  const source = inputSource ?? "external";
  if (!VALID_SOURCES.includes(source)) {
    throw new Error(`source must be one of ${VALID_SOURCES}`);
  }
  if (isEmpty(scores) && isEmpty(expected) && isEmpty(tags) && isEmpty(comment)) {
    throw new Error(
      "At least one of scores, expected, tags, or comment must be specified"
    );
  }
  const validatedEvent = validateAndSanitizeExperimentLogPartialArgs({
    scores,
    metadata: inputMetadata,
    expected,
    tags
  });
  let { metadata, ...updateEvent } = deepCopyEvent(validatedEvent);
  updateEvent = Object.fromEntries(
    Object.entries(updateEvent).filter(([_, v]) => !isEmpty(v))
  );
  const parentIds = async () => new SpanComponentsV3({
    object_type: parentObjectType,
    object_id: await parentObjectId.get()
  }).objectIdFields();
  if (Object.keys(updateEvent).length > 0) {
    const record = new LazyValue(async () => {
      return {
        id,
        ...updateEvent,
        ...await parentIds(),
        [AUDIT_SOURCE_FIELD]: source,
        [AUDIT_METADATA_FIELD]: metadata,
        [IS_MERGE_FIELD]: true
      };
    });
    state.bgLogger().log([record]);
  }
  if (!isEmpty(comment)) {
    const record = new LazyValue(async () => {
      return {
        id: uuidv4(),
        created: (/* @__PURE__ */ new Date()).toISOString(),
        origin: {
          // NOTE: We do not know (or care?) what the transaction id of the row that
          // we're commenting on is here, so we omit it.
          id
        },
        comment: {
          text: comment
        },
        ...await parentIds(),
        [AUDIT_SOURCE_FIELD]: source,
        [AUDIT_METADATA_FIELD]: metadata
      };
    });
    state.bgLogger().log([record]);
  }
}
function updateSpanImpl({
  state,
  parentObjectType,
  parentObjectId,
  id,
  event
}) {
  const updateEvent = deepCopyEvent(
    validateAndSanitizeExperimentLogPartialArgs({
      id,
      ...event
    })
  );
  const parentIds = async () => new SpanComponentsV3({
    object_type: parentObjectType,
    object_id: await parentObjectId.get()
  }).objectIdFields();
  const record = new LazyValue(async () => ({
    id,
    ...updateEvent,
    ...await parentIds(),
    [IS_MERGE_FIELD]: true
  }));
  state.bgLogger().log([record]);
}
function updateSpan({
  exported,
  state,
  ...event
}) {
  const resolvedState = state ?? _globalState;
  const components = SpanComponentsV3.fromStr(exported);
  if (!components.data.row_id) {
    throw new Error("Exported span must have a row id");
  }
  updateSpanImpl({
    state: resolvedState,
    parentObjectType: components.data.object_type,
    parentObjectId: new LazyValue(
      spanComponentsToObjectIdLambda(resolvedState, components)
    ),
    id: components.data.row_id,
    event
  });
}
function spanComponentsToObjectIdLambda(state, components) {
  if (components.data.object_id) {
    const ret = components.data.object_id;
    return async () => ret;
  }
  if (!components.data.compute_object_metadata_args) {
    throw new Error(
      "Impossible: must provide either objectId or computeObjectMetadataArgs"
    );
  }
  switch (components.data.object_type) {
    case SpanObjectTypeV3.EXPERIMENT:
      throw new Error(
        "Impossible: computeObjectMetadataArgs not supported for experiments"
      );
    case SpanObjectTypeV3.PROJECT_LOGS:
      return async () => (await computeLoggerMetadata(state, {
        ...components.data.compute_object_metadata_args
      })).project.id;
    default:
      const x = components.data.object_type;
      throw new Error(`Unknown object type: ${x}`);
  }
}
async function spanComponentsToObjectId({
  components,
  state
}) {
  return await spanComponentsToObjectIdLambda(
    state ?? _globalState,
    components
  )();
}
async function permalink(slug, opts) {
  const state = opts?.state ?? _globalState;
  const getOrgName = async () => {
    if (opts?.orgName) {
      return opts.orgName;
    }
    await state.login({});
    if (!state.orgName) {
      throw new Error(
        "Must either provide orgName explicitly or be logged in to a specific org"
      );
    }
    return state.orgName;
  };
  const getAppUrl = async () => {
    if (opts?.appUrl) {
      return opts.appUrl;
    }
    await state.login({});
    if (!state.appUrl) {
      throw new Error("Must either provide appUrl explicitly or be logged in");
    }
    return state.appUrl;
  };
  const components = SpanComponentsV3.fromStr(slug);
  const object_type = spanObjectTypeV3ToString(components.data.object_type);
  const [orgName, appUrl, object_id] = await Promise.all([
    getOrgName(),
    getAppUrl(),
    spanComponentsToObjectId({ components, state })
  ]);
  const id = components.data.row_id;
  if (!id) {
    throw new Error("Span slug does not refer to an individual row");
  }
  const urlParams = new URLSearchParams({ object_type, object_id, id });
  return `${appUrl}/app/${orgName}/object?${urlParams}`;
}
function startSpanParentArgs(args) {
  let argParentObjectId = void 0;
  let argParentSpanIds = void 0;
  let argPropagatedEvent = void 0;
  if (args.parent) {
    if (args.parentSpanIds) {
      throw new Error("Cannot specify both parent and parentSpanIds");
    }
    const parentComponents = SpanComponentsV3.fromStr(args.parent);
    if (args.parentObjectType !== parentComponents.data.object_type) {
      throw new Error(
        `Mismatch between expected span parent object type ${args.parentObjectType} and provided type ${parentComponents.data.object_type}`
      );
    }
    const parentComponentsObjectIdLambda = spanComponentsToObjectIdLambda(
      args.state,
      parentComponents
    );
    const computeParentObjectId = async () => {
      const parentComponentsObjectId = await parentComponentsObjectIdLambda();
      if (await args.parentObjectId.get() !== parentComponentsObjectId) {
        throw new Error(
          `Mismatch between expected span parent object id ${await args.parentObjectId.get()} and provided id ${parentComponentsObjectId}`
        );
      }
      return await args.parentObjectId.get();
    };
    argParentObjectId = new LazyValue(computeParentObjectId);
    if (parentComponents.data.row_id) {
      argParentSpanIds = {
        spanId: parentComponents.data.span_id,
        rootSpanId: parentComponents.data.root_span_id
      };
    }
    argPropagatedEvent = args.propagatedEvent ?? (parentComponents.data.propagated_event ?? void 0);
  } else {
    argParentObjectId = args.parentObjectId;
    argParentSpanIds = args.parentSpanIds;
    argPropagatedEvent = args.propagatedEvent;
  }
  return {
    parentObjectType: args.parentObjectType,
    parentObjectId: argParentObjectId,
    parentComputeObjectMetadataArgs: args.parentComputeObjectMetadataArgs,
    parentSpanIds: argParentSpanIds,
    propagatedEvent: argPropagatedEvent
  };
}
var Logger = class {
  state;
  lazyMetadata;
  _asyncFlush;
  computeMetadataArgs;
  lastStartTime;
  lazyId;
  calledStartSpan;
  // For type identification.
  kind = "logger";
  constructor(state, lazyMetadata, logOptions = {}) {
    this.lazyMetadata = lazyMetadata;
    this._asyncFlush = logOptions.asyncFlush;
    this.computeMetadataArgs = logOptions.computeMetadataArgs;
    this.lastStartTime = getCurrentUnixTimestamp();
    this.lazyId = new LazyValue(async () => await this.id);
    this.calledStartSpan = false;
    this.state = state;
  }
  get org_id() {
    return (async () => {
      return (await this.lazyMetadata.get()).org_id;
    })();
  }
  get project() {
    return (async () => {
      return (await this.lazyMetadata.get()).project;
    })();
  }
  get id() {
    return (async () => (await this.project).id)();
  }
  parentObjectType() {
    return SpanObjectTypeV3.PROJECT_LOGS;
  }
  /**
   * Log a single event. The event will be batched and uploaded behind the scenes if `logOptions.asyncFlush` is true.
   *
   * @param event The event to log.
   * @param event.input: (Optional) the arguments that uniquely define a user input (an arbitrary, JSON serializable object).
   * @param event.output: (Optional) the output of your application, including post-processing (an arbitrary, JSON serializable object), that allows you to determine whether the result is correct or not. For example, in an app that generates SQL queries, the `output` should be the _result_ of the SQL query generated by the model, not the query itself, because there may be multiple valid queries that answer a single question.
   * @param event.expected: (Optional) the ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not. Braintrust currently does not compare `output` to `expected` for you, since there are so many different ways to do that correctly. Instead, these values are just used to help you navigate while digging into analyses. However, we may later use these values to re-score outputs or fine-tune your models.
   * @param event.error: (Optional) The error that occurred, if any. If you use tracing to run an experiment, errors are automatically logged when your code throws an exception.
   * @param event.scores: (Optional) a dictionary of numeric values (between 0 and 1) to log. The scores should give you a variety of signals that help you determine how accurate the outputs are compared to what you expect and diagnose failures. For example, a summarization app might have one score that tells you how accurate the summary is, and another that measures the word similarity between the generated and grouth truth summary. The word similarity score could help you determine whether the summarization was covering similar concepts or not. You can use these scores to help you sort, filter, and compare logs.
   * @param event.metadata: (Optional) a dictionary with additional data about the test example, model outputs, or just about anything else that's relevant, that you can use to help find and analyze examples later. For example, you could log the `prompt`, example's `id`, or anything else that would be useful to slice/dice later. The values in `metadata` can be any JSON-serializable type, but its keys must be strings.
   * @param event.metrics: (Optional) a dictionary of metrics to log. The following keys are populated automatically: "start", "end".
   * @param event.id: (Optional) a unique identifier for the event. If you don't provide one, BrainTrust will generate one for you.
   * @param options Additional logging options
   * @param options.allowConcurrentWithSpans in rare cases where you need to log at the top level separately from spans on the logger elsewhere, set this to true.
   * @returns The `id` of the logged event.
   */
  log(event, options) {
    if (this.calledStartSpan && !options?.allowConcurrentWithSpans) {
      throw new Error(
        "Cannot run toplevel `log` method while using spans. To log to the span, call `logger.traced` and then log with `span.log`"
      );
    }
    const span = this.startSpanImpl({ startTime: this.lastStartTime, event });
    this.lastStartTime = span.end();
    const ret = span.id;
    if (this.asyncFlush === true) {
      return ret;
    } else {
      return (async () => {
        await this.flush();
        return ret;
      })();
    }
  }
  /**
   * Create a new toplevel span underneath the logger. The name defaults to "root".
   *
   * See {@link Span.traced} for full details.
   */
  traced(callback, args) {
    const { setCurrent, ...argsRest } = args ?? {};
    const span = this.startSpan(argsRest);
    const ret = runCatchFinally(
      () => {
        if (setCurrent ?? true) {
          return withCurrent(span, callback);
        } else {
          return callback(span);
        }
      },
      (e) => {
        logError(span, e);
        throw e;
      },
      () => span.end()
    );
    if (this.asyncFlush) {
      return ret;
    } else {
      return (async () => {
        const awaitedRet = await ret;
        await this.flush();
        return awaitedRet;
      })();
    }
  }
  /**
   * Lower-level alternative to `traced`. This allows you to start a span yourself, and can be useful in situations
   * where you cannot use callbacks. However, spans started with `startSpan` will not be marked as the "current span",
   * so `currentSpan()` and `traced()` will be no-ops. If you want to mark a span as current, use `traced` instead.
   *
   * See {@link traced} for full details.
   */
  startSpan(args) {
    this.calledStartSpan = true;
    return this.startSpanImpl(args);
  }
  startSpanImpl(args) {
    return new SpanImpl({
      state: this.state,
      ...args,
      ...startSpanParentArgs({
        state: this.state,
        parent: args?.parent,
        parentObjectType: this.parentObjectType(),
        parentObjectId: this.lazyId,
        parentComputeObjectMetadataArgs: this.computeMetadataArgs,
        parentSpanIds: void 0,
        propagatedEvent: args?.propagatedEvent
      }),
      defaultRootType: SpanTypeAttribute.TASK
    });
  }
  /**
   * Log feedback to an event. Feedback is used to save feedback scores, set an expected value, or add a comment.
   *
   * @param event
   * @param event.id The id of the event to log feedback for. This is the `id` returned by `log` or accessible as the `id` field of a span.
   * @param event.scores (Optional) a dictionary of numeric values (between 0 and 1) to log. These scores will be merged into the existing scores for the event.
   * @param event.expected (Optional) the ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not.
   * @param event.comment (Optional) an optional comment string to log about the event.
   * @param event.metadata (Optional) a dictionary with additional data about the feedback. If you have a `user_id`, you can log it here and access it in the Braintrust UI. Note, this metadata does not correspond to the main event itself, but rather the audit log attached to the event.
   * @param event.source (Optional) the source of the feedback. Must be one of "external" (default), "app", or "api".
   */
  logFeedback(event) {
    logFeedbackImpl(this.state, this.parentObjectType(), this.lazyId, event);
  }
  /**
   * Update a span in the experiment using its id. It is important that you only update a span once the original span has been fully written and flushed,
   * since otherwise updates to the span may conflict with the original span.
   *
   * @param event The event data to update the span with. Must include `id`. See {@link Experiment.log} for a full list of valid fields.
   */
  updateSpan(event) {
    const { id, ...eventRest } = event;
    if (!id) {
      throw new Error("Span id is required to update a span");
    }
    updateSpanImpl({
      state: this.state,
      parentObjectType: this.parentObjectType(),
      parentObjectId: this.lazyId,
      id,
      event: eventRest
    });
  }
  /**
   * Return a serialized representation of the logger that can be used to start subspans in other places.
   *
   * See {@link Span.startSpan} for more details.
   */
  async export() {
    return new SpanComponentsV3({
      object_type: this.parentObjectType(),
      ...this.computeMetadataArgs && !this.lazyId.hasComputed ? { compute_object_metadata_args: this.computeMetadataArgs } : { object_id: await this.lazyId.get() }
    }).toStr();
  }
  /*
   * Flush any pending logs to the server.
   */
  async flush() {
    return await this.state.bgLogger().flush();
  }
  get asyncFlush() {
    return this._asyncFlush;
  }
};
function castLogger(logger, asyncFlush) {
  if (logger === void 0)
    return void 0;
  if (asyncFlush !== void 0 && !!asyncFlush !== !!logger.asyncFlush) {
    throw new Error(
      `Asserted asyncFlush setting ${asyncFlush} does not match stored logger's setting ${logger.asyncFlush}`
    );
  }
  return logger;
}
function constructLogs3Data(items) {
  return `{"rows": ${constructJsonArray(items)}, "api_version": 2}`;
}
function now() {
  return (/* @__PURE__ */ new Date()).getTime();
}
var BackgroundLogger = class _BackgroundLogger {
  apiConn;
  items = [];
  activeFlush = Promise.resolve();
  activeFlushResolved = true;
  activeFlushError = void 0;
  onFlushError;
  syncFlush = false;
  // 6 MB for the AWS lambda gateway (from our own testing).
  maxRequestSize = 6 * 1024 * 1024;
  defaultBatchSize = 100;
  numTries = 3;
  queueDropExceedingMaxsize = void 0;
  queueDropLoggingPeriod = 60;
  failedPublishPayloadsDir = void 0;
  allPublishPayloadsDir = void 0;
  queueDropLoggingState = {
    numDropped: 0,
    lastLoggedTimestamp: 0
  };
  constructor(apiConn, opts) {
    opts = opts ?? {};
    this.apiConn = apiConn;
    const syncFlushEnv = Number(isomorph_default.getEnv("BRAINTRUST_SYNC_FLUSH"));
    if (!isNaN(syncFlushEnv)) {
      this.syncFlush = Boolean(syncFlushEnv);
    }
    const defaultBatchSizeEnv = Number(
      isomorph_default.getEnv("BRAINTRUST_DEFAULT_BATCH_SIZE")
    );
    if (!isNaN(defaultBatchSizeEnv)) {
      this.defaultBatchSize = defaultBatchSizeEnv;
    }
    const maxRequestSizeEnv = Number(isomorph_default.getEnv("BRAINTRUST_MAX_REQUEST_SIZE"));
    if (!isNaN(maxRequestSizeEnv)) {
      this.maxRequestSize = maxRequestSizeEnv;
    }
    const numTriesEnv = Number(isomorph_default.getEnv("BRAINTRUST_NUM_RETRIES"));
    if (!isNaN(numTriesEnv)) {
      this.numTries = numTriesEnv + 1;
    }
    const queueDropExceedingMaxsizeEnv = Number(
      isomorph_default.getEnv("BRAINTRUST_QUEUE_DROP_EXCEEDING_MAXSIZE")
    );
    if (!isNaN(queueDropExceedingMaxsizeEnv)) {
      this.queueDropExceedingMaxsize = queueDropExceedingMaxsizeEnv;
    }
    const queueDropLoggingPeriodEnv = Number(
      isomorph_default.getEnv("BRAINTRUST_QUEUE_DROP_LOGGING_PERIOD")
    );
    if (!isNaN(queueDropLoggingPeriodEnv)) {
      this.queueDropLoggingPeriod = queueDropLoggingPeriodEnv;
    }
    const failedPublishPayloadsDirEnv = isomorph_default.getEnv(
      "BRAINTRUST_FAILED_PUBLISH_PAYLOADS_DIR"
    );
    if (failedPublishPayloadsDirEnv) {
      this.failedPublishPayloadsDir = failedPublishPayloadsDirEnv;
    }
    const allPublishPayloadsDirEnv = isomorph_default.getEnv(
      "BRAINTRUST_ALL_PUBLISH_PAYLOADS_DIR"
    );
    if (allPublishPayloadsDirEnv) {
      this.allPublishPayloadsDir = allPublishPayloadsDirEnv;
    }
    if (!opts.noExitFlush) {
      isomorph_default.processOn("beforeExit", async () => {
        await this.flush();
      });
    }
    this.onFlushError = opts.onFlushError;
  }
  log(items) {
    const [addedItems, droppedItems] = (() => {
      if (this.queueDropExceedingMaxsize === void 0) {
        return [items, []];
      }
      const numElementsToAdd = Math.min(
        Math.max(this.queueDropExceedingMaxsize - this.items.length, 0),
        items.length
      );
      return [items.slice(0, numElementsToAdd), items.slice(numElementsToAdd)];
    })();
    this.items.push(...addedItems);
    if (!this.syncFlush) {
      this.triggerActiveFlush();
    }
    if (droppedItems.length) {
      this.registerDroppedItemCount(droppedItems.length);
      if (this.allPublishPayloadsDir || this.failedPublishPayloadsDir) {
        this.dumpDroppedEvents(droppedItems);
      }
    }
  }
  async flush() {
    if (this.syncFlush) {
      this.triggerActiveFlush();
    }
    await this.activeFlush;
    if (this.activeFlushError) {
      const err = this.activeFlushError;
      this.activeFlushError = void 0;
      if (this.syncFlush) {
        throw err;
      }
    }
  }
  async flushOnce(args) {
    const batchSize = args?.batchSize ?? this.defaultBatchSize;
    const wrappedItems = this.items;
    this.items = [];
    const [allItems, attachments] = await this.unwrapLazyValues(wrappedItems);
    if (allItems.length === 0) {
      return;
    }
    const allItemsStr = allItems.map(
      (bucket) => bucket.map((item) => JSON.stringify(item))
    );
    const batchSets = batchItems({
      items: allItemsStr,
      batchMaxNumItems: batchSize,
      batchMaxNumBytes: this.maxRequestSize / 2
    });
    for (const batchSet of batchSets) {
      const postPromises = batchSet.map(
        (batch) => (async () => {
          try {
            await this.submitLogsRequest(batch);
            return { type: "success" };
          } catch (e) {
            return { type: "error", value: e };
          }
        })()
      );
      const results = await Promise.all(postPromises);
      const failingResultErrors = results.map((r) => r.type === "success" ? void 0 : r.value).filter((r) => r !== void 0);
      if (failingResultErrors.length) {
        throw new AggregateError(
          failingResultErrors,
          `Encountered the following errors while logging:`
        );
      }
    }
    const attachmentErrors = [];
    for (const attachment of attachments) {
      try {
        const result = await attachment.upload();
        if (result.upload_status === "error") {
          throw new Error(result.error_message);
        }
      } catch (error2) {
        attachmentErrors.push(error2);
      }
    }
    if (attachmentErrors.length === 1) {
      throw attachmentErrors[0];
    } else if (attachmentErrors.length > 1) {
      throw new AggregateError(
        attachmentErrors,
        `Encountered the following errors while uploading attachments:`
      );
    }
    if (this.items.length > 0) {
      await this.flushOnce(args);
    }
  }
  async unwrapLazyValues(wrappedItems) {
    for (let i = 0; i < this.numTries; ++i) {
      try {
        const items = await Promise.all(wrappedItems.map((x) => x.get()));
        const attachments = [];
        items.forEach((item) => extractAttachments(item, attachments));
        return [mergeRowBatch(items), attachments];
      } catch (e) {
        let errmsg = "Encountered error when constructing records to flush";
        const isRetrying = i + 1 < this.numTries;
        if (isRetrying) {
          errmsg += ". Retrying";
        }
        console.warn(errmsg);
        if (!isRetrying) {
          console.warn(
            `Failed to construct log records to flush after ${this.numTries} attempts. Dropping batch`
          );
          throw e;
        } else {
          console.warn(e);
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      }
    }
    throw new Error("Impossible");
  }
  async submitLogsRequest(items) {
    const conn = await this.apiConn.get();
    const dataStr = constructLogs3Data(items);
    if (this.allPublishPayloadsDir) {
      await _BackgroundLogger.writePayloadToDir({
        payloadDir: this.allPublishPayloadsDir,
        payload: dataStr
      });
    }
    for (let i = 0; i < this.numTries; i++) {
      const startTime = now();
      let error2 = void 0;
      try {
        await conn.post_json("logs3", dataStr);
      } catch {
        try {
          const legacyDataS = constructJsonArray(
            items.map((r) => JSON.stringify(makeLegacyEvent(JSON.parse(r))))
          );
          await conn.post_json("logs", legacyDataS);
        } catch (e) {
          error2 = e;
        }
      }
      if (error2 === void 0) {
        return;
      }
      const isRetrying = i + 1 < this.numTries;
      const retryingText = isRetrying ? "" : " Retrying";
      const errorText = (() => {
        if (error2 instanceof FailedHTTPResponse) {
          return `${error2.status} (${error2.text}): ${error2.data}`;
        } else {
          return `${error2}`;
        }
      })();
      const errMsg = `log request failed. Elapsed time: ${(now() - startTime) / 1e3} seconds. Payload size: ${dataStr.length}.${retryingText}
Error: ${errorText}`;
      if (!isRetrying && this.failedPublishPayloadsDir) {
        await _BackgroundLogger.writePayloadToDir({
          payloadDir: this.failedPublishPayloadsDir,
          payload: dataStr
        });
        this.logFailedPayloadsDir();
      }
      if (!isRetrying) {
        console.warn(
          `log request failed after ${this.numTries} retries. Dropping batch`
        );
        throw new Error(errMsg);
      } else {
        console.warn(errMsg);
        if (isRetrying) {
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      }
    }
  }
  registerDroppedItemCount(numItems) {
    if (numItems <= 0) {
      return;
    }
    this.queueDropLoggingState.numDropped += numItems;
    const timeNow = getCurrentUnixTimestamp();
    if (timeNow - this.queueDropLoggingState.lastLoggedTimestamp > this.queueDropLoggingPeriod) {
      console.warn(
        `Dropped ${this.queueDropLoggingState.numDropped} elements due to full queue`
      );
      if (this.failedPublishPayloadsDir) {
        this.logFailedPayloadsDir();
      }
      this.queueDropLoggingState.numDropped = 0;
      this.queueDropLoggingState.lastLoggedTimestamp = timeNow;
    }
  }
  async dumpDroppedEvents(wrappedItems) {
    const publishPayloadsDir = [
      this.allPublishPayloadsDir,
      this.failedPublishPayloadsDir
    ].reduce((acc, x) => x ? acc.concat([x]) : acc, new Array());
    if (!(wrappedItems.length && publishPayloadsDir.length)) {
      return;
    }
    try {
      const [allItems, allAttachments] = await this.unwrapLazyValues(wrappedItems);
      const dataStr = constructLogs3Data(
        allItems.map((x) => JSON.stringify(x))
      );
      const attachmentStr = JSON.stringify(
        allAttachments.map((a) => a.debugInfo())
      );
      const payload = `{"data": ${dataStr}, "attachments": ${attachmentStr}}
`;
      for (const payloadDir of publishPayloadsDir) {
        await _BackgroundLogger.writePayloadToDir({ payloadDir, payload });
      }
    } catch (e) {
      console.error(e);
    }
  }
  static async writePayloadToDir({
    payloadDir,
    payload
  }) {
    if (!(isomorph_default.pathJoin && isomorph_default.mkdir && isomorph_default.writeFile)) {
      console.warn(
        "Cannot dump payloads: filesystem-operations not supported on this platform"
      );
      return;
    }
    const payloadFile = isomorph_default.pathJoin(
      payloadDir,
      `payload_${getCurrentUnixTimestamp()}_${uuidv4().slice(0, 8)}.json`
    );
    try {
      await isomorph_default.mkdir(payloadDir, { recursive: true });
      await isomorph_default.writeFile(payloadFile, payload);
    } catch (e) {
      console.error(
        `Failed to write failed payload to output file ${payloadFile}:
`,
        e
      );
    }
  }
  triggerActiveFlush() {
    if (this.activeFlushResolved) {
      this.activeFlushResolved = false;
      this.activeFlushError = void 0;
      this.activeFlush = (async () => {
        try {
          await this.flushOnce();
        } catch (err) {
          if (err instanceof AggregateError) {
            for (const e of err.errors) {
              this.onFlushError?.(e);
            }
          } else {
            this.onFlushError?.(err);
          }
          this.activeFlushError = err;
        } finally {
          this.activeFlushResolved = true;
        }
      })();
      waitUntil(this.activeFlush);
    }
  }
  logFailedPayloadsDir() {
    console.warn(`Logging failed payloads to ${this.failedPublishPayloadsDir}`);
  }
  // Should only be called by BraintrustState.
  internalReplaceApiConn(apiConn) {
    this.apiConn = new LazyValue(async () => apiConn);
  }
};
function init(projectOrOptions, optionalOptions) {
  const options = (() => {
    if (typeof projectOrOptions === "string") {
      return { ...optionalOptions, project: projectOrOptions };
    } else {
      if (optionalOptions !== void 0) {
        throw new Error(
          "Cannot specify options struct as both parameters. Must call either init(project, options) or init(options)."
        );
      }
      return projectOrOptions;
    }
  })();
  const {
    project,
    experiment,
    description,
    dataset,
    baseExperiment,
    isPublic,
    open,
    update,
    appUrl,
    apiKey,
    orgName,
    forceLogin,
    fetch: fetch2,
    metadata,
    gitMetadataSettings,
    projectId,
    baseExperimentId,
    repoInfo: repoInfo2,
    state: stateArg
  } = options;
  if (open && update) {
    throw new Error("Cannot open and update an experiment at the same time");
  }
  const state = stateArg ?? _globalState;
  if (open) {
    if (isEmpty(experiment)) {
      throw new Error(`Cannot open an experiment without specifying its name`);
    }
    const lazyMetadata2 = new LazyValue(
      async () => {
        await state.login({ apiKey, appUrl, orgName, fetch: fetch2, forceLogin });
        const args = {
          project_name: project,
          project_id: projectId,
          org_name: state.orgName,
          experiment_name: experiment
        };
        const response = await state.appConn().post_json("api/experiment/get", args);
        if (response.length === 0) {
          throw new Error(
            `Experiment ${experiment} not found in project ${projectId ?? project}.`
          );
        }
        const info = response[0];
        return {
          project: {
            id: info.project_id,
            name: project ?? "UNKNOWN_PROJECT",
            fullInfo: {}
          },
          experiment: {
            id: info.id,
            name: info.name,
            fullInfo: info
          }
        };
      }
    );
    return new ReadonlyExperiment(
      stateArg ?? _globalState,
      lazyMetadata2
    );
  }
  const lazyMetadata = new LazyValue(
    async () => {
      await state.login({ apiKey, appUrl, orgName });
      const args = {
        project_name: project,
        project_id: projectId,
        org_id: state.orgId,
        update
      };
      if (experiment) {
        args["experiment_name"] = experiment;
      }
      if (description) {
        args["description"] = description;
      }
      const repoInfoArg = await (async () => {
        if (repoInfo2) {
          return repoInfo2;
        }
        let mergedGitMetadataSettings = {
          ...state.gitMetadataSettings || {
            collect: "all"
          }
        };
        if (gitMetadataSettings) {
          mergedGitMetadataSettings = mergeGitMetadataSettings(
            mergedGitMetadataSettings,
            gitMetadataSettings
          );
        }
        return await isomorph_default.getRepoInfo(mergedGitMetadataSettings);
      })();
      if (repoInfoArg) {
        args["repo_info"] = repoInfoArg;
      }
      if (baseExperimentId) {
        args["base_exp_id"] = baseExperimentId;
      } else if (baseExperiment) {
        args["base_experiment"] = baseExperiment;
      } else {
        args["ancestor_commits"] = await isomorph_default.getPastNAncestors();
      }
      if (dataset !== void 0) {
        args["dataset_id"] = await dataset.id;
        args["dataset_version"] = await dataset.version();
      }
      if (isPublic !== void 0) {
        args["public"] = isPublic;
      }
      if (metadata) {
        args["metadata"] = metadata;
      }
      let response = null;
      while (true) {
        try {
          response = await state.appConn().post_json("api/experiment/register", args);
          break;
        } catch (e) {
          if (args["base_experiment"] && `${"data" in e && e.data}`.includes("base experiment")) {
            console.warn(
              `Base experiment ${args["base_experiment"]} not found.`
            );
            delete args["base_experiment"];
          } else {
            throw e;
          }
        }
      }
      return {
        project: {
          id: response.project.id,
          name: response.project.name,
          fullInfo: response.project
        },
        experiment: {
          id: response.experiment.id,
          name: response.experiment.name,
          fullInfo: response.experiment
        }
      };
    }
  );
  const ret = new Experiment(state, lazyMetadata, dataset);
  if (options.setCurrent ?? true) {
    state.currentExperiment = ret;
  }
  return ret;
}
function initExperiment(projectOrOptions, optionalOptions) {
  const options = (() => {
    if (typeof projectOrOptions === "string") {
      return { ...optionalOptions, project: projectOrOptions };
    } else {
      if (optionalOptions !== void 0) {
        throw new Error(
          "Cannot specify options struct as both parameters. Must call either init(project, options) or init(options)."
        );
      }
      return projectOrOptions;
    }
  })();
  return init(options);
}
function withExperiment(project, callback, options = {}) {
  console.warn(
    "withExperiment is deprecated and will be removed in a future version of braintrust. Simply create the experiment with `init`."
  );
  const experiment = init(project, options);
  return callback(experiment);
}
function withLogger(callback, options = {}) {
  console.warn(
    "withLogger is deprecated and will be removed in a future version of braintrust. Simply create the logger with `initLogger`."
  );
  const logger = initLogger(options);
  return callback(logger);
}
function initDataset(projectOrOptions, optionalOptions) {
  const options = (() => {
    if (typeof projectOrOptions === "string") {
      return { ...optionalOptions, project: projectOrOptions };
    } else {
      if (optionalOptions !== void 0) {
        throw new Error(
          "Cannot specify options struct as both parameters. Must call either initDataset(project, options) or initDataset(options)."
        );
      }
      return projectOrOptions;
    }
  })();
  const {
    project,
    dataset,
    description,
    version,
    appUrl,
    apiKey,
    orgName,
    fetch: fetch2,
    forceLogin,
    projectId,
    metadata,
    useOutput: legacy,
    state: stateArg
  } = options;
  const state = stateArg ?? _globalState;
  const lazyMetadata = new LazyValue(
    async () => {
      await state.login({
        orgName,
        apiKey,
        appUrl,
        fetch: fetch2,
        forceLogin
      });
      const args = {
        org_id: state.orgId,
        project_name: project,
        project_id: projectId,
        dataset_name: dataset,
        description,
        metadata
      };
      const response = await state.appConn().post_json("api/dataset/register", args);
      return {
        project: {
          id: response.project.id,
          name: response.project.name,
          fullInfo: response.project
        },
        dataset: {
          id: response.dataset.id,
          name: response.dataset.name,
          fullInfo: response.dataset
        }
      };
    }
  );
  return new Dataset(stateArg ?? _globalState, lazyMetadata, version, legacy);
}
function withDataset(project, callback, options = {}) {
  console.warn(
    "withDataset is deprecated and will be removed in a future version of braintrust. Simply create the dataset with `initDataset`."
  );
  const dataset = initDataset(project, options);
  return callback(dataset);
}
async function computeLoggerMetadata(state, {
  project_name,
  project_id
}) {
  await state.login({});
  const org_id = state.orgId;
  if (isEmpty(project_id)) {
    const response = await state.appConn().post_json("api/project/register", {
      project_name: project_name || GLOBAL_PROJECT,
      org_id
    });
    return {
      org_id,
      project: {
        id: response.project.id,
        name: response.project.name,
        fullInfo: response.project
      }
    };
  } else if (isEmpty(project_name)) {
    const response = await state.appConn().get_json("api/project", {
      id: project_id
    });
    return {
      org_id,
      project: {
        id: project_id,
        name: response.name,
        fullInfo: response.project
      }
    };
  } else {
    return {
      org_id,
      project: { id: project_id, name: project_name, fullInfo: {} }
    };
  }
}
function initLogger(options = {}) {
  const {
    projectName,
    projectId,
    asyncFlush,
    appUrl,
    apiKey,
    orgName,
    forceLogin,
    fetch: fetch2,
    state: stateArg
  } = options || {};
  const computeMetadataArgs = {
    project_name: projectName,
    project_id: projectId
  };
  const state = stateArg ?? _globalState;
  const lazyMetadata = new LazyValue(
    async () => {
      await state.login({
        orgName,
        apiKey,
        appUrl,
        forceLogin,
        fetch: fetch2
      });
      return computeLoggerMetadata(state, computeMetadataArgs);
    }
  );
  const ret = new Logger(state, lazyMetadata, {
    asyncFlush,
    computeMetadataArgs
  });
  if (options.setCurrent ?? true) {
    state.currentLogger = ret;
  }
  return ret;
}
async function loadPrompt({
  projectName,
  projectId,
  slug,
  version,
  defaults,
  noTrace = false,
  appUrl,
  apiKey,
  orgName,
  fetch: fetch2,
  forceLogin,
  state: stateArg
}) {
  if (isEmpty(projectName) && isEmpty(projectId)) {
    throw new Error("Must specify either projectName or projectId");
  }
  if (isEmpty(slug)) {
    throw new Error("Must specify slug");
  }
  const state = stateArg ?? _globalState;
  await state.login({
    orgName,
    apiKey,
    appUrl,
    fetch: fetch2,
    forceLogin
  });
  const args = {
    project_name: projectName,
    project_id: projectId,
    slug,
    version
  };
  const response = await state.apiConn().get_json("v1/prompt", args);
  if (!("objects" in response) || response.objects.length === 0) {
    throw new Error(
      `Prompt ${slug} not found in ${[projectName ?? projectId]}`
    );
  } else if (response.objects.length > 1) {
    throw new Error(
      `Multiple prompts found with slug ${slug} in project ${projectName ?? projectId}. This should never happen.`
    );
  }
  const metadata = promptSchema.parse(response["objects"][0]);
  return new Prompt(metadata, defaults || {}, noTrace);
}
async function login(options = {}) {
  const { forceLogin = false } = options || {};
  if (_globalState.loggedIn && !forceLogin) {
    let checkUpdatedParam2 = function(varname, arg, orig) {
      if (!isEmpty(arg) && !isEmpty(orig) && arg !== orig) {
        throw new Error(
          `Re-logging in with different ${varname} (${arg}) than original (${orig}). To force re-login, pass \`forceLogin: true\``
        );
      }
    };
    var checkUpdatedParam = checkUpdatedParam2;
    checkUpdatedParam2("appUrl", options.appUrl, _globalState.appUrl);
    checkUpdatedParam2(
      "apiKey",
      options.apiKey ? HTTPConnection.sanitize_token(options.apiKey) : void 0,
      _globalState.loginToken
    );
    checkUpdatedParam2("orgName", options.orgName, _globalState.orgName);
    return _globalState;
  }
  await _globalState.login(options);
  globalThis.__inherited_braintrust_state = _globalState;
  return _globalState;
}
async function loginToState(options = {}) {
  const {
    appUrl = isomorph_default.getEnv("BRAINTRUST_APP_URL") || "https://www.braintrust.dev",
    apiKey = isomorph_default.getEnv("BRAINTRUST_API_KEY"),
    orgName = isomorph_default.getEnv("BRAINTRUST_ORG_NAME"),
    fetch: fetch2 = globalThis.fetch
  } = options || {};
  const appPublicUrl = isomorph_default.getEnv("BRAINTRUST_APP_PUBLIC_URL") || appUrl;
  const state = new BraintrustState(options);
  state.resetLoginInfo();
  state.appUrl = appUrl;
  state.appPublicUrl = appPublicUrl;
  let conn = null;
  if (apiKey !== void 0) {
    const resp = await checkResponse(
      await fetch2(_urljoin(state.appUrl, `/api/apikey/login`), {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${apiKey}`
        }
      })
    );
    const info = await resp.json();
    _check_org_info(state, info.org_info, orgName);
    conn = state.apiConn();
    conn.set_token(apiKey);
  } else {
    throw new Error(
      "Please specify an api key (e.g. by setting BRAINTRUST_API_KEY)."
    );
  }
  if (!conn) {
    throw new Error("Conn should be set at this point (a bug)");
  }
  conn.make_long_lived();
  state.appConn().set_token(apiKey);
  if (state.proxyUrl) {
    state.proxyConn().set_token(apiKey);
  }
  state.loginToken = conn.token;
  state.loggedIn = true;
  state.loginReplaceApiConn(conn);
  return state;
}
function log(event) {
  console.warn(
    "braintrust.log is deprecated and will be removed in a future version of braintrust. Use `experiment.log` instead."
  );
  const e = currentExperiment();
  if (!e) {
    throw new Error("Not initialized. Please call init() first");
  }
  return e.log(event);
}
async function summarize(options = {}) {
  console.warn(
    "braintrust.summarize is deprecated and will be removed in a future version of braintrust. Use `experiment.summarize` instead."
  );
  const e = currentExperiment();
  if (!e) {
    throw new Error("Not initialized. Please call init() first");
  }
  return await e.summarize(options);
}
function currentExperiment(options) {
  const state = options?.state ?? _globalState;
  return state.currentExperiment;
}
function currentLogger(options) {
  const state = options?.state ?? _globalState;
  return castLogger(state.currentLogger, options?.asyncFlush);
}
function currentSpan(options) {
  const state = options?.state ?? _globalState;
  return state.currentSpan.getStore() ?? NOOP_SPAN;
}
function getSpanParentObject(options) {
  const state = options?.state ?? _globalState;
  const parentSpan = currentSpan({ state });
  if (!Object.is(parentSpan, NOOP_SPAN)) {
    return parentSpan;
  }
  const experiment = currentExperiment();
  if (experiment) {
    return experiment;
  }
  const logger = currentLogger(options);
  if (logger) {
    return logger;
  }
  return NOOP_SPAN;
}
function logError(span, error2) {
  let errorMessage = "<error>";
  let stackTrace = "";
  if (error2 instanceof Error) {
    errorMessage = error2.message;
    stackTrace = error2.stack || "";
  } else {
    errorMessage = String(error2);
  }
  span.log({ error: `${errorMessage}

${stackTrace}` });
}
function traced(callback, args) {
  const { span, isSyncFlushLogger } = startSpanAndIsLogger(args);
  const ret = runCatchFinally(
    () => {
      if (args?.setCurrent ?? true) {
        return withCurrent(span, callback);
      } else {
        return callback(span);
      }
    },
    (e) => {
      logError(span, e);
      throw e;
    },
    () => span.end()
  );
  if (args?.asyncFlush) {
    return ret;
  } else {
    return (async () => {
      const awaitedRet = await ret;
      if (isSyncFlushLogger) {
        await span.flush();
      }
      return awaitedRet;
    })();
  }
}
function wrapTraced(fn, args) {
  const spanArgs = {
    name: fn.name,
    type: "function",
    ...args
  };
  const hasExplicitInput = args && args.event && "input" in args.event && args.event.input !== void 0;
  const hasExplicitOutput = args && args.event && args.event.output !== void 0;
  if (args?.asyncFlush) {
    return (...fnArgs) => traced((span) => {
      if (!hasExplicitInput) {
        span.log({ input: fnArgs });
      }
      const output = fn(...fnArgs);
      if (!hasExplicitOutput) {
        if (output instanceof Promise) {
          return (async () => {
            const result = await output;
            span.log({ output: result });
            return result;
          })();
        } else {
          span.log({ output });
        }
      }
      return output;
    }, spanArgs);
  } else {
    return (...fnArgs) => traced(async (span) => {
      if (!hasExplicitInput) {
        span.log({ input: fnArgs });
      }
      const outputResult = fn(...fnArgs);
      const output = await outputResult;
      if (!hasExplicitOutput) {
        span.log({ output });
      }
      return output;
    }, spanArgs);
  }
}
var traceable = wrapTraced;
function startSpan(args) {
  return startSpanAndIsLogger(args).span;
}
async function flush(options) {
  const state = options?.state ?? _globalState;
  return await state.bgLogger().flush();
}
function setFetch(fetch2) {
  _globalState.setFetch(fetch2);
}
function startSpanAndIsLogger(args) {
  const state = args?.state ?? _globalState;
  if (args?.parent) {
    const components = SpanComponentsV3.fromStr(args?.parent);
    const parentSpanIds = components.data.row_id ? {
      spanId: components.data.span_id,
      rootSpanId: components.data.root_span_id
    } : void 0;
    const span = new SpanImpl({
      state,
      ...args,
      parentObjectType: components.data.object_type,
      parentObjectId: new LazyValue(
        spanComponentsToObjectIdLambda(state, components)
      ),
      parentComputeObjectMetadataArgs: components.data.compute_object_metadata_args ?? void 0,
      parentSpanIds,
      propagatedEvent: args?.propagatedEvent ?? (components.data.propagated_event ?? void 0)
    });
    return {
      span,
      isSyncFlushLogger: components.data.object_type === SpanObjectTypeV3.PROJECT_LOGS && // Since there's no parent logger here, we're free to choose the async flush
      // behavior, and therefore propagate along whatever we get from the arguments
      !args?.asyncFlush
    };
  } else {
    const parentObject = getSpanParentObject({
      asyncFlush: args?.asyncFlush
    });
    const span = parentObject.startSpan(args);
    return {
      span,
      isSyncFlushLogger: parentObject.kind === "logger" && !parentObject.asyncFlush
    };
  }
}
function withCurrent(span, callback, state = _globalState) {
  return state.currentSpan.run(span, () => callback(span));
}
function _check_org_info(state, org_info, org_name) {
  if (org_info.length === 0) {
    throw new Error("This user is not part of any organizations.");
  }
  for (const org of org_info) {
    if (org_name === void 0 || org.name === org_name) {
      state.orgId = org.id;
      state.orgName = org.name;
      state.apiUrl = isomorph_default.getEnv("BRAINTRUST_API_URL") ?? org.api_url;
      state.proxyUrl = isomorph_default.getEnv("BRAINTRUST_PROXY_URL") ?? org.proxy_url;
      state.gitMetadataSettings = org.git_metadata || void 0;
      break;
    }
  }
  if (state.orgId === void 0) {
    throw new Error(
      `Organization ${org_name} not found. Must be one of ${org_info.map((x) => x.name).join(", ")}`
    );
  }
}
function validateTags(tags) {
  const seen = /* @__PURE__ */ new Set();
  for (const tag of tags) {
    if (typeof tag !== "string") {
      throw new Error("tags must be strings");
    }
    if (seen.has(tag)) {
      throw new Error(`duplicate tag: ${tag}`);
    }
  }
}
function validateAndSanitizeExperimentLogPartialArgs(event) {
  if (event.scores) {
    if (Array.isArray(event.scores)) {
      throw new Error("scores must be an object, not an array");
    }
    for (let [name, score] of Object.entries(event.scores)) {
      if (typeof name !== "string") {
        throw new Error("score names must be strings");
      }
      if (score === null || score === void 0) {
        continue;
      }
      if (typeof score === "boolean") {
        score = score ? 1 : 0;
        event.scores[name] = score;
      }
      if (typeof score !== "number") {
        throw new Error("score values must be numbers");
      }
      if (score < 0 || score > 1) {
        throw new Error("score values must be between 0 and 1");
      }
    }
  }
  if (event.metadata) {
    for (const key of Object.keys(event.metadata)) {
      if (typeof key !== "string") {
        throw new Error("metadata keys must be strings");
      }
    }
  }
  if (event.metrics) {
    for (const [key, value] of Object.entries(event.metrics)) {
      if (typeof key !== "string") {
        throw new Error("metric keys must be strings");
      }
      if (value !== void 0 && typeof value !== "number") {
        throw new Error("metric values must be numbers");
      }
    }
  }
  if ("input" in event && event.input && "inputs" in event && event.inputs) {
    throw new Error(
      "Only one of input or inputs (deprecated) can be specified. Prefer input."
    );
  }
  if ("tags" in event && event.tags) {
    validateTags(event.tags);
  }
  if ("inputs" in event) {
    const { inputs, ...rest } = event;
    return { input: inputs, ...rest };
  } else {
    return { ...event };
  }
}
function deepCopyEvent(event) {
  const attachments = [];
  const IDENTIFIER = "_bt_internal_saved_attachment";
  const savedAttachmentSchema = z2.strictObject({ [IDENTIFIER]: z2.number() });
  const serialized = JSON.stringify(event, (_k, v) => {
    if (v instanceof SpanImpl || v instanceof NoopSpan) {
      return `<span>`;
    } else if (v instanceof Experiment) {
      return `<experiment>`;
    } else if (v instanceof Dataset) {
      return `<dataset>`;
    } else if (v instanceof Logger) {
      return `<logger>`;
    } else if (v instanceof Attachment) {
      const idx = attachments.push(v);
      return { [IDENTIFIER]: idx - 1 };
    }
    return v;
  });
  const x = JSON.parse(serialized, (_k, v) => {
    const parsedAttachment = savedAttachmentSchema.safeParse(v);
    if (parsedAttachment.success) {
      return attachments[parsedAttachment.data[IDENTIFIER]];
    }
    return v;
  });
  return x;
}
function extractAttachments(event, attachments) {
  for (const [key, value] of Object.entries(event)) {
    if (value instanceof Attachment) {
      attachments.push(value);
      event[key] = value.reference;
      continue;
    }
    if (!(value instanceof Object)) {
      continue;
    }
    extractAttachments(value, attachments);
  }
}
function validateAndSanitizeExperimentLogFullArgs(event, hasDataset) {
  if ("input" in event && !isEmpty(event.input) && "inputs" in event && !isEmpty(event.inputs) || !("input" in event) && !("inputs" in event)) {
    throw new Error(
      "Exactly one of input or inputs (deprecated) must be specified. Prefer input."
    );
  }
  if (isEmpty(event.output)) {
    throw new Error("output must be specified");
  }
  if (isEmpty(event.scores)) {
    throw new Error("scores must be specified");
  }
  if (hasDataset && event.datasetRecordId === void 0) {
    throw new Error("datasetRecordId must be specified when using a dataset");
  } else if (!hasDataset && event.datasetRecordId !== void 0) {
    throw new Error(
      "datasetRecordId cannot be specified when not using a dataset"
    );
  }
  return event;
}
var ObjectFetcher = class {
  constructor(objectType, pinnedVersion, mutateRecord) {
    this.objectType = objectType;
    this.pinnedVersion = pinnedVersion;
    this.mutateRecord = mutateRecord;
  }
  _fetchedData = void 0;
  get id() {
    throw new Error("ObjectFetcher subclasses must have an 'id' attribute");
  }
  async getState() {
    throw new Error("ObjectFetcher subclasses must have a 'getState' method");
  }
  async *fetch() {
    const records = await this.fetchedData();
    for (const record of records) {
      yield record;
    }
  }
  [Symbol.asyncIterator]() {
    return this.fetch();
  }
  async fetchedData() {
    if (this._fetchedData === void 0) {
      const state = await this.getState();
      const resp = await state.apiConn().get(
        `v1/${this.objectType}/${await this.id}/fetch`,
        {
          version: this.pinnedVersion
        },
        { headers: { "Accept-Encoding": "gzip" } }
      );
      const data = (await resp.json()).events;
      this._fetchedData = this.mutateRecord ? data?.map(this.mutateRecord) : data;
    }
    return this._fetchedData || [];
  }
  clearCache() {
    this._fetchedData = void 0;
  }
  async version() {
    if (this.pinnedVersion !== void 0) {
      return this.pinnedVersion;
    } else {
      const fetchedData = await this.fetchedData();
      let maxVersion = void 0;
      for (const record of fetchedData) {
        const xactId = String(record[TRANSACTION_ID_FIELD] ?? "0");
        if (maxVersion === void 0 || xactId > maxVersion) {
          maxVersion = xactId;
        }
      }
      return maxVersion;
    }
  }
};
var Experiment = class extends ObjectFetcher {
  lazyMetadata;
  dataset;
  lastStartTime;
  lazyId;
  calledStartSpan;
  state;
  // For type identification.
  kind = "experiment";
  constructor(state, lazyMetadata, dataset) {
    super("experiment", void 0);
    this.lazyMetadata = lazyMetadata;
    this.dataset = dataset;
    this.lastStartTime = getCurrentUnixTimestamp();
    this.lazyId = new LazyValue(async () => await this.id);
    this.calledStartSpan = false;
    this.state = state;
  }
  get id() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.id;
    })();
  }
  get name() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.name;
    })();
  }
  get project() {
    return (async () => {
      return (await this.lazyMetadata.get()).project;
    })();
  }
  parentObjectType() {
    return SpanObjectTypeV3.EXPERIMENT;
  }
  async getState() {
    await this.lazyMetadata.get();
    return this.state;
  }
  /**
   * Log a single event to the experiment. The event will be batched and uploaded behind the scenes.
   *
   * @param event The event to log.
   * @param event.input: The arguments that uniquely define a test case (an arbitrary, JSON serializable object). Later on, Braintrust will use the `input` to know whether two test cases are the same between experiments, so they should not contain experiment-specific state. A simple rule of thumb is that if you run the same experiment twice, the `input` should be identical.
   * @param event.output: The output of your application, including post-processing (an arbitrary, JSON serializable object), that allows you to determine whether the result is correct or not. For example, in an app that generates SQL queries, the `output` should be the _result_ of the SQL query generated by the model, not the query itself, because there may be multiple valid queries that answer a single question.
   * @param event.expected: (Optional) The ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not. Braintrust currently does not compare `output` to `expected` for you, since there are so many different ways to do that correctly. Instead, these values are just used to help you navigate your experiments while digging into analyses. However, we may later use these values to re-score outputs or fine-tune your models.
   * @param event.error: (Optional) The error that occurred, if any. If you use tracing to run an experiment, errors are automatically logged when your code throws an exception.
   * @param event.scores: A dictionary of numeric values (between 0 and 1) to log. The scores should give you a variety of signals that help you determine how accurate the outputs are compared to what you expect and diagnose failures. For example, a summarization app might have one score that tells you how accurate the summary is, and another that measures the word similarity between the generated and grouth truth summary. The word similarity score could help you determine whether the summarization was covering similar concepts or not. You can use these scores to help you sort, filter, and compare experiments.
   * @param event.metadata: (Optional) a dictionary with additional data about the test example, model outputs, or just about anything else that's relevant, that you can use to help find and analyze examples later. For example, you could log the `prompt`, example's `id`, or anything else that would be useful to slice/dice later. The values in `metadata` can be any JSON-serializable type, but its keys must be strings.
   * @param event.metrics: (Optional) a dictionary of metrics to log. The following keys are populated automatically: "start", "end".
   * @param event.id: (Optional) a unique identifier for the event. If you don't provide one, BrainTrust will generate one for you.
   * @param event.dataset_record_id: (Optional) the id of the dataset record that this event is associated with. This field is required if and only if the experiment is associated with a dataset.
   * @param options Additional logging options
   * @param options.allowConcurrentWithSpans in rare cases where you need to log at the top level separately from spans on the experiment elsewhere, set this to true.
   * @returns The `id` of the logged event.
   */
  log(event, options) {
    if (this.calledStartSpan && !options?.allowConcurrentWithSpans) {
      throw new Error(
        "Cannot run toplevel `log` method while using spans. To log to the span, call `experiment.traced` and then log with `span.log`"
      );
    }
    event = validateAndSanitizeExperimentLogFullArgs(event, !!this.dataset);
    const span = this.startSpanImpl({ startTime: this.lastStartTime, event });
    this.lastStartTime = span.end();
    return span.id;
  }
  /**
   * Create a new toplevel span underneath the experiment. The name defaults to "root".
   *
   * See {@link Span.traced} for full details.
   */
  traced(callback, args) {
    const { setCurrent, ...argsRest } = args ?? {};
    const span = this.startSpan(argsRest);
    const ret = runCatchFinally(
      () => {
        if (setCurrent ?? true) {
          return withCurrent(span, callback);
        } else {
          return callback(span);
        }
      },
      (e) => {
        logError(span, e);
        throw e;
      },
      () => span.end()
    );
    return ret;
  }
  /**
   * Lower-level alternative to `traced`. This allows you to start a span yourself, and can be useful in situations
   * where you cannot use callbacks. However, spans started with `startSpan` will not be marked as the "current span",
   * so `currentSpan()` and `traced()` will be no-ops. If you want to mark a span as current, use `traced` instead.
   *
   * See {@link traced} for full details.
   */
  startSpan(args) {
    this.calledStartSpan = true;
    return this.startSpanImpl(args);
  }
  startSpanImpl(args) {
    return new SpanImpl({
      state: this.state,
      ...args,
      ...startSpanParentArgs({
        state: this.state,
        parent: args?.parent,
        parentObjectType: this.parentObjectType(),
        parentObjectId: this.lazyId,
        parentComputeObjectMetadataArgs: void 0,
        parentSpanIds: void 0,
        propagatedEvent: args?.propagatedEvent
      }),
      defaultRootType: SpanTypeAttribute.EVAL
    });
  }
  async fetchBaseExperiment() {
    const state = await this.getState();
    const conn = state.appConn();
    try {
      const resp = await conn.post("/api/base_experiment/get_id", {
        id: await this.id
      });
      const base = await resp.json();
      return {
        id: base["base_exp_id"],
        name: base["base_exp_name"]
      };
    } catch (e) {
      if (e instanceof FailedHTTPResponse && e.status === 400) {
        return null;
      } else {
        throw e;
      }
    }
  }
  /**
   * Summarize the experiment, including the scores (compared to the closest reference experiment) and metadata.
   *
   * @param options Options for summarizing the experiment.
   * @param options.summarizeScores Whether to summarize the scores. If False, only the metadata will be returned.
   * @param options.comparisonExperimentId The experiment to compare against. If None, the most recent experiment on the origin's main branch will be used.
   * @returns A summary of the experiment, including the scores (compared to the closest reference experiment) and metadata.
   */
  async summarize(options = {}) {
    let { summarizeScores = true, comparisonExperimentId = void 0 } = options || {};
    await this.flush();
    const state = await this.getState();
    const projectUrl = `${state.appPublicUrl}/app/${encodeURIComponent(
      state.orgName
    )}/p/${encodeURIComponent((await this.project).name)}`;
    const experimentUrl = `${projectUrl}/experiments/${encodeURIComponent(
      await this.name
    )}`;
    let scores = void 0;
    let metrics = void 0;
    let comparisonExperimentName = void 0;
    if (summarizeScores) {
      if (comparisonExperimentId === void 0) {
        const baseExperiment = await this.fetchBaseExperiment();
        if (baseExperiment !== null) {
          comparisonExperimentId = baseExperiment.id;
          comparisonExperimentName = baseExperiment.name;
        }
      }
      const results = await state.apiConn().get_json(
        "/experiment-comparison2",
        {
          experiment_id: await this.id,
          base_experiment_id: comparisonExperimentId
        },
        3
      );
      scores = results["scores"];
      metrics = results["metrics"];
    }
    return {
      projectName: (await this.project).name,
      experimentName: await this.name,
      projectId: (await this.project).id,
      experimentId: await this.id,
      projectUrl,
      experimentUrl,
      comparisonExperimentName,
      scores: scores ?? {},
      metrics
    };
  }
  /**
   * Log feedback to an event in the experiment. Feedback is used to save feedback scores, set an expected value, or add a comment.
   *
   * @param event
   * @param event.id The id of the event to log feedback for. This is the `id` returned by `log` or accessible as the `id` field of a span.
   * @param event.scores (Optional) a dictionary of numeric values (between 0 and 1) to log. These scores will be merged into the existing scores for the event.
   * @param event.expected (Optional) the ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not.
   * @param event.comment (Optional) an optional comment string to log about the event.
   * @param event.metadata (Optional) a dictionary with additional data about the feedback. If you have a `user_id`, you can log it here and access it in the Braintrust UI. Note, this metadata does not correspond to the main event itself, but rather the audit log attached to the event.
   * @param event.source (Optional) the source of the feedback. Must be one of "external" (default), "app", or "api".
   */
  logFeedback(event) {
    logFeedbackImpl(this.state, this.parentObjectType(), this.lazyId, event);
  }
  /**
   * Update a span in the experiment using its id. It is important that you only update a span once the original span has been fully written and flushed,
   * since otherwise updates to the span may conflict with the original span.
   *
   * @param event The event data to update the span with. Must include `id`. See {@link Experiment.log} for a full list of valid fields.
   */
  updateSpan(event) {
    const { id, ...eventRest } = event;
    if (!id) {
      throw new Error("Span id is required to update a span");
    }
    updateSpanImpl({
      state: this.state,
      parentObjectType: this.parentObjectType(),
      parentObjectId: this.lazyId,
      id,
      event: eventRest
    });
  }
  /**
   * Return a serialized representation of the experiment that can be used to start subspans in other places.
   *
   * See {@link Span.startSpan} for more details.
   */
  async export() {
    return new SpanComponentsV3({
      object_type: this.parentObjectType(),
      object_id: await this.id
    }).toStr();
  }
  /**
   * Flush any pending rows to the server.
   */
  async flush() {
    return await this.state.bgLogger().flush();
  }
  /**
   * @deprecated This function is deprecated. You can simply remove it from your code.
   */
  async close() {
    console.warn(
      "close is deprecated and will be removed in a future version of braintrust. It is now a no-op and can be removed"
    );
    return this.id;
  }
};
var ReadonlyExperiment = class extends ObjectFetcher {
  constructor(state, lazyMetadata) {
    super("experiment", void 0);
    this.state = state;
    this.lazyMetadata = lazyMetadata;
  }
  get id() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.id;
    })();
  }
  get name() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.name;
    })();
  }
  async getState() {
    await this.lazyMetadata.get();
    return this.state;
  }
  async *asDataset() {
    const records = this.fetch();
    for await (const record of records) {
      if (record.root_span_id !== record.span_id) {
        continue;
      }
      const { output, expected: expectedRecord } = record;
      const expected = expectedRecord ?? output;
      if (isEmpty(expected)) {
        yield {
          input: record.input,
          tags: record.tags
        };
      } else {
        yield {
          input: record.input,
          expected,
          tags: record.tags
        };
      }
    }
  }
};
var executionCounter = 0;
function newId() {
  return uuidv4();
}
var SpanImpl = class _SpanImpl {
  state;
  isMerge;
  loggedEndTime;
  propagatedEvent;
  // For internal use only.
  parentObjectType;
  parentObjectId;
  parentComputeObjectMetadataArgs;
  _id;
  spanId;
  rootSpanId;
  spanParents;
  kind = "span";
  constructor(args) {
    this.state = args.state;
    const spanAttributes = args.spanAttributes ?? {};
    const rawEvent = args.event ?? {};
    const type = args.type ?? (args.parentSpanIds ? void 0 : args.defaultRootType);
    this.loggedEndTime = void 0;
    this.parentObjectType = args.parentObjectType;
    this.parentObjectId = args.parentObjectId;
    this.parentComputeObjectMetadataArgs = args.parentComputeObjectMetadataArgs;
    this.propagatedEvent = args.propagatedEvent;
    if (this.propagatedEvent) {
      mergeDicts(rawEvent, this.propagatedEvent);
    }
    const { id: eventId, ...event } = rawEvent;
    const callerLocation = isomorph_default.getCallerLocation();
    const name = (() => {
      if (args.name)
        return args.name;
      if (!args.parentSpanIds)
        return "root";
      if (callerLocation) {
        const pathComponents = callerLocation.caller_filename.split("/");
        const filename = pathComponents[pathComponents.length - 1];
        return [callerLocation.caller_functionname].concat(
          filename ? [`${filename}:${callerLocation.caller_lineno}`] : []
        ).join(":");
      }
      return "subspan";
    })();
    const internalData = {
      metrics: {
        start: args.startTime ?? getCurrentUnixTimestamp()
      },
      context: { ...callerLocation },
      span_attributes: {
        name,
        type,
        ...spanAttributes,
        exec_counter: executionCounter++
      },
      created: (/* @__PURE__ */ new Date()).toISOString()
    };
    this._id = eventId ?? uuidv4();
    this.spanId = uuidv4();
    if (args.parentSpanIds) {
      this.rootSpanId = args.parentSpanIds.rootSpanId;
      this.spanParents = [args.parentSpanIds.spanId];
    } else {
      this.rootSpanId = this.spanId;
      this.spanParents = void 0;
    }
    this.isMerge = false;
    this.logInternal({ event, internalData });
    this.isMerge = true;
  }
  get id() {
    return this._id;
  }
  setAttributes(args) {
    this.logInternal({ internalData: { span_attributes: args } });
  }
  log(event) {
    this.logInternal({ event });
  }
  logInternal({
    event,
    internalData
  }) {
    const [serializableInternalData, lazyInternalData] = splitLoggingData({
      event,
      internalData
    });
    const partialRecord = deepCopyEvent({
      id: this.id,
      span_id: this.spanId,
      root_span_id: this.rootSpanId,
      span_parents: this.spanParents,
      ...serializableInternalData,
      [IS_MERGE_FIELD]: this.isMerge
    });
    if (partialRecord.metrics?.end) {
      this.loggedEndTime = partialRecord.metrics?.end;
    }
    if ((partialRecord.tags ?? []).length > 0 && this.spanParents?.length) {
      throw new Error("Tags can only be logged to the root span");
    }
    const computeRecord = async () => ({
      ...partialRecord,
      ...Object.fromEntries(
        await Promise.all(
          Object.entries(lazyInternalData).map(async ([key, value]) => [
            key,
            await value.get()
          ])
        )
      ),
      ...new SpanComponentsV3({
        object_type: this.parentObjectType,
        object_id: await this.parentObjectId.get()
      }).objectIdFields()
    });
    this.state.bgLogger().log([new LazyValue(computeRecord)]);
  }
  logFeedback(event) {
    logFeedbackImpl(this.state, this.parentObjectType, this.parentObjectId, {
      ...event,
      id: this.id
    });
  }
  traced(callback, args) {
    const { setCurrent, ...argsRest } = args ?? {};
    const span = this.startSpan(argsRest);
    return runCatchFinally(
      () => {
        if (setCurrent ?? true) {
          return withCurrent(span, callback);
        } else {
          return callback(span);
        }
      },
      (e) => {
        logError(span, e);
        throw e;
      },
      () => span.end()
    );
  }
  startSpan(args) {
    const parentSpanIds = args?.parent ? void 0 : { spanId: this.spanId, rootSpanId: this.rootSpanId };
    return new _SpanImpl({
      state: this.state,
      ...args,
      ...startSpanParentArgs({
        state: this.state,
        parent: args?.parent,
        parentObjectType: this.parentObjectType,
        parentObjectId: this.parentObjectId,
        parentComputeObjectMetadataArgs: this.parentComputeObjectMetadataArgs,
        parentSpanIds,
        propagatedEvent: args?.propagatedEvent ?? this.propagatedEvent
      })
    });
  }
  end(args) {
    let endTime;
    let internalData = {};
    if (!this.loggedEndTime) {
      endTime = args?.endTime ?? getCurrentUnixTimestamp();
      internalData = { metrics: { end: endTime } };
    } else {
      endTime = this.loggedEndTime;
    }
    this.logInternal({ internalData });
    return endTime;
  }
  async export() {
    return new SpanComponentsV3({
      object_type: this.parentObjectType,
      ...this.parentComputeObjectMetadataArgs && !this.parentObjectId.hasComputed ? { compute_object_metadata_args: this.parentComputeObjectMetadataArgs } : { object_id: await this.parentObjectId.get() },
      row_id: this.id,
      span_id: this.spanId,
      root_span_id: this.rootSpanId,
      propagated_event: this.propagatedEvent
    }).toStr();
  }
  async permalink() {
    return await permalink(await this.export(), {
      state: this.state
    });
  }
  async flush() {
    return await this.state.bgLogger().flush();
  }
  close(args) {
    return this.end(args);
  }
};
function splitLoggingData({
  event,
  internalData
}) {
  const sanitized = validateAndSanitizeExperimentLogPartialArgs(event ?? {});
  const sanitizedAndInternalData = {};
  mergeDicts(sanitizedAndInternalData, internalData || {});
  mergeDicts(sanitizedAndInternalData, sanitized);
  const serializableInternalData = {};
  const lazyInternalData = {};
  for (const [key, value] of Object.entries(sanitizedAndInternalData)) {
    if (value instanceof BraintrustStream) {
      const streamCopy = value.copy();
      lazyInternalData[key] = new LazyValue(async () => {
        return await new Promise((resolve, reject2) => {
          streamCopy.toReadableStream().pipeThrough(createFinalValuePassThroughStream(resolve, reject2)).pipeTo(devNullWritableStream());
        });
      });
    } else if (value instanceof ReadableStream) {
      lazyInternalData[key] = new LazyValue(async () => {
        return await new Promise((resolve, reject2) => {
          value.pipeThrough(createFinalValuePassThroughStream(resolve, reject2)).pipeTo(devNullWritableStream());
        });
      });
    } else {
      serializableInternalData[key] = value;
    }
  }
  return [serializableInternalData, lazyInternalData];
}
var Dataset = class extends ObjectFetcher {
  constructor(state, lazyMetadata, pinnedVersion, legacy) {
    const isLegacyDataset = legacy ?? DEFAULT_IS_LEGACY_DATASET;
    if (isLegacyDataset) {
      console.warn(
        `Records will be fetched from this dataset in the legacy format, with the "expected" field renamed to "output". Please update your code to use "expected", and use \`braintrust.initDataset()\` with \`{ useOutput: false }\`, which will become the default in a future version of Braintrust.`
      );
    }
    super(
      "dataset",
      pinnedVersion,
      (r) => ensureDatasetRecord(r, isLegacyDataset)
    );
    this.state = state;
    this.lazyMetadata = lazyMetadata;
  }
  lazyMetadata;
  get id() {
    return (async () => {
      return (await this.lazyMetadata.get()).dataset.id;
    })();
  }
  get name() {
    return (async () => {
      return (await this.lazyMetadata.get()).dataset.name;
    })();
  }
  get project() {
    return (async () => {
      return (await this.lazyMetadata.get()).project;
    })();
  }
  async getState() {
    await this.lazyMetadata.get();
    return this.state;
  }
  validateEvent({
    metadata,
    expected,
    output,
    tags
  }) {
    if (metadata !== void 0) {
      for (const key of Object.keys(metadata)) {
        if (typeof key !== "string") {
          throw new Error("metadata keys must be strings");
        }
      }
    }
    if (expected !== void 0 && output !== void 0) {
      throw new Error(
        "Only one of expected or output (deprecated) can be specified. Prefer expected."
      );
    }
    if (tags) {
      validateTags(tags);
    }
  }
  createArgs({
    id,
    input,
    expected,
    metadata,
    tags,
    output,
    isMerge
  }) {
    return new LazyValue(async () => {
      const dataset_id = await this.id;
      const expectedValue = expected === void 0 ? output : expected;
      const args = {
        id,
        input,
        expected: expectedValue,
        tags,
        dataset_id,
        created: !isMerge ? (/* @__PURE__ */ new Date()).toISOString() : void 0,
        //if we're merging/updating an event we will not add this ts
        metadata,
        ...!!isMerge ? {
          [IS_MERGE_FIELD]: true
        } : {}
      };
      return args;
    });
  }
  /**
   * Insert a single record to the dataset. The record will be batched and uploaded behind the scenes. If you pass in an `id`,
   * and a record with that `id` already exists, it will be overwritten (upsert).
   *
   * @param event The event to log.
   * @param event.input The argument that uniquely define an input case (an arbitrary, JSON serializable object).
   * @param event.expected The output of your application, including post-processing (an arbitrary, JSON serializable object).
   * @param event.tags (Optional) a list of strings that you can use to filter and group records later.
   * @param event.metadata (Optional) a dictionary with additional data about the test example, model outputs, or just
   * about anything else that's relevant, that you can use to help find and analyze examples later. For example, you could log the
   * `prompt`, example's `id`, or anything else that would be useful to slice/dice later. The values in `metadata` can be any
   * JSON-serializable type, but its keys must be strings.
   * @param event.id (Optional) a unique identifier for the event. If you don't provide one, Braintrust will generate one for you.
   * @param event.output: (Deprecated) The output of your application. Use `expected` instead.
   * @returns The `id` of the logged record.
   */
  insert({
    input,
    expected,
    metadata,
    tags,
    id,
    output
  }) {
    this.validateEvent({ metadata, expected, output, tags });
    const rowId = id || uuidv4();
    const args = this.createArgs(
      deepCopyEvent({
        id: rowId,
        input,
        expected,
        metadata,
        tags,
        output,
        isMerge: false
      })
    );
    this.state.bgLogger().log([args]);
    return rowId;
  }
  /**
   * Update fields of a single record in the dataset. The updated fields will be batched and uploaded behind the scenes.
   * You must pass in an `id` of the record to update. Only the fields provided will be updated; other fields will remain unchanged.
   *
   * @param event The fields to update in the record.
   * @param event.id The unique identifier of the record to update.
   * @param event.input (Optional) The new input value for the record (an arbitrary, JSON serializable object).
   * @param event.expected (Optional) The new expected output value for the record (an arbitrary, JSON serializable object).
   * @param event.tags (Optional) A list of strings to update the tags of the record.
   * @param event.metadata (Optional) A dictionary to update the metadata of the record. The values in `metadata` can be any
   * JSON-serializable type, but its keys must be strings.
   * @returns The `id` of the updated record.
   */
  update({
    input,
    expected,
    metadata,
    tags,
    id
  }) {
    this.validateEvent({ metadata, expected, tags });
    const args = this.createArgs(
      deepCopyEvent({
        id,
        input,
        expected,
        metadata,
        tags,
        isMerge: true
      })
    );
    this.state.bgLogger().log([args]);
    return id;
  }
  delete(id) {
    const args = new LazyValue(async () => ({
      id,
      dataset_id: await this.id,
      created: (/* @__PURE__ */ new Date()).toISOString(),
      _object_delete: true
    }));
    this.state.bgLogger().log([args]);
    return id;
  }
  /**
   * Summarize the dataset, including high level metrics about its size and other metadata.
   * @param summarizeData Whether to summarize the data. If false, only the metadata will be returned.
   * @returns `DatasetSummary`
   * @returns A summary of the dataset.
   */
  async summarize(options = {}) {
    const { summarizeData = true } = options || {};
    await this.flush();
    const state = await this.getState();
    const projectUrl = `${state.appPublicUrl}/app/${encodeURIComponent(
      state.orgName
    )}/p/${encodeURIComponent((await this.project).name)}`;
    const datasetUrl = `${projectUrl}/datasets/${encodeURIComponent(
      await this.name
    )}`;
    let dataSummary = void 0;
    if (summarizeData) {
      dataSummary = await state.apiConn().get_json(
        "dataset-summary",
        {
          dataset_id: await this.id
        },
        3
      );
    }
    return {
      projectName: (await this.project).name,
      datasetName: await this.name,
      projectUrl,
      datasetUrl,
      dataSummary
    };
  }
  /**
   * Flush any pending rows to the server.
   */
  async flush() {
    return await this.state.bgLogger().flush();
  }
  /**
   * @deprecated This function is deprecated. You can simply remove it from your code.
   */
  async close() {
    console.warn(
      "close is deprecated and will be removed in a future version of braintrust. It is now a no-op and can be removed"
    );
    return this.id;
  }
};
function renderMessage(render, message) {
  return {
    ...message,
    ..."content" in message ? {
      content: isEmpty(message.content) ? void 0 : typeof message.content === "string" ? render(message.content) : message.content.map((c) => {
        switch (c.type) {
          case "text":
            return { ...c, text: render(c.text) };
          case "image_url":
            return {
              ...c,
              image_url: {
                ...c.image_url,
                url: render(c.image_url.url)
              }
            };
          default:
            const _exhaustiveCheck = c;
            return _exhaustiveCheck;
        }
      })
    } : {}
  };
}
var Prompt = class {
  constructor(metadata, defaults, noTrace) {
    this.metadata = metadata;
    this.defaults = defaults;
    this.noTrace = noTrace;
  }
  parsedPromptData;
  hasParsedPromptData = false;
  get id() {
    return this.metadata.id;
  }
  get projectId() {
    return this.metadata.project_id;
  }
  get name() {
    return "name" in this.metadata ? this.metadata.name : `Playground function ${this.metadata.id}`;
  }
  get slug() {
    return "slug" in this.metadata ? this.metadata.slug : this.metadata.id;
  }
  get prompt() {
    return this.getParsedPromptData()?.prompt;
  }
  get version() {
    return this.metadata[TRANSACTION_ID_FIELD];
  }
  get options() {
    return this.getParsedPromptData()?.options || {};
  }
  /**
   * Build the prompt with the given formatting options. The args you pass in will
   * be forwarded to the mustache template that defines the prompt and rendered with
   * the `mustache-js` library.
   *
   * @param buildArgs Args to forward along to the prompt template.
   */
  build(buildArgs, options = {}) {
    return this.runBuild(buildArgs, {
      flavor: options.flavor ?? "chat",
      messages: options.messages
    });
  }
  runBuild(buildArgs, options) {
    const { flavor } = options;
    const params = {
      ...this.defaults,
      ...Object.fromEntries(
        Object.entries(this.options.params || {}).filter(
          ([k, _v]) => !BRAINTRUST_PARAMS.includes(k)
        )
      ),
      ...!isEmpty(this.options.model) ? {
        model: this.options.model
      } : {}
    };
    if (!("model" in params) || isEmpty(params.model)) {
      throw new Error(
        "No model specified. Either specify it in the prompt or as a default"
      );
    }
    const spanInfo = this.noTrace ? {} : {
      span_info: {
        metadata: {
          prompt: this.id ? {
            variables: buildArgs,
            id: this.id,
            project_id: this.projectId,
            version: this.version,
            ..."prompt_session_id" in this.metadata ? { prompt_session_id: this.metadata.prompt_session_id } : {}
          } : void 0
        }
      }
    };
    const prompt = this.prompt;
    if (!prompt) {
      throw new Error("Empty prompt");
    }
    const dictArgParsed = z2.record(z2.unknown()).safeParse(buildArgs);
    const variables = {
      input: buildArgs,
      ...dictArgParsed.success ? dictArgParsed.data : {}
    };
    if (flavor === "chat") {
      if (prompt.type !== "chat") {
        throw new Error(
          "Prompt is a completion prompt. Use buildCompletion() instead"
        );
      }
      const render = (template) => Mustache.render(template, variables, void 0, {
        escape: (v) => typeof v === "string" ? v : JSON.stringify(v)
      });
      const messages = [
        ...(prompt.messages || []).map((m) => renderMessage(render, m)),
        ...options.messages ?? []
      ];
      return {
        ...params,
        ...spanInfo,
        messages,
        ...prompt.tools?.trim() ? {
          tools: toolsSchema.parse(
            JSON.parse(Mustache.render(prompt.tools, variables))
          )
        } : void 0
      };
    } else if (flavor === "completion") {
      if (prompt.type !== "completion") {
        throw new Error(`Prompt is a chat prompt. Use flavor: 'chat' instead`);
      }
      if (options.messages) {
        throw new Error(
          "extra messages are not supported for completion prompts"
        );
      }
      return {
        ...params,
        ...spanInfo,
        prompt: Mustache.render(prompt.content, variables)
      };
    } else {
      throw new Error("never!");
    }
  }
  getParsedPromptData() {
    if (!this.hasParsedPromptData) {
      this.parsedPromptData = promptDataSchema.parse(this.metadata.prompt_data);
      this.hasParsedPromptData = true;
    }
    return this.parsedPromptData;
  }
};
var _exportsForTestingOnly = { extractAttachments, deepCopyEvent };

// src/node.ts
function configureNode() {
  isomorph_default.getRepoInfo = getRepoInfo;
  isomorph_default.getPastNAncestors = getPastNAncestors;
  isomorph_default.getEnv = (name) => process.env[name];
  isomorph_default.getCallerLocation = getCallerLocation;
  isomorph_default.newAsyncLocalStorage = () => new AsyncLocalStorage();
  isomorph_default.processOn = (event, handler) => {
    process.on(event, handler);
  };
  isomorph_default.pathJoin = path.join;
  isomorph_default.pathDirname = path.dirname;
  isomorph_default.mkdir = fs.mkdir;
  isomorph_default.writeFile = fs.writeFile;
  isomorph_default.readFile = fs.readFile;
  _internalSetInitialState();
}

// src/exports-node.ts
var exports_node_exports = {};
__export(exports_node_exports, {
  Attachment: () => Attachment,
  BaseExperiment: () => BaseExperiment,
  BraintrustState: () => BraintrustState,
  BraintrustStream: () => BraintrustStream,
  CodeFunction: () => CodeFunction,
  CodePrompt: () => CodePrompt,
  Dataset: () => Dataset,
  Eval: () => Eval,
  Experiment: () => Experiment,
  FailedHTTPResponse: () => FailedHTTPResponse,
  LEGACY_CACHED_HEADER: () => LEGACY_CACHED_HEADER,
  LazyValue: () => LazyValue,
  Logger: () => Logger,
  NOOP_SPAN: () => NOOP_SPAN,
  NoopSpan: () => NoopSpan,
  Project: () => Project,
  Prompt: () => Prompt,
  PromptBuilder: () => PromptBuilder,
  ReadonlyExperiment: () => ReadonlyExperiment,
  Reporter: () => Reporter,
  SpanImpl: () => SpanImpl,
  ToolBuilder: () => ToolBuilder,
  X_CACHED_HEADER: () => X_CACHED_HEADER,
  _exportsForTestingOnly: () => _exportsForTestingOnly,
  _internalGetGlobalState: () => _internalGetGlobalState,
  _internalSetInitialState: () => _internalSetInitialState,
  braintrustStreamChunkSchema: () => braintrustStreamChunkSchema,
  buildLocalSummary: () => buildLocalSummary,
  createFinalValuePassThroughStream: () => createFinalValuePassThroughStream,
  currentExperiment: () => currentExperiment,
  currentLogger: () => currentLogger,
  currentSpan: () => currentSpan,
  devNullWritableStream: () => devNullWritableStream,
  flush: () => flush,
  getSpanParentObject: () => getSpanParentObject,
  init: () => init,
  initDataset: () => initDataset,
  initExperiment: () => initExperiment,
  initLogger: () => initLogger,
  invoke: () => invoke,
  loadPrompt: () => loadPrompt,
  log: () => log,
  logError: () => logError,
  login: () => login,
  loginToState: () => loginToState,
  newId: () => newId,
  parseCachedHeader: () => parseCachedHeader,
  permalink: () => permalink,
  projects: () => projects,
  renderMessage: () => renderMessage,
  reportFailures: () => reportFailures,
  setFetch: () => setFetch,
  spanComponentsToObjectId: () => spanComponentsToObjectId,
  startSpan: () => startSpan,
  summarize: () => summarize,
  toolFunctionDefinitionSchema: () => toolFunctionDefinitionSchema,
  traceable: () => traceable,
  traced: () => traced,
  updateSpan: () => updateSpan,
  withCurrent: () => withCurrent,
  withDataset: () => withDataset,
  withExperiment: () => withExperiment,
  withLogger: () => withLogger,
  wrapAISDKModel: () => wrapAISDKModel,
  wrapOpenAI: () => wrapOpenAI,
  wrapOpenAIv4: () => wrapOpenAIv4,
  wrapTraced: () => wrapTraced
});

// src/functions/invoke.ts
import {
  functionIdSchema
} from "@braintrust/core/typespecs";
async function invoke(args) {
  const {
    orgName,
    apiKey,
    appUrl,
    forceLogin,
    fetch: fetch2,
    input,
    messages,
    parent: parentArg,
    state: stateArg,
    stream,
    mode,
    schema,
    ...functionIdArgs
  } = args;
  const state = stateArg ?? _internalGetGlobalState();
  await state.login({
    orgName,
    apiKey,
    appUrl,
    forceLogin,
    fetch: fetch2
  });
  const parent = parentArg ? typeof parentArg === "string" ? parentArg : await parentArg.export() : await getSpanParentObject().export();
  const functionId = functionIdSchema.safeParse({
    project_name: functionIdArgs.projectName,
    slug: functionIdArgs.slug,
    global_function: functionIdArgs.globalFunction,
    prompt_session_id: functionIdArgs.promptSessionId,
    prompt_session_function_id: functionIdArgs.promptSessionFunctionId,
    version: functionIdArgs.version
  });
  if (!functionId.success) {
    throw new Error(
      `Invalid function ID arguments: ${functionId.error.message}`
    );
  }
  const request = {
    ...functionId.data,
    input,
    messages,
    parent,
    stream,
    mode
  };
  const resp = await state.proxyConn().post(`function/invoke`, request, {
    headers: {
      Accept: stream ? "text/event-stream" : "application/json"
    }
  });
  if (stream) {
    if (!resp.body) {
      throw new Error("Received empty stream body");
    }
    return new BraintrustStream(resp.body);
  } else {
    const data = await resp.json();
    return schema ? schema.parse(data) : data;
  }
}

// src/framework.ts
import chalk from "chalk";
import { SpanTypeAttribute as SpanTypeAttribute2, mergeDicts as mergeDicts2 } from "@braintrust/core";

// src/progress.ts
import * as cliProgress from "cli-progress";
var MAX_NAME_LENGTH = 40;
function fitNameToSpaces(name, length) {
  const padded = name.padEnd(length);
  if (padded.length <= length) {
    return padded;
  }
  return padded.substring(0, length - 3) + "...";
}
var BarProgressReporter = class {
  multiBar;
  bars = {};
  constructor() {
    this.multiBar = new cliProgress.MultiBar(
      {
        clearOnComplete: false,
        format: " {bar} | {evaluator} | {percentage}% | {value}/{total} datapoints",
        autopadding: true
      },
      cliProgress.Presets.shades_grey
    );
  }
  start(name, total) {
    const bar = this.multiBar.create(total, 0);
    this.bars[name] = bar;
  }
  stop() {
    this.multiBar.stop();
  }
  increment(name) {
    this.bars[name].increment({
      evaluator: fitNameToSpaces(name, MAX_NAME_LENGTH)
    });
  }
};

// src/framework.ts
import pluralize from "pluralize";

// ../../node_modules/.pnpm/async@3.2.5/node_modules/async/dist/async.mjs
function initialParams(fn) {
  return function(...args) {
    var callback = args.pop();
    return fn.call(this, args, callback);
  };
}
var hasQueueMicrotask = typeof queueMicrotask === "function" && queueMicrotask;
var hasSetImmediate = typeof setImmediate === "function" && setImmediate;
var hasNextTick = typeof process === "object" && typeof process.nextTick === "function";
function fallback(fn) {
  setTimeout(fn, 0);
}
function wrap(defer) {
  return (fn, ...args) => defer(() => fn(...args));
}
var _defer$1;
if (hasQueueMicrotask) {
  _defer$1 = queueMicrotask;
} else if (hasSetImmediate) {
  _defer$1 = setImmediate;
} else if (hasNextTick) {
  _defer$1 = process.nextTick;
} else {
  _defer$1 = fallback;
}
var setImmediate$1 = wrap(_defer$1);
function asyncify(func) {
  if (isAsync(func)) {
    return function(...args) {
      const callback = args.pop();
      const promise = func.apply(this, args);
      return handlePromise(promise, callback);
    };
  }
  return initialParams(function(args, callback) {
    var result;
    try {
      result = func.apply(this, args);
    } catch (e) {
      return callback(e);
    }
    if (result && typeof result.then === "function") {
      return handlePromise(result, callback);
    } else {
      callback(null, result);
    }
  });
}
function handlePromise(promise, callback) {
  return promise.then((value) => {
    invokeCallback(callback, null, value);
  }, (err) => {
    invokeCallback(callback, err && (err instanceof Error || err.message) ? err : new Error(err));
  });
}
function invokeCallback(callback, error2, value) {
  try {
    callback(error2, value);
  } catch (err) {
    setImmediate$1((e) => {
      throw e;
    }, err);
  }
}
function isAsync(fn) {
  return fn[Symbol.toStringTag] === "AsyncFunction";
}
function isAsyncGenerator(fn) {
  return fn[Symbol.toStringTag] === "AsyncGenerator";
}
function isAsyncIterable(obj) {
  return typeof obj[Symbol.asyncIterator] === "function";
}
function wrapAsync(asyncFn) {
  if (typeof asyncFn !== "function")
    throw new Error("expected a function");
  return isAsync(asyncFn) ? asyncify(asyncFn) : asyncFn;
}
function awaitify(asyncFn, arity) {
  if (!arity)
    arity = asyncFn.length;
  if (!arity)
    throw new Error("arity is undefined");
  function awaitable(...args) {
    if (typeof args[arity - 1] === "function") {
      return asyncFn.apply(this, args);
    }
    return new Promise((resolve, reject2) => {
      args[arity - 1] = (err, ...cbArgs) => {
        if (err)
          return reject2(err);
        resolve(cbArgs.length > 1 ? cbArgs : cbArgs[0]);
      };
      asyncFn.apply(this, args);
    });
  }
  return awaitable;
}
function applyEach$1(eachfn) {
  return function applyEach2(fns, ...callArgs) {
    const go = awaitify(function(callback) {
      var that = this;
      return eachfn(fns, (fn, cb) => {
        wrapAsync(fn).apply(that, callArgs.concat(cb));
      }, callback);
    });
    return go;
  };
}
function _asyncMap(eachfn, arr, iteratee, callback) {
  arr = arr || [];
  var results = [];
  var counter = 0;
  var _iteratee = wrapAsync(iteratee);
  return eachfn(arr, (value, _, iterCb) => {
    var index = counter++;
    _iteratee(value, (err, v) => {
      results[index] = v;
      iterCb(err);
    });
  }, (err) => {
    callback(err, results);
  });
}
function isArrayLike(value) {
  return value && typeof value.length === "number" && value.length >= 0 && value.length % 1 === 0;
}
var breakLoop = {};
var breakLoop$1 = breakLoop;
function once(fn) {
  function wrapper(...args) {
    if (fn === null)
      return;
    var callFn = fn;
    fn = null;
    callFn.apply(this, args);
  }
  Object.assign(wrapper, fn);
  return wrapper;
}
function getIterator(coll) {
  return coll[Symbol.iterator] && coll[Symbol.iterator]();
}
function createArrayIterator(coll) {
  var i = -1;
  var len = coll.length;
  return function next() {
    return ++i < len ? { value: coll[i], key: i } : null;
  };
}
function createES2015Iterator(iterator) {
  var i = -1;
  return function next() {
    var item = iterator.next();
    if (item.done)
      return null;
    i++;
    return { value: item.value, key: i };
  };
}
function createObjectIterator(obj) {
  var okeys = obj ? Object.keys(obj) : [];
  var i = -1;
  var len = okeys.length;
  return function next() {
    var key = okeys[++i];
    if (key === "__proto__") {
      return next();
    }
    return i < len ? { value: obj[key], key } : null;
  };
}
function createIterator(coll) {
  if (isArrayLike(coll)) {
    return createArrayIterator(coll);
  }
  var iterator = getIterator(coll);
  return iterator ? createES2015Iterator(iterator) : createObjectIterator(coll);
}
function onlyOnce(fn) {
  return function(...args) {
    if (fn === null)
      throw new Error("Callback was already called.");
    var callFn = fn;
    fn = null;
    callFn.apply(this, args);
  };
}
function asyncEachOfLimit(generator, limit, iteratee, callback) {
  let done = false;
  let canceled = false;
  let awaiting = false;
  let running = 0;
  let idx = 0;
  function replenish() {
    if (running >= limit || awaiting || done)
      return;
    awaiting = true;
    generator.next().then(({ value, done: iterDone }) => {
      if (canceled || done)
        return;
      awaiting = false;
      if (iterDone) {
        done = true;
        if (running <= 0) {
          callback(null);
        }
        return;
      }
      running++;
      iteratee(value, idx, iterateeCallback);
      idx++;
      replenish();
    }).catch(handleError);
  }
  function iterateeCallback(err, result) {
    running -= 1;
    if (canceled)
      return;
    if (err)
      return handleError(err);
    if (err === false) {
      done = true;
      canceled = true;
      return;
    }
    if (result === breakLoop$1 || done && running <= 0) {
      done = true;
      return callback(null);
    }
    replenish();
  }
  function handleError(err) {
    if (canceled)
      return;
    awaiting = false;
    done = true;
    callback(err);
  }
  replenish();
}
var eachOfLimit$2 = (limit) => {
  return (obj, iteratee, callback) => {
    callback = once(callback);
    if (limit <= 0) {
      throw new RangeError("concurrency limit cannot be less than 1");
    }
    if (!obj) {
      return callback(null);
    }
    if (isAsyncGenerator(obj)) {
      return asyncEachOfLimit(obj, limit, iteratee, callback);
    }
    if (isAsyncIterable(obj)) {
      return asyncEachOfLimit(obj[Symbol.asyncIterator](), limit, iteratee, callback);
    }
    var nextElem = createIterator(obj);
    var done = false;
    var canceled = false;
    var running = 0;
    var looping = false;
    function iterateeCallback(err, value) {
      if (canceled)
        return;
      running -= 1;
      if (err) {
        done = true;
        callback(err);
      } else if (err === false) {
        done = true;
        canceled = true;
      } else if (value === breakLoop$1 || done && running <= 0) {
        done = true;
        return callback(null);
      } else if (!looping) {
        replenish();
      }
    }
    function replenish() {
      looping = true;
      while (running < limit && !done) {
        var elem = nextElem();
        if (elem === null) {
          done = true;
          if (running <= 0) {
            callback(null);
          }
          return;
        }
        running += 1;
        iteratee(elem.value, elem.key, onlyOnce(iterateeCallback));
      }
      looping = false;
    }
    replenish();
  };
};
function eachOfLimit(coll, limit, iteratee, callback) {
  return eachOfLimit$2(limit)(coll, wrapAsync(iteratee), callback);
}
var eachOfLimit$1 = awaitify(eachOfLimit, 4);
function eachOfArrayLike(coll, iteratee, callback) {
  callback = once(callback);
  var index = 0, completed = 0, { length } = coll, canceled = false;
  if (length === 0) {
    callback(null);
  }
  function iteratorCallback(err, value) {
    if (err === false) {
      canceled = true;
    }
    if (canceled === true)
      return;
    if (err) {
      callback(err);
    } else if (++completed === length || value === breakLoop$1) {
      callback(null);
    }
  }
  for (; index < length; index++) {
    iteratee(coll[index], index, onlyOnce(iteratorCallback));
  }
}
function eachOfGeneric(coll, iteratee, callback) {
  return eachOfLimit$1(coll, Infinity, iteratee, callback);
}
function eachOf(coll, iteratee, callback) {
  var eachOfImplementation = isArrayLike(coll) ? eachOfArrayLike : eachOfGeneric;
  return eachOfImplementation(coll, wrapAsync(iteratee), callback);
}
var eachOf$1 = awaitify(eachOf, 3);
function map(coll, iteratee, callback) {
  return _asyncMap(eachOf$1, coll, iteratee, callback);
}
var map$1 = awaitify(map, 3);
var applyEach = applyEach$1(map$1);
function eachOfSeries(coll, iteratee, callback) {
  return eachOfLimit$1(coll, 1, iteratee, callback);
}
var eachOfSeries$1 = awaitify(eachOfSeries, 3);
function mapSeries(coll, iteratee, callback) {
  return _asyncMap(eachOfSeries$1, coll, iteratee, callback);
}
var mapSeries$1 = awaitify(mapSeries, 3);
var applyEachSeries = applyEach$1(mapSeries$1);
var PROMISE_SYMBOL = Symbol("promiseCallback");
var DLL = class {
  constructor() {
    this.head = this.tail = null;
    this.length = 0;
  }
  removeLink(node) {
    if (node.prev)
      node.prev.next = node.next;
    else
      this.head = node.next;
    if (node.next)
      node.next.prev = node.prev;
    else
      this.tail = node.prev;
    node.prev = node.next = null;
    this.length -= 1;
    return node;
  }
  empty() {
    while (this.head)
      this.shift();
    return this;
  }
  insertAfter(node, newNode) {
    newNode.prev = node;
    newNode.next = node.next;
    if (node.next)
      node.next.prev = newNode;
    else
      this.tail = newNode;
    node.next = newNode;
    this.length += 1;
  }
  insertBefore(node, newNode) {
    newNode.prev = node.prev;
    newNode.next = node;
    if (node.prev)
      node.prev.next = newNode;
    else
      this.head = newNode;
    node.prev = newNode;
    this.length += 1;
  }
  unshift(node) {
    if (this.head)
      this.insertBefore(this.head, node);
    else
      setInitial(this, node);
  }
  push(node) {
    if (this.tail)
      this.insertAfter(this.tail, node);
    else
      setInitial(this, node);
  }
  shift() {
    return this.head && this.removeLink(this.head);
  }
  pop() {
    return this.tail && this.removeLink(this.tail);
  }
  toArray() {
    return [...this];
  }
  *[Symbol.iterator]() {
    var cur = this.head;
    while (cur) {
      yield cur.data;
      cur = cur.next;
    }
  }
  remove(testFn) {
    var curr = this.head;
    while (curr) {
      var { next } = curr;
      if (testFn(curr)) {
        this.removeLink(curr);
      }
      curr = next;
    }
    return this;
  }
};
function setInitial(dll, node) {
  dll.length = 1;
  dll.head = dll.tail = node;
}
function queue$1(worker, concurrency, payload) {
  if (concurrency == null) {
    concurrency = 1;
  } else if (concurrency === 0) {
    throw new RangeError("Concurrency must not be zero");
  }
  var _worker = wrapAsync(worker);
  var numRunning = 0;
  var workersList = [];
  const events = {
    error: [],
    drain: [],
    saturated: [],
    unsaturated: [],
    empty: []
  };
  function on(event, handler) {
    events[event].push(handler);
  }
  function once2(event, handler) {
    const handleAndRemove = (...args) => {
      off(event, handleAndRemove);
      handler(...args);
    };
    events[event].push(handleAndRemove);
  }
  function off(event, handler) {
    if (!event)
      return Object.keys(events).forEach((ev) => events[ev] = []);
    if (!handler)
      return events[event] = [];
    events[event] = events[event].filter((ev) => ev !== handler);
  }
  function trigger(event, ...args) {
    events[event].forEach((handler) => handler(...args));
  }
  var processingScheduled = false;
  function _insert(data, insertAtFront, rejectOnError, callback) {
    if (callback != null && typeof callback !== "function") {
      throw new Error("task callback must be a function");
    }
    q.started = true;
    var res, rej;
    function promiseCallback(err, ...args) {
      if (err)
        return rejectOnError ? rej(err) : res();
      if (args.length <= 1)
        return res(args[0]);
      res(args);
    }
    var item = q._createTaskItem(
      data,
      rejectOnError ? promiseCallback : callback || promiseCallback
    );
    if (insertAtFront) {
      q._tasks.unshift(item);
    } else {
      q._tasks.push(item);
    }
    if (!processingScheduled) {
      processingScheduled = true;
      setImmediate$1(() => {
        processingScheduled = false;
        q.process();
      });
    }
    if (rejectOnError || !callback) {
      return new Promise((resolve, reject2) => {
        res = resolve;
        rej = reject2;
      });
    }
  }
  function _createCB(tasks) {
    return function(err, ...args) {
      numRunning -= 1;
      for (var i = 0, l = tasks.length; i < l; i++) {
        var task = tasks[i];
        var index = workersList.indexOf(task);
        if (index === 0) {
          workersList.shift();
        } else if (index > 0) {
          workersList.splice(index, 1);
        }
        task.callback(err, ...args);
        if (err != null) {
          trigger("error", err, task.data);
        }
      }
      if (numRunning <= q.concurrency - q.buffer) {
        trigger("unsaturated");
      }
      if (q.idle()) {
        trigger("drain");
      }
      q.process();
    };
  }
  function _maybeDrain(data) {
    if (data.length === 0 && q.idle()) {
      setImmediate$1(() => trigger("drain"));
      return true;
    }
    return false;
  }
  const eventMethod = (name) => (handler) => {
    if (!handler) {
      return new Promise((resolve, reject2) => {
        once2(name, (err, data) => {
          if (err)
            return reject2(err);
          resolve(data);
        });
      });
    }
    off(name);
    on(name, handler);
  };
  var isProcessing = false;
  var q = {
    _tasks: new DLL(),
    _createTaskItem(data, callback) {
      return {
        data,
        callback
      };
    },
    *[Symbol.iterator]() {
      yield* q._tasks[Symbol.iterator]();
    },
    concurrency,
    payload,
    buffer: concurrency / 4,
    started: false,
    paused: false,
    push(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, false, false, callback));
      }
      return _insert(data, false, false, callback);
    },
    pushAsync(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, false, true, callback));
      }
      return _insert(data, false, true, callback);
    },
    kill() {
      off();
      q._tasks.empty();
    },
    unshift(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, true, false, callback));
      }
      return _insert(data, true, false, callback);
    },
    unshiftAsync(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, true, true, callback));
      }
      return _insert(data, true, true, callback);
    },
    remove(testFn) {
      q._tasks.remove(testFn);
    },
    process() {
      if (isProcessing) {
        return;
      }
      isProcessing = true;
      while (!q.paused && numRunning < q.concurrency && q._tasks.length) {
        var tasks = [], data = [];
        var l = q._tasks.length;
        if (q.payload)
          l = Math.min(l, q.payload);
        for (var i = 0; i < l; i++) {
          var node = q._tasks.shift();
          tasks.push(node);
          workersList.push(node);
          data.push(node.data);
        }
        numRunning += 1;
        if (q._tasks.length === 0) {
          trigger("empty");
        }
        if (numRunning === q.concurrency) {
          trigger("saturated");
        }
        var cb = onlyOnce(_createCB(tasks));
        _worker(data, cb);
      }
      isProcessing = false;
    },
    length() {
      return q._tasks.length;
    },
    running() {
      return numRunning;
    },
    workersList() {
      return workersList;
    },
    idle() {
      return q._tasks.length + numRunning === 0;
    },
    pause() {
      q.paused = true;
    },
    resume() {
      if (q.paused === false) {
        return;
      }
      q.paused = false;
      setImmediate$1(q.process);
    }
  };
  Object.defineProperties(q, {
    saturated: {
      writable: false,
      value: eventMethod("saturated")
    },
    unsaturated: {
      writable: false,
      value: eventMethod("unsaturated")
    },
    empty: {
      writable: false,
      value: eventMethod("empty")
    },
    drain: {
      writable: false,
      value: eventMethod("drain")
    },
    error: {
      writable: false,
      value: eventMethod("error")
    }
  });
  return q;
}
function reduce(coll, memo, iteratee, callback) {
  callback = once(callback);
  var _iteratee = wrapAsync(iteratee);
  return eachOfSeries$1(coll, (x, i, iterCb) => {
    _iteratee(memo, x, (err, v) => {
      memo = v;
      iterCb(err);
    });
  }, (err) => callback(err, memo));
}
var reduce$1 = awaitify(reduce, 4);
function mapLimit(coll, limit, iteratee, callback) {
  return _asyncMap(eachOfLimit$2(limit), coll, iteratee, callback);
}
var mapLimit$1 = awaitify(mapLimit, 4);
function concatLimit(coll, limit, iteratee, callback) {
  var _iteratee = wrapAsync(iteratee);
  return mapLimit$1(coll, limit, (val, iterCb) => {
    _iteratee(val, (err, ...args) => {
      if (err)
        return iterCb(err);
      return iterCb(err, args);
    });
  }, (err, mapResults) => {
    var result = [];
    for (var i = 0; i < mapResults.length; i++) {
      if (mapResults[i]) {
        result = result.concat(...mapResults[i]);
      }
    }
    return callback(err, result);
  });
}
var concatLimit$1 = awaitify(concatLimit, 4);
function concat(coll, iteratee, callback) {
  return concatLimit$1(coll, Infinity, iteratee, callback);
}
var concat$1 = awaitify(concat, 3);
function concatSeries(coll, iteratee, callback) {
  return concatLimit$1(coll, 1, iteratee, callback);
}
var concatSeries$1 = awaitify(concatSeries, 3);
function _createTester(check, getResult) {
  return (eachfn, arr, _iteratee, cb) => {
    var testPassed = false;
    var testResult;
    const iteratee = wrapAsync(_iteratee);
    eachfn(arr, (value, _, callback) => {
      iteratee(value, (err, result) => {
        if (err || err === false)
          return callback(err);
        if (check(result) && !testResult) {
          testPassed = true;
          testResult = getResult(true, value);
          return callback(null, breakLoop$1);
        }
        callback();
      });
    }, (err) => {
      if (err)
        return cb(err);
      cb(null, testPassed ? testResult : getResult(false));
    });
  };
}
function detect(coll, iteratee, callback) {
  return _createTester((bool) => bool, (res, item) => item)(eachOf$1, coll, iteratee, callback);
}
var detect$1 = awaitify(detect, 3);
function detectLimit(coll, limit, iteratee, callback) {
  return _createTester((bool) => bool, (res, item) => item)(eachOfLimit$2(limit), coll, iteratee, callback);
}
var detectLimit$1 = awaitify(detectLimit, 4);
function detectSeries(coll, iteratee, callback) {
  return _createTester((bool) => bool, (res, item) => item)(eachOfLimit$2(1), coll, iteratee, callback);
}
var detectSeries$1 = awaitify(detectSeries, 3);
function consoleFunc(name) {
  return (fn, ...args) => wrapAsync(fn)(...args, (err, ...resultArgs) => {
    if (typeof console === "object") {
      if (err) {
        if (console.error) {
          console.error(err);
        }
      } else if (console[name]) {
        resultArgs.forEach((x) => console[name](x));
      }
    }
  });
}
var dir = consoleFunc("dir");
function doWhilst(iteratee, test, callback) {
  callback = onlyOnce(callback);
  var _fn = wrapAsync(iteratee);
  var _test = wrapAsync(test);
  var results;
  function next(err, ...args) {
    if (err)
      return callback(err);
    if (err === false)
      return;
    results = args;
    _test(...args, check);
  }
  function check(err, truth) {
    if (err)
      return callback(err);
    if (err === false)
      return;
    if (!truth)
      return callback(null, ...results);
    _fn(next);
  }
  return check(null, true);
}
var doWhilst$1 = awaitify(doWhilst, 3);
function _withoutIndex(iteratee) {
  return (value, index, callback) => iteratee(value, callback);
}
function eachLimit$2(coll, iteratee, callback) {
  return eachOf$1(coll, _withoutIndex(wrapAsync(iteratee)), callback);
}
var each = awaitify(eachLimit$2, 3);
function eachLimit(coll, limit, iteratee, callback) {
  return eachOfLimit$2(limit)(coll, _withoutIndex(wrapAsync(iteratee)), callback);
}
var eachLimit$1 = awaitify(eachLimit, 4);
function eachSeries(coll, iteratee, callback) {
  return eachLimit$1(coll, 1, iteratee, callback);
}
var eachSeries$1 = awaitify(eachSeries, 3);
function ensureAsync(fn) {
  if (isAsync(fn))
    return fn;
  return function(...args) {
    var callback = args.pop();
    var sync = true;
    args.push((...innerArgs) => {
      if (sync) {
        setImmediate$1(() => callback(...innerArgs));
      } else {
        callback(...innerArgs);
      }
    });
    fn.apply(this, args);
    sync = false;
  };
}
function every(coll, iteratee, callback) {
  return _createTester((bool) => !bool, (res) => !res)(eachOf$1, coll, iteratee, callback);
}
var every$1 = awaitify(every, 3);
function everyLimit(coll, limit, iteratee, callback) {
  return _createTester((bool) => !bool, (res) => !res)(eachOfLimit$2(limit), coll, iteratee, callback);
}
var everyLimit$1 = awaitify(everyLimit, 4);
function everySeries(coll, iteratee, callback) {
  return _createTester((bool) => !bool, (res) => !res)(eachOfSeries$1, coll, iteratee, callback);
}
var everySeries$1 = awaitify(everySeries, 3);
function filterArray(eachfn, arr, iteratee, callback) {
  var truthValues = new Array(arr.length);
  eachfn(arr, (x, index, iterCb) => {
    iteratee(x, (err, v) => {
      truthValues[index] = !!v;
      iterCb(err);
    });
  }, (err) => {
    if (err)
      return callback(err);
    var results = [];
    for (var i = 0; i < arr.length; i++) {
      if (truthValues[i])
        results.push(arr[i]);
    }
    callback(null, results);
  });
}
function filterGeneric(eachfn, coll, iteratee, callback) {
  var results = [];
  eachfn(coll, (x, index, iterCb) => {
    iteratee(x, (err, v) => {
      if (err)
        return iterCb(err);
      if (v) {
        results.push({ index, value: x });
      }
      iterCb(err);
    });
  }, (err) => {
    if (err)
      return callback(err);
    callback(null, results.sort((a, b) => a.index - b.index).map((v) => v.value));
  });
}
function _filter(eachfn, coll, iteratee, callback) {
  var filter2 = isArrayLike(coll) ? filterArray : filterGeneric;
  return filter2(eachfn, coll, wrapAsync(iteratee), callback);
}
function filter(coll, iteratee, callback) {
  return _filter(eachOf$1, coll, iteratee, callback);
}
var filter$1 = awaitify(filter, 3);
function filterLimit(coll, limit, iteratee, callback) {
  return _filter(eachOfLimit$2(limit), coll, iteratee, callback);
}
var filterLimit$1 = awaitify(filterLimit, 4);
function filterSeries(coll, iteratee, callback) {
  return _filter(eachOfSeries$1, coll, iteratee, callback);
}
var filterSeries$1 = awaitify(filterSeries, 3);
function forever(fn, errback) {
  var done = onlyOnce(errback);
  var task = wrapAsync(ensureAsync(fn));
  function next(err) {
    if (err)
      return done(err);
    if (err === false)
      return;
    task(next);
  }
  return next();
}
var forever$1 = awaitify(forever, 2);
function groupByLimit(coll, limit, iteratee, callback) {
  var _iteratee = wrapAsync(iteratee);
  return mapLimit$1(coll, limit, (val, iterCb) => {
    _iteratee(val, (err, key) => {
      if (err)
        return iterCb(err);
      return iterCb(err, { key, val });
    });
  }, (err, mapResults) => {
    var result = {};
    var { hasOwnProperty } = Object.prototype;
    for (var i = 0; i < mapResults.length; i++) {
      if (mapResults[i]) {
        var { key } = mapResults[i];
        var { val } = mapResults[i];
        if (hasOwnProperty.call(result, key)) {
          result[key].push(val);
        } else {
          result[key] = [val];
        }
      }
    }
    return callback(err, result);
  });
}
var groupByLimit$1 = awaitify(groupByLimit, 4);
var log2 = consoleFunc("log");
function mapValuesLimit(obj, limit, iteratee, callback) {
  callback = once(callback);
  var newObj = {};
  var _iteratee = wrapAsync(iteratee);
  return eachOfLimit$2(limit)(obj, (val, key, next) => {
    _iteratee(val, key, (err, result) => {
      if (err)
        return next(err);
      newObj[key] = result;
      next(err);
    });
  }, (err) => callback(err, newObj));
}
var mapValuesLimit$1 = awaitify(mapValuesLimit, 4);
var _defer;
if (hasNextTick) {
  _defer = process.nextTick;
} else if (hasSetImmediate) {
  _defer = setImmediate;
} else {
  _defer = fallback;
}
var nextTick = wrap(_defer);
var _parallel = awaitify((eachfn, tasks, callback) => {
  var results = isArrayLike(tasks) ? [] : {};
  eachfn(tasks, (task, key, taskCb) => {
    wrapAsync(task)((err, ...result) => {
      if (result.length < 2) {
        [result] = result;
      }
      results[key] = result;
      taskCb(err);
    });
  }, (err) => callback(err, results));
}, 3);
function queue(worker, concurrency) {
  var _worker = wrapAsync(worker);
  return queue$1((items, cb) => {
    _worker(items[0], cb);
  }, concurrency, 1);
}
function race(tasks, callback) {
  callback = once(callback);
  if (!Array.isArray(tasks))
    return callback(new TypeError("First argument to race must be an array of functions"));
  if (!tasks.length)
    return callback();
  for (var i = 0, l = tasks.length; i < l; i++) {
    wrapAsync(tasks[i])(callback);
  }
}
var race$1 = awaitify(race, 2);
function reject$2(eachfn, arr, _iteratee, callback) {
  const iteratee = wrapAsync(_iteratee);
  return _filter(eachfn, arr, (value, cb) => {
    iteratee(value, (err, v) => {
      cb(err, !v);
    });
  }, callback);
}
function reject(coll, iteratee, callback) {
  return reject$2(eachOf$1, coll, iteratee, callback);
}
var reject$1 = awaitify(reject, 3);
function rejectLimit(coll, limit, iteratee, callback) {
  return reject$2(eachOfLimit$2(limit), coll, iteratee, callback);
}
var rejectLimit$1 = awaitify(rejectLimit, 4);
function rejectSeries(coll, iteratee, callback) {
  return reject$2(eachOfSeries$1, coll, iteratee, callback);
}
var rejectSeries$1 = awaitify(rejectSeries, 3);
function some(coll, iteratee, callback) {
  return _createTester(Boolean, (res) => res)(eachOf$1, coll, iteratee, callback);
}
var some$1 = awaitify(some, 3);
function someLimit(coll, limit, iteratee, callback) {
  return _createTester(Boolean, (res) => res)(eachOfLimit$2(limit), coll, iteratee, callback);
}
var someLimit$1 = awaitify(someLimit, 4);
function someSeries(coll, iteratee, callback) {
  return _createTester(Boolean, (res) => res)(eachOfSeries$1, coll, iteratee, callback);
}
var someSeries$1 = awaitify(someSeries, 3);
function sortBy(coll, iteratee, callback) {
  var _iteratee = wrapAsync(iteratee);
  return map$1(coll, (x, iterCb) => {
    _iteratee(x, (err, criteria) => {
      if (err)
        return iterCb(err);
      iterCb(err, { value: x, criteria });
    });
  }, (err, results) => {
    if (err)
      return callback(err);
    callback(null, results.sort(comparator).map((v) => v.value));
  });
  function comparator(left, right) {
    var a = left.criteria, b = right.criteria;
    return a < b ? -1 : a > b ? 1 : 0;
  }
}
var sortBy$1 = awaitify(sortBy, 3);
function tryEach(tasks, callback) {
  var error2 = null;
  var result;
  return eachSeries$1(tasks, (task, taskCb) => {
    wrapAsync(task)((err, ...args) => {
      if (err === false)
        return taskCb(err);
      if (args.length < 2) {
        [result] = args;
      } else {
        result = args;
      }
      error2 = err;
      taskCb(err ? null : {});
    });
  }, () => callback(error2, result));
}
var tryEach$1 = awaitify(tryEach);
function whilst(test, iteratee, callback) {
  callback = onlyOnce(callback);
  var _fn = wrapAsync(iteratee);
  var _test = wrapAsync(test);
  var results = [];
  function next(err, ...rest) {
    if (err)
      return callback(err);
    results = rest;
    if (err === false)
      return;
    _test(check);
  }
  function check(err, truth) {
    if (err)
      return callback(err);
    if (err === false)
      return;
    if (!truth)
      return callback(null, ...results);
    _fn(next);
  }
  return _test(check);
}
var whilst$1 = awaitify(whilst, 3);
function waterfall(tasks, callback) {
  callback = once(callback);
  if (!Array.isArray(tasks))
    return callback(new Error("First argument to waterfall must be an array of functions"));
  if (!tasks.length)
    return callback();
  var taskIndex = 0;
  function nextTask(args) {
    var task = wrapAsync(tasks[taskIndex++]);
    task(...args, onlyOnce(next));
  }
  function next(err, ...args) {
    if (err === false)
      return;
    if (err || taskIndex === tasks.length) {
      return callback(err, ...args);
    }
    nextTask(args);
  }
  nextTask([]);
}
var waterfall$1 = awaitify(waterfall);

// src/framework.ts
function BaseExperiment(options = {}) {
  return { _type: "BaseExperiment", ...options };
}
var EvalResultWithSummary = class {
  constructor(summary, results) {
    this.summary = summary;
    this.results = results;
  }
  toString() {
    return formatExperimentSummary(this.summary);
  }
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `EvalResultWithSummary(summary="...", results=[...])`;
  }
  toJSON() {
    return {
      summary: this.summary,
      results: this.results
    };
  }
};
function makeEvalName(projectName, experimentName) {
  let out = projectName;
  if (experimentName) {
    out += ` [experimentName=${experimentName}]`;
  }
  return out;
}
function initExperiment2(state, options = {}) {
  return init({
    state,
    ...options,
    setCurrent: false
  });
}
function callEvaluatorData(data) {
  const dataResult = typeof data === "function" ? data() : data;
  let baseExperiment = void 0;
  if ("_type" in dataResult && dataResult._type === "BaseExperiment") {
    baseExperiment = dataResult.name;
  }
  return {
    data: dataResult,
    baseExperiment
  };
}
globalThis._evals = {
  functions: [],
  prompts: [],
  evaluators: {},
  reporters: {}
};
function _initializeSpanContext() {
  globalThis._spanContext = { currentSpan, withCurrent, startSpan, NOOP_SPAN };
}
async function Eval(name, evaluator, reporterOrOpts) {
  const options = isEmpty(reporterOrOpts) ? {} : typeof reporterOrOpts === "string" ? { reporter: reporterOrOpts } : "name" in reporterOrOpts ? { reporter: reporterOrOpts } : reporterOrOpts;
  let evalName = makeEvalName(name, evaluator.experimentName);
  if (globalThis._evals.evaluators[evalName]) {
    evalName = `${evalName}_${Object.keys(_evals).length}`;
  }
  if (globalThis._lazy_load) {
    globalThis._evals.evaluators[evalName] = {
      // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
      evaluator: {
        evalName,
        projectName: name,
        ...evaluator
      },
      reporter: options.reporter
    };
    _initializeSpanContext();
    return new EvalResultWithSummary(
      {
        scores: {},
        metrics: {},
        projectName: "",
        experimentName: ""
      },
      []
    );
  }
  const progressReporter = new BarProgressReporter();
  if (typeof options.reporter === "string") {
    throw new Error(
      "Must specify a reporter object, not a name. Can only specify reporter names when running 'braintrust eval'"
    );
  }
  const resolvedReporter = options.reporter || defaultReporter;
  try {
    const { data, baseExperiment: defaultBaseExperiment } = callEvaluatorData(
      evaluator.data
    );
    const experiment = initExperiment2(evaluator.state, {
      ...evaluator.projectId ? { projectId: evaluator.projectId } : { project: name },
      experiment: evaluator.experimentName,
      metadata: evaluator.metadata,
      isPublic: evaluator.isPublic,
      update: evaluator.update,
      baseExperiment: evaluator.baseExperimentName ?? defaultBaseExperiment,
      baseExperimentId: evaluator.baseExperimentId,
      gitMetadataSettings: evaluator.gitMetadataSettings,
      repoInfo: evaluator.repoInfo,
      dataset: data instanceof Dataset ? data : void 0
    });
    if (options.onStart) {
      experiment.summarize({ summarizeScores: false }).then(options.onStart);
    }
    try {
      const evalDef = {
        evalName,
        projectName: name,
        ...evaluator,
        data
      };
      const ret = await runEvaluator(experiment, evalDef, progressReporter, []);
      progressReporter.stop();
      resolvedReporter.reportEval(evalDef, ret, {
        verbose: true,
        jsonl: false
      });
      return ret;
    } finally {
      experiment.flush();
    }
  } finally {
    progressReporter.stop();
  }
}
function Reporter(name, reporter) {
  const ret = { name, ...reporter };
  if (_evals.reporters[name]) {
    throw new Error(`Reporter ${name} already exists`);
  }
  if (globalThis._lazy_load) {
    _evals.reporters[name] = ret;
  }
  return ret;
}
function serializeJSONWithPlainString(v) {
  if (typeof v === "string") {
    return v;
  } else {
    return JSON.stringify(v);
  }
}
function evaluateFilter(object, filter2) {
  const { path: path3, pattern } = filter2;
  const key = path3.reduce(
    (acc, p) => typeof acc === "object" && acc !== null ? (
      // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
      acc[p]
    ) : void 0,
    object
  );
  if (key === void 0) {
    return false;
  }
  return pattern.test(serializeJSONWithPlainString(key));
}
function scorerName(scorer, scorer_idx) {
  return scorer.name || `scorer_${scorer_idx}`;
}
async function runEvaluator(experiment, evaluator, progressReporter, filters) {
  const result = runEvaluatorInternal(
    experiment,
    evaluator,
    progressReporter,
    filters
  );
  const timer = async () => {
    await new Promise((_, reject2) => {
      if (evaluator.timeout) {
        setTimeout(() => {
          reject2("evaluator timed out");
        }, evaluator.timeout);
      }
    });
    return null;
  };
  const winner = await Promise.race([result, timer()]);
  if (!winner) {
    throw new Error("unreachable");
  }
  return winner;
}
async function runEvaluatorInternal(experiment, evaluator, progressReporter, filters) {
  if (typeof evaluator.data === "string") {
    throw new Error("Unimplemented: string data paths");
  }
  let dataResult = typeof evaluator.data === "function" ? evaluator.data() : evaluator.data;
  if ("_type" in dataResult) {
    if (dataResult._type !== "BaseExperiment") {
      throw new Error("Invalid _type");
    }
    if (!experiment) {
      throw new Error(
        "Cannot use BaseExperiment() without connecting to Braintrust (you most likely set --no-send-logs)"
      );
    }
    let name = dataResult.name;
    if (isEmpty(name)) {
      const baseExperiment = await experiment.fetchBaseExperiment();
      if (!baseExperiment) {
        throw new Error("BaseExperiment() failed to fetch base experiment");
      }
      name = baseExperiment.name;
    }
    dataResult = initExperiment2(evaluator.state, {
      ...evaluator.projectId ? { projectId: evaluator.projectId } : { project: evaluator.projectName },
      experiment: name,
      open: true
    }).asDataset();
  }
  let data = [];
  if (dataResult instanceof Promise) {
    data = await dataResult;
  } else if (Symbol.asyncIterator in dataResult) {
    data = [];
    for await (const d of dataResult) {
      data.push(d);
    }
  } else {
    data = dataResult;
  }
  data = data.filter((d) => filters.every((f) => evaluateFilter(d, f))).flatMap(
    (datum) => [...Array(evaluator.trialCount ?? 1).keys()].map(() => datum)
  );
  progressReporter.start(evaluator.evalName, data.length);
  const results = [];
  const q = queue(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    async (datum) => {
      const callback = async (rootSpan) => {
        let metadata = {
          ..."metadata" in datum ? datum.metadata : {}
        };
        let output = void 0;
        let error2 = void 0;
        const scores = {};
        try {
          const meta = (o) => metadata = { ...metadata, ...o };
          await rootSpan.traced(
            async (span) => {
              const outputResult = evaluator.task(datum.input, { meta, span });
              if (outputResult instanceof Promise) {
                output = await outputResult;
              } else {
                output = outputResult;
              }
              span.log({ output });
            },
            {
              name: "task",
              spanAttributes: { type: SpanTypeAttribute2.TASK },
              event: { input: datum.input }
            }
          );
          rootSpan.log({ output, metadata });
          const scoringArgs = {
            input: datum.input,
            expected: "expected" in datum ? datum.expected : void 0,
            metadata,
            output
          };
          const scorerNames = evaluator.scores.map(scorerName);
          const scoreResults = await Promise.all(
            evaluator.scores.map(async (score, score_idx) => {
              try {
                const results2 = await rootSpan.traced(
                  async (span) => {
                    const scoreResult = score(scoringArgs);
                    const scoreValue = scoreResult instanceof Promise ? await scoreResult : scoreResult;
                    if (scoreValue === null) {
                      return null;
                    }
                    if (Array.isArray(scoreValue)) {
                      for (const s of scoreValue) {
                        if (!(typeof s === "object" && !isEmpty(s))) {
                          throw new Error(
                            `When returning an array of scores, each score must be a non-empty object. Got: ${JSON.stringify(
                              s
                            )}`
                          );
                        }
                      }
                    }
                    const results3 = Array.isArray(scoreValue) ? scoreValue : typeof scoreValue === "object" && !isEmpty(scoreValue) ? [scoreValue] : [
                      {
                        name: scorerNames[score_idx],
                        score: scoreValue
                      }
                    ];
                    const getOtherFields = (s) => {
                      const { metadata: _metadata, name: _name, ...rest } = s;
                      return rest;
                    };
                    const resultMetadata = results3.length === 1 ? results3[0].metadata : results3.reduce(
                      (prev, s) => mergeDicts2(prev, {
                        [s.name]: s.metadata
                      }),
                      {}
                    );
                    const resultOutput = results3.length === 1 ? getOtherFields(results3[0]) : results3.reduce(
                      (prev, s) => mergeDicts2(prev, { [s.name]: getOtherFields(s) }),
                      {}
                    );
                    const scores2 = results3.reduce(
                      (prev, s) => mergeDicts2(prev, { [s.name]: s.score }),
                      {}
                    );
                    span.log({
                      output: resultOutput,
                      metadata: resultMetadata,
                      scores: scores2
                    });
                    return results3;
                  },
                  {
                    name: scorerNames[score_idx],
                    spanAttributes: {
                      type: SpanTypeAttribute2.SCORE
                    },
                    event: { input: scoringArgs }
                  }
                );
                return { kind: "score", value: results2 };
              } catch (e) {
                return { kind: "error", value: e };
              }
            })
          );
          const passingScorersAndResults = [];
          const failingScorersAndResults = [];
          scoreResults.forEach((results2, i) => {
            const name = scorerNames[i];
            if (results2.kind === "score") {
              (results2.value || []).forEach((result) => {
                passingScorersAndResults.push({
                  name: result.name,
                  score: result
                });
                scores[result.name] = result.score;
              });
            } else {
              failingScorersAndResults.push({ name, error: results2.value });
            }
          });
          if (failingScorersAndResults.length) {
            const scorerErrors = Object.fromEntries(
              failingScorersAndResults.map(({ name, error: error3 }) => [
                name,
                error3 instanceof Error ? error3.stack : `${error3}`
              ])
            );
            metadata["scorer_errors"] = scorerErrors;
            rootSpan.log({ metadata: { scorer_errors: scorerErrors } });
            const names = Object.keys(scorerErrors).join(", ");
            const errors = failingScorersAndResults.map((item) => item.error);
            throw new AggregateError(
              errors,
              `Found exceptions for the following scorers: ${names}`
            );
          }
        } catch (e) {
          logError(rootSpan, e);
          error2 = e;
        } finally {
          progressReporter.increment(evaluator.evalName);
        }
        results.push({
          input: datum.input,
          ..."expected" in datum ? { expected: datum.expected } : {},
          output,
          tags: datum.tags,
          metadata,
          scores,
          error: error2
        });
      };
      if (!experiment) {
        return await callback(NOOP_SPAN);
      } else {
        return await experiment.traced(callback, {
          name: "eval",
          spanAttributes: {
            type: SpanTypeAttribute2.EVAL
          },
          event: {
            input: datum.input,
            expected: "expected" in datum ? datum.expected : void 0,
            tags: datum.tags,
            origin: experiment.dataset && datum.id && datum._xact_id ? {
              object_type: "dataset",
              object_id: await experiment.dataset.id,
              id: datum.id,
              _xact_id: datum._xact_id
            } : void 0
          }
        });
      }
    },
    Math.max(evaluator.maxConcurrency ?? data.length, 1)
  );
  q.push(data);
  await q.drain();
  const summary = experiment ? await experiment.summarize() : buildLocalSummary(evaluator, results);
  return new EvalResultWithSummary(summary, results);
}
var error = chalk.bold.red;
var warning = chalk.hex("#FFA500");
function logError2(e, verbose) {
  if (!verbose) {
    console.error(`${e}`);
  } else {
    console.error(e);
  }
}
function buildLocalSummary(evaluator, results) {
  const scoresByName = {};
  for (const result of results) {
    for (const [name, score] of Object.entries(result.scores)) {
      const { total, count } = scoresByName[name] || { total: 0, count: 0 };
      if (score === null) {
        continue;
      }
      scoresByName[name] = { total: total + score, count: count + 1 };
    }
  }
  return {
    projectName: evaluator.projectName,
    experimentName: evaluator.evalName,
    scores: Object.fromEntries(
      Object.entries(scoresByName).map(([name, { total, count }]) => [
        name,
        {
          name,
          score: total / count,
          improvements: 0,
          regressions: 0
        }
      ])
    )
  };
}
function reportFailures(evaluator, failingResults, { verbose, jsonl }) {
  if (failingResults.length > 0) {
    console.error(
      warning(
        `Evaluator ${evaluator.evalName} failed with ${pluralize(
          "error",
          failingResults.length,
          true
        )}. This evaluation ("${evaluator.evalName}") will not be fully logged.`
      )
    );
    if (jsonl) {
      console.log(
        JSON.stringify({
          evaluatorName: evaluator.evalName,
          errors: failingResults.map(
            (r) => `${r.error instanceof Error ? r.error.stack : r.error}`
          )
        })
      );
    } else {
      for (const result of failingResults) {
        logError2(result.error, verbose);
      }
    }
    if (!verbose && !jsonl) {
      console.error(warning("Add --verbose to see full stack traces."));
    }
  }
}
var defaultReporter = {
  name: "Braintrust default reporter",
  async reportEval(evaluator, result, { verbose, jsonl }) {
    const { results, summary } = result;
    const failingResults = results.filter(
      (r) => r.error !== void 0
    );
    if (failingResults.length > 0) {
      reportFailures(evaluator, failingResults, { verbose, jsonl });
    }
    process.stdout.write(
      jsonl ? JSON.stringify(summary) : formatExperimentSummary(summary)
    );
    process.stdout.write("\n");
    return failingResults.length === 0;
  },
  async reportRun(evalReports) {
    return evalReports.every((r) => r);
  }
};
function formatExperimentSummary(summary) {
  let comparisonLine = "";
  if (summary.comparisonExperimentName) {
    comparisonLine = `${summary.experimentName} compared to ${summary.comparisonExperimentName}:
`;
  }
  const longestScoreName = Math.max(
    ...Object.values(summary.scores).map((score) => score.name.length)
  );
  const longestMetricName = Math.max(
    ...Object.values(summary.metrics ?? {}).map((metric) => metric.name.length)
  );
  return `
=========================SUMMARY=========================
${comparisonLine}` + Object.values(summary.scores).map((score) => formatScoreSummary(score, longestScoreName)).join("\n") + (Object.keys(summary.scores).length ? "\n\n" : "") + Object.values(summary.metrics ?? {}).map((metric) => formatMetricSummary(metric, longestMetricName)).join("\n") + (Object.keys(summary.metrics ?? {}).length ? "\n\n" : "") + (summary.experimentUrl ? `See results for ${summary.experimentName} at ${summary.experimentUrl}` : "");
}
function formatScoreSummary(summary, longestScoreName) {
  const diffString = isEmpty(summary.diff) ? "" : ` (${summary.diff > 0 ? "+" : ""}${(summary.diff * 100).toFixed(2)}%)`;
  const scoreName = `'${summary.name}'`.padEnd(longestScoreName + 2);
  return `${(summary.score * 100).toFixed(
    2
  )}%${diffString} ${scoreName} score	(${summary.improvements} improvements, ${summary.regressions} regressions)`;
}
function formatMetricSummary(summary, longestMetricName) {
  const fractionDigits = Number.isInteger(summary.metric) ? 0 : 2;
  const metricName = `'${summary.name}'`.padEnd(longestMetricName + 2);
  return `${summary.metric.toFixed(fractionDigits)}${summary.unit} ${metricName}	(${summary.improvements} improvements, ${summary.regressions} regressions)`;
}

// src/framework2.ts
import path2 from "path";
import slugifyLib from "slugify";
import { z as z3 } from "zod";
var ProjectBuilder = class {
  create(opts) {
    return new Project(opts);
  }
};
var projects = new ProjectBuilder();
var Project = class {
  name;
  id;
  tools;
  prompts;
  constructor(args) {
    _initializeSpanContext();
    this.name = "name" in args ? args.name : void 0;
    this.id = "id" in args ? args.id : void 0;
    this.tools = new ToolBuilder(this);
    this.prompts = new PromptBuilder(this);
  }
};
var ToolBuilder = class {
  constructor(project) {
    this.project = project;
  }
  taskCounter = 0;
  create(opts) {
    this.taskCounter++;
    opts = opts ?? {};
    const { handler, name, slug, ...rest } = opts;
    let resolvedName = name ?? handler.name;
    if (resolvedName.trim().length === 0) {
      resolvedName = `Tool ${path2.basename(__filename)} ${this.taskCounter}`;
    }
    const tool = new CodeFunction(
      this.project,
      {
        handler,
        name: resolvedName,
        slug: slug ?? slugifyLib(resolvedName, { lower: true, strict: true }),
        type: "tool",
        ...rest
      }
    );
    if (globalThis._lazy_load) {
      globalThis._evals.functions.push(
        tool
      );
    }
    return tool;
  }
};
var CodeFunction = class {
  constructor(project, opts) {
    this.project = project;
    this.handler = opts.handler;
    this.name = opts.name;
    this.slug = opts.slug;
    this.description = opts.description;
    this.type = opts.type;
    this.ifExists = opts.ifExists;
    this.parameters = opts.parameters;
    this.returns = opts.returns;
    if (this.returns && !this.parameters) {
      throw new Error("parameters are required if return type is defined");
    }
  }
  handler;
  name;
  slug;
  type;
  description;
  parameters;
  returns;
  ifExists;
  key() {
    return JSON.stringify([
      this.project.id ?? "",
      this.project.name ?? "",
      this.slug
    ]);
  }
};
var CodePrompt = class {
  project;
  name;
  slug;
  prompt;
  ifExists;
  description;
  id;
  toolFunctions;
  constructor(project, prompt, toolFunctions, opts) {
    this.project = project;
    this.name = opts.name;
    this.slug = opts.slug;
    this.prompt = prompt;
    this.toolFunctions = toolFunctions;
    this.ifExists = opts.ifExists;
    this.description = opts.description;
    this.id = opts.id;
  }
};
var toolFunctionDefinitionSchema = z3.object({
  type: z3.literal("function"),
  function: z3.object({
    name: z3.string(),
    description: z3.string().optional(),
    parameters: z3.record(z3.unknown()).optional(),
    strict: z3.boolean().optional()
  })
});
var PromptBuilder = class {
  constructor(project) {
    this.project = project;
  }
  create(opts) {
    const toolFunctions = [];
    const rawTools = [];
    for (const tool of opts.tools ?? []) {
      if (tool instanceof CodeFunction) {
        toolFunctions.push(tool);
      } else if ("type" in tool && !("function" in tool)) {
        toolFunctions.push(tool);
      } else {
        rawTools.push(tool);
      }
    }
    const promptBlock = "messages" in opts ? {
      type: "chat",
      messages: opts.messages,
      tools: rawTools && rawTools.length > 0 ? JSON.stringify(rawTools) : void 0
    } : {
      type: "completion",
      content: opts.prompt
    };
    const slug = opts.slug ?? slugifyLib(opts.name, { lower: true, strict: true });
    const promptData = {
      prompt: promptBlock,
      options: {
        model: opts.model,
        params: opts.params
      }
    };
    const promptRow = {
      id: opts.id,
      _xact_id: opts.version,
      name: opts.name,
      slug,
      prompt_data: promptData
    };
    const prompt = new Prompt(
      promptRow,
      {},
      // It doesn't make sense to specify defaults here.
      opts.noTrace ?? false
    );
    const codePrompt = new CodePrompt(this.project, promptData, toolFunctions, {
      ...opts,
      slug
    });
    if (globalThis._lazy_load) {
      globalThis._evals.prompts.push(codePrompt);
    }
    return prompt;
  }
};

// src/wrappers/oai.ts
import { SpanTypeAttribute as SpanTypeAttribute3 } from "@braintrust/core";
import { mergeDicts as mergeDicts3 } from "@braintrust/core";
function wrapOpenAI(openai) {
  if (openai?.chat?.completions?.create) {
    return wrapOpenAIv4(openai);
  } else {
    console.warn("Unsupported OpenAI library (potentially v3). Not wrapping.");
    return openai;
  }
}
globalThis.__inherited_braintrust_wrap_openai = wrapOpenAI;
function wrapOpenAIv4(openai) {
  let completionProxy = new Proxy(openai.chat.completions, {
    get(target, name, receiver) {
      const baseVal = Reflect.get(target, name, receiver);
      if (name === "create") {
        return wrapChatCompletion(baseVal.bind(target));
      }
      return baseVal;
    }
  });
  let chatProxy = new Proxy(openai.chat, {
    get(target, name, receiver) {
      if (name === "completions") {
        return completionProxy;
      }
      return Reflect.get(target, name, receiver);
    }
  });
  let embeddingProxy = new Proxy(openai.embeddings, {
    get(target, name, receiver) {
      const baseVal = Reflect.get(target, name, receiver);
      if (name === "create") {
        return wrapEmbeddings(baseVal.bind(target));
      }
      return baseVal;
    }
  });
  let betaProxy;
  if (openai.beta?.chat?.completions?.stream) {
    let betaChatCompletionProxy = new Proxy(openai?.beta?.chat.completions, {
      get(target, name, receiver) {
        const baseVal = Reflect.get(target, name, receiver);
        if (name === "parse") {
          return wrapBetaChatCompletionParse(baseVal.bind(target));
        } else if (name === "stream") {
          return wrapBetaChatCompletionStream(baseVal.bind(target));
        }
        return baseVal;
      }
    });
    let betaChatProxy = new Proxy(openai.beta.chat, {
      get(target, name, receiver) {
        if (name === "completions") {
          return betaChatCompletionProxy;
        }
        return Reflect.get(target, name, receiver);
      }
    });
    betaProxy = new Proxy(openai.beta, {
      get(target, name, receiver) {
        if (name === "chat") {
          return betaChatProxy;
        }
        return Reflect.get(target, name, receiver);
      }
    });
  }
  let proxy = new Proxy(openai, {
    get(target, name, receiver) {
      if (name === "chat") {
        return chatProxy;
      }
      if (name === "embeddings") {
        return embeddingProxy;
      }
      if (name === "beta" && betaProxy) {
        return betaProxy;
      }
      return Reflect.get(target, name, receiver);
    }
  });
  return proxy;
}
function logCompletionResponse(startTime, response, span) {
  span.log({
    output: response.choices,
    metrics: {
      time_to_first_token: getCurrentUnixTimestamp() - startTime,
      tokens: response.usage?.total_tokens,
      prompt_tokens: response.usage?.prompt_tokens,
      completion_tokens: response.usage?.completion_tokens
    }
  });
}
function wrapBetaChatCompletionParse(completion) {
  return async (allParams) => {
    const { span_info: _, ...params } = allParams;
    const span = startSpan(
      mergeDicts3(
        {
          name: "Chat Completion",
          spanAttributes: {
            type: SpanTypeAttribute3.LLM
          }
        },
        parseChatCompletionParams(allParams)
      )
    );
    const startTime = getCurrentUnixTimestamp();
    const ret = await completion(params);
    try {
      logCompletionResponse(startTime, ret, span);
      return ret;
    } finally {
      span.end();
    }
  };
}
function wrapBetaChatCompletionStream(completion) {
  return (allParams) => {
    const { span_info: _, ...params } = allParams;
    const span = startSpan(
      mergeDicts3(
        {
          name: "Chat Completion",
          spanAttributes: {
            type: SpanTypeAttribute3.LLM
          }
        },
        parseChatCompletionParams(allParams)
      )
    );
    const startTime = getCurrentUnixTimestamp();
    const ret = completion(params);
    let first = true;
    ret.on("chunk", (_chunk) => {
      if (first) {
        const now2 = getCurrentUnixTimestamp();
        span.log({
          metrics: {
            time_to_first_token: now2 - startTime
          }
        });
        first = false;
      }
    });
    ret.on("chatCompletion", (completion2) => {
      span.log({
        output: completion2.choices
      });
    });
    ret.on("end", () => {
      span.end();
    });
    return ret;
  };
}
var LEGACY_CACHED_HEADER = "x-cached";
var X_CACHED_HEADER = "x-bt-cached";
function parseCachedHeader(value) {
  return isEmpty(value) ? void 0 : ["true", "hit"].includes(value.toLowerCase()) ? 1 : 0;
}
function logHeaders(response, span) {
  const cachedHeader = response.headers.get(X_CACHED_HEADER);
  if (isEmpty(cachedHeader)) {
    const legacyCacheHeader = response.headers.get(LEGACY_CACHED_HEADER);
    if (!isEmpty(legacyCacheHeader)) {
      span.log({
        metrics: {
          cached: parseCachedHeader(legacyCacheHeader)
        }
      });
    }
  } else {
    span.log({
      metrics: {
        cached: parseCachedHeader(cachedHeader)
      }
    });
  }
}
function wrapChatCompletion(completion) {
  return async (allParams, options) => {
    const { span_info: _, ...params } = allParams;
    const span = startSpan(
      mergeDicts3(
        {
          name: "Chat Completion",
          spanAttributes: {
            type: SpanTypeAttribute3.LLM
          }
        },
        parseChatCompletionParams(allParams)
      )
    );
    const startTime = getCurrentUnixTimestamp();
    if (params.stream) {
      const { data: ret, response } = await completion(
        // We could get rid of this type coercion if we could somehow enforce
        // that `P extends ChatParams` BUT does not have the property
        // `span_info`.
        params,
        options
      ).withResponse();
      logHeaders(response, span);
      const wrapperStream = new WrapperStream(span, startTime, ret.iterator());
      ret.iterator = () => wrapperStream[Symbol.asyncIterator]();
      return ret;
    } else {
      try {
        const { data: ret, response } = await completion(
          params,
          options
        ).withResponse();
        logHeaders(response, span);
        const { messages, ...rest } = params;
        span.log({
          input: messages,
          metadata: {
            ...rest
          }
        });
        logCompletionResponse(startTime, ret, span);
        return ret;
      } finally {
        span.end();
      }
    }
  };
}
function parseChatCompletionParams(allParams) {
  const { span_info, ...params } = allParams;
  const { metadata: spanInfoMetadata, ...spanInfoRest } = span_info ?? {};
  let ret = {
    ...spanInfoRest,
    event: {
      metadata: spanInfoMetadata
    }
  };
  const { messages, ...paramsRest } = params;
  return mergeDicts3(ret, { event: { input: messages, metadata: paramsRest } });
}
function wrapEmbeddings(create) {
  return async (allParams, options) => {
    const { span_info: _, ...params } = allParams;
    return traced(
      async (span) => {
        const { data: result, response } = await create(
          params,
          options
        ).withResponse();
        logHeaders(response, span);
        const embedding_length = result.data[0].embedding.length;
        span.log({
          // TODO: Add a flag to control whether to log the full embedding vector,
          // possibly w/ JSON compression.
          output: { embedding_length },
          metrics: {
            tokens: result.usage?.total_tokens,
            prompt_tokens: result.usage?.prompt_tokens
          }
        });
        return result;
      },
      mergeDicts3(
        {
          name: "Embedding",
          spanAttributes: {
            type: SpanTypeAttribute3.LLM
          }
        },
        parseEmbeddingParams(allParams)
      )
    );
  };
}
function parseEmbeddingParams(allParams) {
  const { span_info, ...params } = allParams;
  const { metadata: spanInfoMetadata, ...spanInfoRest } = span_info ?? {};
  let ret = {
    ...spanInfoRest,
    event: {
      metadata: spanInfoMetadata
    }
  };
  const { input, ...paramsRest } = params;
  return mergeDicts3(ret, { event: { input, metadata: paramsRest } });
}
function postprocessStreamingResults(allResults) {
  let role = void 0;
  let content = void 0;
  let tool_calls = void 0;
  let finish_reason = void 0;
  let metrics = {};
  for (const result of allResults) {
    if (result.usage) {
      metrics = {
        ...metrics,
        tokens: result.usage.total_tokens,
        prompt_tokens: result.usage.prompt_tokens,
        completion_tokens: result.usage.completion_tokens
      };
    }
    const delta = result.choices?.[0]?.delta;
    if (!delta) {
      continue;
    }
    if (!role && delta.role) {
      role = delta.role;
    }
    if (delta.finish_reason) {
      finish_reason = delta.finish_reason;
    }
    if (delta.content) {
      content = (content || "") + delta.content;
    }
    if (delta.tool_calls) {
      if (!tool_calls) {
        tool_calls = [
          {
            id: delta.tool_calls[0].id,
            type: delta.tool_calls[0].type,
            function: delta.tool_calls[0].function
          }
        ];
      } else {
        tool_calls[0].function.arguments += delta.tool_calls[0].function.arguments;
      }
    }
  }
  return {
    metrics,
    output: [
      {
        index: 0,
        message: {
          role,
          content,
          tool_calls
        },
        logprobs: null,
        finish_reason
      }
    ]
  };
}
var WrapperStream = class {
  span;
  iter;
  startTime;
  constructor(span, startTime, iter) {
    this.span = span;
    this.iter = iter;
    this.startTime = startTime;
  }
  async *[Symbol.asyncIterator]() {
    let first = true;
    let allResults = [];
    try {
      for await (const item of this.iter) {
        if (first) {
          const now2 = getCurrentUnixTimestamp();
          this.span.log({
            metrics: {
              time_to_first_token: now2 - this.startTime
            }
          });
          first = false;
        }
        allResults.push(item);
        yield item;
      }
      this.span.log({
        ...postprocessStreamingResults(allResults)
      });
    } finally {
      this.span.end();
    }
  }
};

// src/wrappers/ai-sdk.ts
function wrapAISDKModel(model) {
  const m = model;
  if (m?.specificationVersion === "v1" && typeof m?.provider === "string" && typeof m?.modelId === "string") {
    return new BraintrustLanguageModelWrapper(m);
  } else {
    console.warn("Unsupported AI SDK model. Not wrapping.");
    return model;
  }
}
var BraintrustLanguageModelWrapper = class {
  constructor(model) {
    this.model = model;
  }
  get specificationVersion() {
    return this.model.specificationVersion;
  }
  get provider() {
    return this.model.provider;
  }
  get modelId() {
    return this.model.modelId;
  }
  get defaultObjectGenerationMode() {
    return this.model.defaultObjectGenerationMode;
  }
  // For the first cut, do not support custom span_info arguments. We can
  // propagate those via async local storage
  async doGenerate(options) {
    const span = startSpan({
      name: "Chat Completion",
      spanAttributes: {
        type: "llm"
      }
    });
    const { prompt, mode, ...rest } = options;
    const startTime = getCurrentUnixTimestamp();
    try {
      const ret = await this.model.doGenerate(options);
      span.log({
        input: prompt,
        metadata: {
          model: this.modelId,
          ...rest,
          ..."tools" in mode && mode.tools ? { tools: convertTools(mode.tools) } : "tool" in mode && mode.tool ? { tools: convertTools([mode.tool]) } : {}
        },
        output: postProcessOutput(ret.text, ret.toolCalls, ret.finishReason),
        metrics: {
          time_to_first_token: getCurrentUnixTimestamp() - startTime,
          tokens: !isEmpty(ret.usage) ? ret.usage.promptTokens + ret.usage.completionTokens : void 0,
          prompt_tokens: ret.usage?.promptTokens,
          completion_tokens: ret.usage?.completionTokens,
          cached: parseCachedHeader(
            ret.rawResponse?.headers?.[X_CACHED_HEADER] ?? ret.rawResponse?.headers?.[LEGACY_CACHED_HEADER]
          )
        }
      });
      return ret;
    } finally {
      span.end();
    }
  }
  async doStream(options) {
    const { prompt, mode, ...rest } = options;
    const startTime = getCurrentUnixTimestamp();
    const span = startSpan({
      name: "Chat Completion",
      spanAttributes: {
        type: "llm"
      }
    });
    span.log({
      input: prompt,
      metadata: {
        model: this.modelId,
        ...rest,
        ..."tools" in mode && mode.tools ? { tools: convertTools(mode.tools) } : "tool" in mode && mode.tool ? { tools: convertTools([mode.tool]) } : {}
      }
    });
    let ended = false;
    const end = () => {
      if (!ended) {
        span.end();
        ended = true;
      }
    };
    try {
      const ret = await this.model.doStream(options);
      let time_to_first_token = void 0;
      let usage = void 0;
      let fullText = void 0;
      const toolCalls = {};
      let finishReason = void 0;
      return {
        ...ret,
        stream: ret.stream.pipeThrough(
          new TransformStream({
            transform(chunk, controller) {
              if (time_to_first_token === void 0) {
                time_to_first_token = getCurrentUnixTimestamp() - startTime;
                span.log({ metrics: { time_to_first_token } });
              }
              switch (chunk.type) {
                case "text-delta":
                  if (fullText === void 0) {
                    fullText = "";
                  }
                  fullText += chunk.textDelta;
                  break;
                case "tool-call":
                  toolCalls[chunk.toolCallId] = {
                    toolCallType: chunk.toolCallType,
                    toolCallId: chunk.toolCallId,
                    toolName: chunk.toolName,
                    args: chunk.args
                  };
                  break;
                case "tool-call-delta":
                  if (toolCalls[chunk.toolCallId] === void 0) {
                    toolCalls[chunk.toolCallId] = {
                      toolCallType: chunk.toolCallType,
                      toolCallId: chunk.toolCallId,
                      toolName: chunk.toolName,
                      args: ""
                    };
                  }
                  toolCalls[chunk.toolCallId].args += chunk.argsTextDelta;
                  break;
                case "finish":
                  usage = chunk.usage;
                  finishReason = chunk.finishReason;
                  break;
              }
              controller.enqueue(chunk);
            },
            async flush(controller) {
              span.log({
                output: postProcessOutput(
                  fullText,
                  Object.keys(toolCalls).length > 0 ? Object.values(toolCalls) : void 0,
                  finishReason
                ),
                metrics: {
                  time_to_first_token: getCurrentUnixTimestamp() - startTime,
                  tokens: !isEmpty(usage) ? usage.promptTokens + usage.completionTokens : void 0,
                  prompt_tokens: usage?.promptTokens,
                  completion_tokens: usage?.completionTokens,
                  cached: parseCachedHeader(
                    ret.rawResponse?.headers?.[X_CACHED_HEADER] ?? ret.rawResponse?.headers?.[LEGACY_CACHED_HEADER]
                  )
                }
              });
              end();
              controller.terminate();
            }
          })
        )
      };
    } finally {
      end();
    }
  }
};
function convertTools(tools) {
  return tools.map((tool) => {
    const { type, ...rest } = tool;
    return {
      type: tool.type,
      function: rest
    };
  });
}
function postProcessOutput(text, tool_calls, finish_reason) {
  return {
    text,
    tool_calls,
    finish_reason
  };
}

// src/index.ts
configureNode();
var src_default = exports_node_exports;
export {
  Attachment,
  BaseExperiment,
  BraintrustState,
  BraintrustStream,
  CodeFunction,
  CodePrompt,
  Dataset,
  Eval,
  Experiment,
  FailedHTTPResponse,
  LEGACY_CACHED_HEADER,
  LazyValue,
  Logger,
  NOOP_SPAN,
  NoopSpan,
  Project,
  Prompt,
  PromptBuilder,
  ReadonlyExperiment,
  Reporter,
  SpanImpl,
  ToolBuilder,
  X_CACHED_HEADER,
  _exportsForTestingOnly,
  _internalGetGlobalState,
  _internalSetInitialState,
  braintrustStreamChunkSchema,
  buildLocalSummary,
  createFinalValuePassThroughStream,
  currentExperiment,
  currentLogger,
  currentSpan,
  src_default as default,
  devNullWritableStream,
  flush,
  getSpanParentObject,
  init,
  initDataset,
  initExperiment,
  initLogger,
  invoke,
  loadPrompt,
  log,
  logError,
  login,
  loginToState,
  newId,
  parseCachedHeader,
  permalink,
  projects,
  renderMessage,
  reportFailures,
  setFetch,
  spanComponentsToObjectId,
  startSpan,
  summarize,
  toolFunctionDefinitionSchema,
  traceable,
  traced,
  updateSpan,
  withCurrent,
  withDataset,
  withExperiment,
  withLogger,
  wrapAISDKModel,
  wrapOpenAI,
  wrapOpenAIv4,
  wrapTraced
};
