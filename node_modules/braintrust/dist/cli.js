#!/usr/bin/env node
"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __commonJS = (cb, mod) => function __require() {
  return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// ../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/providers/async.js
var require_async = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/providers/async.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.read = void 0;
    function read(path9, settings, callback) {
      settings.fs.lstat(path9, (lstatError, lstat) => {
        if (lstatError !== null) {
          callFailureCallback(callback, lstatError);
          return;
        }
        if (!lstat.isSymbolicLink() || !settings.followSymbolicLink) {
          callSuccessCallback(callback, lstat);
          return;
        }
        settings.fs.stat(path9, (statError, stat) => {
          if (statError !== null) {
            if (settings.throwErrorOnBrokenSymbolicLink) {
              callFailureCallback(callback, statError);
              return;
            }
            callSuccessCallback(callback, lstat);
            return;
          }
          if (settings.markSymbolicLink) {
            stat.isSymbolicLink = () => true;
          }
          callSuccessCallback(callback, stat);
        });
      });
    }
    exports2.read = read;
    function callFailureCallback(callback, error2) {
      callback(error2);
    }
    function callSuccessCallback(callback, result) {
      callback(null, result);
    }
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/providers/sync.js
var require_sync = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/providers/sync.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.read = void 0;
    function read(path9, settings) {
      const lstat = settings.fs.lstatSync(path9);
      if (!lstat.isSymbolicLink() || !settings.followSymbolicLink) {
        return lstat;
      }
      try {
        const stat = settings.fs.statSync(path9);
        if (settings.markSymbolicLink) {
          stat.isSymbolicLink = () => true;
        }
        return stat;
      } catch (error2) {
        if (!settings.throwErrorOnBrokenSymbolicLink) {
          return lstat;
        }
        throw error2;
      }
    }
    exports2.read = read;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/adapters/fs.js
var require_fs = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/adapters/fs.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.createFileSystemAdapter = exports2.FILE_SYSTEM_ADAPTER = void 0;
    var fs6 = require("fs");
    exports2.FILE_SYSTEM_ADAPTER = {
      lstat: fs6.lstat,
      stat: fs6.stat,
      lstatSync: fs6.lstatSync,
      statSync: fs6.statSync
    };
    function createFileSystemAdapter(fsMethods) {
      if (fsMethods === void 0) {
        return exports2.FILE_SYSTEM_ADAPTER;
      }
      return Object.assign(Object.assign({}, exports2.FILE_SYSTEM_ADAPTER), fsMethods);
    }
    exports2.createFileSystemAdapter = createFileSystemAdapter;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/settings.js
var require_settings = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/settings.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var fs6 = require_fs();
    var Settings = class {
      constructor(_options = {}) {
        this._options = _options;
        this.followSymbolicLink = this._getValue(this._options.followSymbolicLink, true);
        this.fs = fs6.createFileSystemAdapter(this._options.fs);
        this.markSymbolicLink = this._getValue(this._options.markSymbolicLink, false);
        this.throwErrorOnBrokenSymbolicLink = this._getValue(this._options.throwErrorOnBrokenSymbolicLink, true);
      }
      _getValue(option, value) {
        return option !== null && option !== void 0 ? option : value;
      }
    };
    exports2.default = Settings;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/index.js
var require_out = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.stat@2.0.5/node_modules/@nodelib/fs.stat/out/index.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.statSync = exports2.stat = exports2.Settings = void 0;
    var async = require_async();
    var sync = require_sync();
    var settings_1 = require_settings();
    exports2.Settings = settings_1.default;
    function stat(path9, optionsOrSettingsOrCallback, callback) {
      if (typeof optionsOrSettingsOrCallback === "function") {
        async.read(path9, getSettings(), optionsOrSettingsOrCallback);
        return;
      }
      async.read(path9, getSettings(optionsOrSettingsOrCallback), callback);
    }
    exports2.stat = stat;
    function statSync(path9, optionsOrSettings) {
      const settings = getSettings(optionsOrSettings);
      return sync.read(path9, settings);
    }
    exports2.statSync = statSync;
    function getSettings(settingsOrOptions = {}) {
      if (settingsOrOptions instanceof settings_1.default) {
        return settingsOrOptions;
      }
      return new settings_1.default(settingsOrOptions);
    }
  }
});

// ../../node_modules/.pnpm/queue-microtask@1.2.3/node_modules/queue-microtask/index.js
var require_queue_microtask = __commonJS({
  "../../node_modules/.pnpm/queue-microtask@1.2.3/node_modules/queue-microtask/index.js"(exports2, module2) {
    "use strict";
    var promise;
    module2.exports = typeof queueMicrotask === "function" ? queueMicrotask.bind(typeof window !== "undefined" ? window : global) : (cb) => (promise || (promise = Promise.resolve())).then(cb).catch((err) => setTimeout(() => {
      throw err;
    }, 0));
  }
});

// ../../node_modules/.pnpm/run-parallel@1.2.0/node_modules/run-parallel/index.js
var require_run_parallel = __commonJS({
  "../../node_modules/.pnpm/run-parallel@1.2.0/node_modules/run-parallel/index.js"(exports2, module2) {
    "use strict";
    module2.exports = runParallel;
    var queueMicrotask2 = require_queue_microtask();
    function runParallel(tasks, cb) {
      let results, pending, keys;
      let isSync = true;
      if (Array.isArray(tasks)) {
        results = [];
        pending = tasks.length;
      } else {
        keys = Object.keys(tasks);
        results = {};
        pending = keys.length;
      }
      function done(err) {
        function end() {
          if (cb)
            cb(err, results);
          cb = null;
        }
        if (isSync)
          queueMicrotask2(end);
        else
          end();
      }
      function each2(i, err, result) {
        results[i] = result;
        if (--pending === 0 || err) {
          done(err);
        }
      }
      if (!pending) {
        done(null);
      } else if (keys) {
        keys.forEach(function(key) {
          tasks[key](function(err, result) {
            each2(key, err, result);
          });
        });
      } else {
        tasks.forEach(function(task, i) {
          task(function(err, result) {
            each2(i, err, result);
          });
        });
      }
      isSync = false;
    }
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/constants.js
var require_constants = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/constants.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.IS_SUPPORT_READDIR_WITH_FILE_TYPES = void 0;
    var NODE_PROCESS_VERSION_PARTS = process.versions.node.split(".");
    if (NODE_PROCESS_VERSION_PARTS[0] === void 0 || NODE_PROCESS_VERSION_PARTS[1] === void 0) {
      throw new Error(`Unexpected behavior. The 'process.versions.node' variable has invalid value: ${process.versions.node}`);
    }
    var MAJOR_VERSION = Number.parseInt(NODE_PROCESS_VERSION_PARTS[0], 10);
    var MINOR_VERSION = Number.parseInt(NODE_PROCESS_VERSION_PARTS[1], 10);
    var SUPPORTED_MAJOR_VERSION = 10;
    var SUPPORTED_MINOR_VERSION = 10;
    var IS_MATCHED_BY_MAJOR = MAJOR_VERSION > SUPPORTED_MAJOR_VERSION;
    var IS_MATCHED_BY_MAJOR_AND_MINOR = MAJOR_VERSION === SUPPORTED_MAJOR_VERSION && MINOR_VERSION >= SUPPORTED_MINOR_VERSION;
    exports2.IS_SUPPORT_READDIR_WITH_FILE_TYPES = IS_MATCHED_BY_MAJOR || IS_MATCHED_BY_MAJOR_AND_MINOR;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/utils/fs.js
var require_fs2 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/utils/fs.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.createDirentFromStats = void 0;
    var DirentFromStats = class {
      constructor(name, stats) {
        this.name = name;
        this.isBlockDevice = stats.isBlockDevice.bind(stats);
        this.isCharacterDevice = stats.isCharacterDevice.bind(stats);
        this.isDirectory = stats.isDirectory.bind(stats);
        this.isFIFO = stats.isFIFO.bind(stats);
        this.isFile = stats.isFile.bind(stats);
        this.isSocket = stats.isSocket.bind(stats);
        this.isSymbolicLink = stats.isSymbolicLink.bind(stats);
      }
    };
    function createDirentFromStats(name, stats) {
      return new DirentFromStats(name, stats);
    }
    exports2.createDirentFromStats = createDirentFromStats;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/utils/index.js
var require_utils = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/utils/index.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.fs = void 0;
    var fs6 = require_fs2();
    exports2.fs = fs6;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/providers/common.js
var require_common = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/providers/common.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.joinPathSegments = void 0;
    function joinPathSegments(a, b, separator) {
      if (a.endsWith(separator)) {
        return a + b;
      }
      return a + separator + b;
    }
    exports2.joinPathSegments = joinPathSegments;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/providers/async.js
var require_async2 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/providers/async.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.readdir = exports2.readdirWithFileTypes = exports2.read = void 0;
    var fsStat = require_out();
    var rpl = require_run_parallel();
    var constants_1 = require_constants();
    var utils = require_utils();
    var common = require_common();
    function read(directory, settings, callback) {
      if (!settings.stats && constants_1.IS_SUPPORT_READDIR_WITH_FILE_TYPES) {
        readdirWithFileTypes(directory, settings, callback);
        return;
      }
      readdir(directory, settings, callback);
    }
    exports2.read = read;
    function readdirWithFileTypes(directory, settings, callback) {
      settings.fs.readdir(directory, { withFileTypes: true }, (readdirError, dirents) => {
        if (readdirError !== null) {
          callFailureCallback(callback, readdirError);
          return;
        }
        const entries = dirents.map((dirent) => ({
          dirent,
          name: dirent.name,
          path: common.joinPathSegments(directory, dirent.name, settings.pathSegmentSeparator)
        }));
        if (!settings.followSymbolicLinks) {
          callSuccessCallback(callback, entries);
          return;
        }
        const tasks = entries.map((entry) => makeRplTaskEntry(entry, settings));
        rpl(tasks, (rplError, rplEntries) => {
          if (rplError !== null) {
            callFailureCallback(callback, rplError);
            return;
          }
          callSuccessCallback(callback, rplEntries);
        });
      });
    }
    exports2.readdirWithFileTypes = readdirWithFileTypes;
    function makeRplTaskEntry(entry, settings) {
      return (done) => {
        if (!entry.dirent.isSymbolicLink()) {
          done(null, entry);
          return;
        }
        settings.fs.stat(entry.path, (statError, stats) => {
          if (statError !== null) {
            if (settings.throwErrorOnBrokenSymbolicLink) {
              done(statError);
              return;
            }
            done(null, entry);
            return;
          }
          entry.dirent = utils.fs.createDirentFromStats(entry.name, stats);
          done(null, entry);
        });
      };
    }
    function readdir(directory, settings, callback) {
      settings.fs.readdir(directory, (readdirError, names) => {
        if (readdirError !== null) {
          callFailureCallback(callback, readdirError);
          return;
        }
        const tasks = names.map((name) => {
          const path9 = common.joinPathSegments(directory, name, settings.pathSegmentSeparator);
          return (done) => {
            fsStat.stat(path9, settings.fsStatSettings, (error2, stats) => {
              if (error2 !== null) {
                done(error2);
                return;
              }
              const entry = {
                name,
                path: path9,
                dirent: utils.fs.createDirentFromStats(name, stats)
              };
              if (settings.stats) {
                entry.stats = stats;
              }
              done(null, entry);
            });
          };
        });
        rpl(tasks, (rplError, entries) => {
          if (rplError !== null) {
            callFailureCallback(callback, rplError);
            return;
          }
          callSuccessCallback(callback, entries);
        });
      });
    }
    exports2.readdir = readdir;
    function callFailureCallback(callback, error2) {
      callback(error2);
    }
    function callSuccessCallback(callback, result) {
      callback(null, result);
    }
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/providers/sync.js
var require_sync2 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/providers/sync.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.readdir = exports2.readdirWithFileTypes = exports2.read = void 0;
    var fsStat = require_out();
    var constants_1 = require_constants();
    var utils = require_utils();
    var common = require_common();
    function read(directory, settings) {
      if (!settings.stats && constants_1.IS_SUPPORT_READDIR_WITH_FILE_TYPES) {
        return readdirWithFileTypes(directory, settings);
      }
      return readdir(directory, settings);
    }
    exports2.read = read;
    function readdirWithFileTypes(directory, settings) {
      const dirents = settings.fs.readdirSync(directory, { withFileTypes: true });
      return dirents.map((dirent) => {
        const entry = {
          dirent,
          name: dirent.name,
          path: common.joinPathSegments(directory, dirent.name, settings.pathSegmentSeparator)
        };
        if (entry.dirent.isSymbolicLink() && settings.followSymbolicLinks) {
          try {
            const stats = settings.fs.statSync(entry.path);
            entry.dirent = utils.fs.createDirentFromStats(entry.name, stats);
          } catch (error2) {
            if (settings.throwErrorOnBrokenSymbolicLink) {
              throw error2;
            }
          }
        }
        return entry;
      });
    }
    exports2.readdirWithFileTypes = readdirWithFileTypes;
    function readdir(directory, settings) {
      const names = settings.fs.readdirSync(directory);
      return names.map((name) => {
        const entryPath = common.joinPathSegments(directory, name, settings.pathSegmentSeparator);
        const stats = fsStat.statSync(entryPath, settings.fsStatSettings);
        const entry = {
          name,
          path: entryPath,
          dirent: utils.fs.createDirentFromStats(name, stats)
        };
        if (settings.stats) {
          entry.stats = stats;
        }
        return entry;
      });
    }
    exports2.readdir = readdir;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/adapters/fs.js
var require_fs3 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/adapters/fs.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.createFileSystemAdapter = exports2.FILE_SYSTEM_ADAPTER = void 0;
    var fs6 = require("fs");
    exports2.FILE_SYSTEM_ADAPTER = {
      lstat: fs6.lstat,
      stat: fs6.stat,
      lstatSync: fs6.lstatSync,
      statSync: fs6.statSync,
      readdir: fs6.readdir,
      readdirSync: fs6.readdirSync
    };
    function createFileSystemAdapter(fsMethods) {
      if (fsMethods === void 0) {
        return exports2.FILE_SYSTEM_ADAPTER;
      }
      return Object.assign(Object.assign({}, exports2.FILE_SYSTEM_ADAPTER), fsMethods);
    }
    exports2.createFileSystemAdapter = createFileSystemAdapter;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/settings.js
var require_settings2 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/settings.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var path9 = require("path");
    var fsStat = require_out();
    var fs6 = require_fs3();
    var Settings = class {
      constructor(_options = {}) {
        this._options = _options;
        this.followSymbolicLinks = this._getValue(this._options.followSymbolicLinks, false);
        this.fs = fs6.createFileSystemAdapter(this._options.fs);
        this.pathSegmentSeparator = this._getValue(this._options.pathSegmentSeparator, path9.sep);
        this.stats = this._getValue(this._options.stats, false);
        this.throwErrorOnBrokenSymbolicLink = this._getValue(this._options.throwErrorOnBrokenSymbolicLink, true);
        this.fsStatSettings = new fsStat.Settings({
          followSymbolicLink: this.followSymbolicLinks,
          fs: this.fs,
          throwErrorOnBrokenSymbolicLink: this.throwErrorOnBrokenSymbolicLink
        });
      }
      _getValue(option, value) {
        return option !== null && option !== void 0 ? option : value;
      }
    };
    exports2.default = Settings;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/index.js
var require_out2 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.scandir@2.1.5/node_modules/@nodelib/fs.scandir/out/index.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.Settings = exports2.scandirSync = exports2.scandir = void 0;
    var async = require_async2();
    var sync = require_sync2();
    var settings_1 = require_settings2();
    exports2.Settings = settings_1.default;
    function scandir(path9, optionsOrSettingsOrCallback, callback) {
      if (typeof optionsOrSettingsOrCallback === "function") {
        async.read(path9, getSettings(), optionsOrSettingsOrCallback);
        return;
      }
      async.read(path9, getSettings(optionsOrSettingsOrCallback), callback);
    }
    exports2.scandir = scandir;
    function scandirSync(path9, optionsOrSettings) {
      const settings = getSettings(optionsOrSettings);
      return sync.read(path9, settings);
    }
    exports2.scandirSync = scandirSync;
    function getSettings(settingsOrOptions = {}) {
      if (settingsOrOptions instanceof settings_1.default) {
        return settingsOrOptions;
      }
      return new settings_1.default(settingsOrOptions);
    }
  }
});

// ../../node_modules/.pnpm/reusify@1.0.4/node_modules/reusify/reusify.js
var require_reusify = __commonJS({
  "../../node_modules/.pnpm/reusify@1.0.4/node_modules/reusify/reusify.js"(exports2, module2) {
    "use strict";
    function reusify(Constructor) {
      var head = new Constructor();
      var tail = head;
      function get() {
        var current = head;
        if (current.next) {
          head = current.next;
        } else {
          head = new Constructor();
          tail = head;
        }
        current.next = null;
        return current;
      }
      function release(obj) {
        tail.next = obj;
        tail = obj;
      }
      return {
        get,
        release
      };
    }
    module2.exports = reusify;
  }
});

// ../../node_modules/.pnpm/fastq@1.16.0/node_modules/fastq/queue.js
var require_queue = __commonJS({
  "../../node_modules/.pnpm/fastq@1.16.0/node_modules/fastq/queue.js"(exports2, module2) {
    "use strict";
    var reusify = require_reusify();
    function fastqueue(context2, worker, concurrency) {
      if (typeof context2 === "function") {
        concurrency = worker;
        worker = context2;
        context2 = null;
      }
      if (concurrency < 1) {
        throw new Error("fastqueue concurrency must be greater than 1");
      }
      var cache = reusify(Task);
      var queueHead = null;
      var queueTail = null;
      var _running = 0;
      var errorHandler = null;
      var self = {
        push,
        drain: noop,
        saturated: noop,
        pause,
        paused: false,
        concurrency,
        running,
        resume,
        idle,
        length,
        getQueue,
        unshift,
        empty: noop,
        kill,
        killAndDrain,
        error: error2
      };
      return self;
      function running() {
        return _running;
      }
      function pause() {
        self.paused = true;
      }
      function length() {
        var current = queueHead;
        var counter = 0;
        while (current) {
          current = current.next;
          counter++;
        }
        return counter;
      }
      function getQueue() {
        var current = queueHead;
        var tasks = [];
        while (current) {
          tasks.push(current.value);
          current = current.next;
        }
        return tasks;
      }
      function resume() {
        if (!self.paused)
          return;
        self.paused = false;
        for (var i = 0; i < self.concurrency; i++) {
          _running++;
          release();
        }
      }
      function idle() {
        return _running === 0 && self.length() === 0;
      }
      function push(value, done) {
        var current = cache.get();
        current.context = context2;
        current.release = release;
        current.value = value;
        current.callback = done || noop;
        current.errorHandler = errorHandler;
        if (_running === self.concurrency || self.paused) {
          if (queueTail) {
            queueTail.next = current;
            queueTail = current;
          } else {
            queueHead = current;
            queueTail = current;
            self.saturated();
          }
        } else {
          _running++;
          worker.call(context2, current.value, current.worked);
        }
      }
      function unshift(value, done) {
        var current = cache.get();
        current.context = context2;
        current.release = release;
        current.value = value;
        current.callback = done || noop;
        current.errorHandler = errorHandler;
        if (_running === self.concurrency || self.paused) {
          if (queueHead) {
            current.next = queueHead;
            queueHead = current;
          } else {
            queueHead = current;
            queueTail = current;
            self.saturated();
          }
        } else {
          _running++;
          worker.call(context2, current.value, current.worked);
        }
      }
      function release(holder) {
        if (holder) {
          cache.release(holder);
        }
        var next = queueHead;
        if (next) {
          if (!self.paused) {
            if (queueTail === queueHead) {
              queueTail = null;
            }
            queueHead = next.next;
            next.next = null;
            worker.call(context2, next.value, next.worked);
            if (queueTail === null) {
              self.empty();
            }
          } else {
            _running--;
          }
        } else if (--_running === 0) {
          self.drain();
        }
      }
      function kill() {
        queueHead = null;
        queueTail = null;
        self.drain = noop;
      }
      function killAndDrain() {
        queueHead = null;
        queueTail = null;
        self.drain();
        self.drain = noop;
      }
      function error2(handler) {
        errorHandler = handler;
      }
    }
    function noop() {
    }
    function Task() {
      this.value = null;
      this.callback = noop;
      this.next = null;
      this.release = noop;
      this.context = null;
      this.errorHandler = null;
      var self = this;
      this.worked = function worked(err, result) {
        var callback = self.callback;
        var errorHandler = self.errorHandler;
        var val = self.value;
        self.value = null;
        self.callback = noop;
        if (self.errorHandler) {
          errorHandler(err, val);
        }
        callback.call(self.context, err, result);
        self.release(self);
      };
    }
    function queueAsPromised(context2, worker, concurrency) {
      if (typeof context2 === "function") {
        concurrency = worker;
        worker = context2;
        context2 = null;
      }
      function asyncWrapper(arg, cb) {
        worker.call(this, arg).then(function(res) {
          cb(null, res);
        }, cb);
      }
      var queue2 = fastqueue(context2, asyncWrapper, concurrency);
      var pushCb = queue2.push;
      var unshiftCb = queue2.unshift;
      queue2.push = push;
      queue2.unshift = unshift;
      queue2.drained = drained;
      return queue2;
      function push(value) {
        var p = new Promise(function(resolve2, reject2) {
          pushCb(value, function(err, result) {
            if (err) {
              reject2(err);
              return;
            }
            resolve2(result);
          });
        });
        p.catch(noop);
        return p;
      }
      function unshift(value) {
        var p = new Promise(function(resolve2, reject2) {
          unshiftCb(value, function(err, result) {
            if (err) {
              reject2(err);
              return;
            }
            resolve2(result);
          });
        });
        p.catch(noop);
        return p;
      }
      function drained() {
        if (queue2.idle()) {
          return new Promise(function(resolve2) {
            resolve2();
          });
        }
        var previousDrain = queue2.drain;
        var p = new Promise(function(resolve2) {
          queue2.drain = function() {
            previousDrain();
            resolve2();
          };
        });
        return p;
      }
    }
    module2.exports = fastqueue;
    module2.exports.promise = queueAsPromised;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/common.js
var require_common2 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/common.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.joinPathSegments = exports2.replacePathSegmentSeparator = exports2.isAppliedFilter = exports2.isFatalError = void 0;
    function isFatalError(settings, error2) {
      if (settings.errorFilter === null) {
        return true;
      }
      return !settings.errorFilter(error2);
    }
    exports2.isFatalError = isFatalError;
    function isAppliedFilter(filter2, value) {
      return filter2 === null || filter2(value);
    }
    exports2.isAppliedFilter = isAppliedFilter;
    function replacePathSegmentSeparator(filepath, separator) {
      return filepath.split(/[/\\]/).join(separator);
    }
    exports2.replacePathSegmentSeparator = replacePathSegmentSeparator;
    function joinPathSegments(a, b, separator) {
      if (a === "") {
        return b;
      }
      if (a.endsWith(separator)) {
        return a + b;
      }
      return a + separator + b;
    }
    exports2.joinPathSegments = joinPathSegments;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/reader.js
var require_reader = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/reader.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var common = require_common2();
    var Reader = class {
      constructor(_root, _settings) {
        this._root = _root;
        this._settings = _settings;
        this._root = common.replacePathSegmentSeparator(_root, _settings.pathSegmentSeparator);
      }
    };
    exports2.default = Reader;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/async.js
var require_async3 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/async.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var events_1 = require("events");
    var fsScandir = require_out2();
    var fastq = require_queue();
    var common = require_common2();
    var reader_1 = require_reader();
    var AsyncReader = class extends reader_1.default {
      constructor(_root, _settings) {
        super(_root, _settings);
        this._settings = _settings;
        this._scandir = fsScandir.scandir;
        this._emitter = new events_1.EventEmitter();
        this._queue = fastq(this._worker.bind(this), this._settings.concurrency);
        this._isFatalError = false;
        this._isDestroyed = false;
        this._queue.drain = () => {
          if (!this._isFatalError) {
            this._emitter.emit("end");
          }
        };
      }
      read() {
        this._isFatalError = false;
        this._isDestroyed = false;
        setImmediate(() => {
          this._pushToQueue(this._root, this._settings.basePath);
        });
        return this._emitter;
      }
      get isDestroyed() {
        return this._isDestroyed;
      }
      destroy() {
        if (this._isDestroyed) {
          throw new Error("The reader is already destroyed");
        }
        this._isDestroyed = true;
        this._queue.killAndDrain();
      }
      onEntry(callback) {
        this._emitter.on("entry", callback);
      }
      onError(callback) {
        this._emitter.once("error", callback);
      }
      onEnd(callback) {
        this._emitter.once("end", callback);
      }
      _pushToQueue(directory, base) {
        const queueItem = { directory, base };
        this._queue.push(queueItem, (error2) => {
          if (error2 !== null) {
            this._handleError(error2);
          }
        });
      }
      _worker(item, done) {
        this._scandir(item.directory, this._settings.fsScandirSettings, (error2, entries) => {
          if (error2 !== null) {
            done(error2, void 0);
            return;
          }
          for (const entry of entries) {
            this._handleEntry(entry, item.base);
          }
          done(null, void 0);
        });
      }
      _handleError(error2) {
        if (this._isDestroyed || !common.isFatalError(this._settings, error2)) {
          return;
        }
        this._isFatalError = true;
        this._isDestroyed = true;
        this._emitter.emit("error", error2);
      }
      _handleEntry(entry, base) {
        if (this._isDestroyed || this._isFatalError) {
          return;
        }
        const fullpath = entry.path;
        if (base !== void 0) {
          entry.path = common.joinPathSegments(base, entry.name, this._settings.pathSegmentSeparator);
        }
        if (common.isAppliedFilter(this._settings.entryFilter, entry)) {
          this._emitEntry(entry);
        }
        if (entry.dirent.isDirectory() && common.isAppliedFilter(this._settings.deepFilter, entry)) {
          this._pushToQueue(fullpath, base === void 0 ? void 0 : entry.path);
        }
      }
      _emitEntry(entry) {
        this._emitter.emit("entry", entry);
      }
    };
    exports2.default = AsyncReader;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/providers/async.js
var require_async4 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/providers/async.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var async_1 = require_async3();
    var AsyncProvider = class {
      constructor(_root, _settings) {
        this._root = _root;
        this._settings = _settings;
        this._reader = new async_1.default(this._root, this._settings);
        this._storage = [];
      }
      read(callback) {
        this._reader.onError((error2) => {
          callFailureCallback(callback, error2);
        });
        this._reader.onEntry((entry) => {
          this._storage.push(entry);
        });
        this._reader.onEnd(() => {
          callSuccessCallback(callback, this._storage);
        });
        this._reader.read();
      }
    };
    exports2.default = AsyncProvider;
    function callFailureCallback(callback, error2) {
      callback(error2);
    }
    function callSuccessCallback(callback, entries) {
      callback(null, entries);
    }
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/providers/stream.js
var require_stream = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/providers/stream.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var stream_1 = require("stream");
    var async_1 = require_async3();
    var StreamProvider = class {
      constructor(_root, _settings) {
        this._root = _root;
        this._settings = _settings;
        this._reader = new async_1.default(this._root, this._settings);
        this._stream = new stream_1.Readable({
          objectMode: true,
          read: () => {
          },
          destroy: () => {
            if (!this._reader.isDestroyed) {
              this._reader.destroy();
            }
          }
        });
      }
      read() {
        this._reader.onError((error2) => {
          this._stream.emit("error", error2);
        });
        this._reader.onEntry((entry) => {
          this._stream.push(entry);
        });
        this._reader.onEnd(() => {
          this._stream.push(null);
        });
        this._reader.read();
        return this._stream;
      }
    };
    exports2.default = StreamProvider;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/sync.js
var require_sync3 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/readers/sync.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var fsScandir = require_out2();
    var common = require_common2();
    var reader_1 = require_reader();
    var SyncReader = class extends reader_1.default {
      constructor() {
        super(...arguments);
        this._scandir = fsScandir.scandirSync;
        this._storage = [];
        this._queue = /* @__PURE__ */ new Set();
      }
      read() {
        this._pushToQueue(this._root, this._settings.basePath);
        this._handleQueue();
        return this._storage;
      }
      _pushToQueue(directory, base) {
        this._queue.add({ directory, base });
      }
      _handleQueue() {
        for (const item of this._queue.values()) {
          this._handleDirectory(item.directory, item.base);
        }
      }
      _handleDirectory(directory, base) {
        try {
          const entries = this._scandir(directory, this._settings.fsScandirSettings);
          for (const entry of entries) {
            this._handleEntry(entry, base);
          }
        } catch (error2) {
          this._handleError(error2);
        }
      }
      _handleError(error2) {
        if (!common.isFatalError(this._settings, error2)) {
          return;
        }
        throw error2;
      }
      _handleEntry(entry, base) {
        const fullpath = entry.path;
        if (base !== void 0) {
          entry.path = common.joinPathSegments(base, entry.name, this._settings.pathSegmentSeparator);
        }
        if (common.isAppliedFilter(this._settings.entryFilter, entry)) {
          this._pushToStorage(entry);
        }
        if (entry.dirent.isDirectory() && common.isAppliedFilter(this._settings.deepFilter, entry)) {
          this._pushToQueue(fullpath, base === void 0 ? void 0 : entry.path);
        }
      }
      _pushToStorage(entry) {
        this._storage.push(entry);
      }
    };
    exports2.default = SyncReader;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/providers/sync.js
var require_sync4 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/providers/sync.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var sync_1 = require_sync3();
    var SyncProvider = class {
      constructor(_root, _settings) {
        this._root = _root;
        this._settings = _settings;
        this._reader = new sync_1.default(this._root, this._settings);
      }
      read() {
        return this._reader.read();
      }
    };
    exports2.default = SyncProvider;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/settings.js
var require_settings3 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/settings.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    var path9 = require("path");
    var fsScandir = require_out2();
    var Settings = class {
      constructor(_options = {}) {
        this._options = _options;
        this.basePath = this._getValue(this._options.basePath, void 0);
        this.concurrency = this._getValue(this._options.concurrency, Number.POSITIVE_INFINITY);
        this.deepFilter = this._getValue(this._options.deepFilter, null);
        this.entryFilter = this._getValue(this._options.entryFilter, null);
        this.errorFilter = this._getValue(this._options.errorFilter, null);
        this.pathSegmentSeparator = this._getValue(this._options.pathSegmentSeparator, path9.sep);
        this.fsScandirSettings = new fsScandir.Settings({
          followSymbolicLinks: this._options.followSymbolicLinks,
          fs: this._options.fs,
          pathSegmentSeparator: this._options.pathSegmentSeparator,
          stats: this._options.stats,
          throwErrorOnBrokenSymbolicLink: this._options.throwErrorOnBrokenSymbolicLink
        });
      }
      _getValue(option, value) {
        return option !== null && option !== void 0 ? option : value;
      }
    };
    exports2.default = Settings;
  }
});

// ../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/index.js
var require_out3 = __commonJS({
  "../../node_modules/.pnpm/@nodelib+fs.walk@1.2.8/node_modules/@nodelib/fs.walk/out/index.js"(exports2) {
    "use strict";
    Object.defineProperty(exports2, "__esModule", { value: true });
    exports2.Settings = exports2.walkStream = exports2.walkSync = exports2.walk = void 0;
    var async_1 = require_async4();
    var stream_1 = require_stream();
    var sync_1 = require_sync4();
    var settings_1 = require_settings3();
    exports2.Settings = settings_1.default;
    function walk2(directory, optionsOrSettingsOrCallback, callback) {
      if (typeof optionsOrSettingsOrCallback === "function") {
        new async_1.default(directory, getSettings()).read(optionsOrSettingsOrCallback);
        return;
      }
      new async_1.default(directory, getSettings(optionsOrSettingsOrCallback)).read(callback);
    }
    exports2.walk = walk2;
    function walkSync(directory, optionsOrSettings) {
      const settings = getSettings(optionsOrSettings);
      const provider = new sync_1.default(directory, settings);
      return provider.read();
    }
    exports2.walkSync = walkSync;
    function walkStream(directory, optionsOrSettings) {
      const settings = getSettings(optionsOrSettings);
      const provider = new stream_1.default(directory, settings);
      return provider.read();
    }
    exports2.walkStream = walkStream;
    function getSettings(settingsOrOptions = {}) {
      if (settingsOrOptions instanceof settings_1.default) {
        return settingsOrOptions;
      }
      return new settings_1.default(settingsOrOptions);
    }
  }
});

// package.json
var require_package = __commonJS({
  "package.json"(exports2, module2) {
    module2.exports = {
      name: "braintrust",
      version: "0.0.171",
      description: "SDK for integrating Braintrust",
      repository: {
        type: "git",
        url: "git+https://github.com/braintrustdata/braintrust-sdk.git",
        directory: "blob/main/js"
      },
      homepage: "https://www.braintrust.dev/docs",
      main: "./dist/index.js",
      module: "./dist/index.mjs",
      types: "./dist/index.d.ts",
      browser: {
        "./dist/index.js": "./dist/browser.js",
        "./dist/index.d.ts": "./dist/browser.d.ts",
        "./dist/index.mjs": "./dist/browser.mjs",
        "./dist/index.d.mts": "./dist/browser.d.mts"
      },
      bin: {
        braintrust: "./dist/cli.js"
      },
      exports: {
        "./package.json": "./package.json",
        ".": {
          types: "./dist/index.d.ts",
          import: "./dist/index.mjs",
          module: "./dist/index.mjs",
          require: "./dist/index.js"
        },
        "./browser": {
          import: "./dist/browser.mjs",
          module: "./dist/browser.mjs",
          require: "./dist/browser.js"
        },
        "./ai-sdk": {
          types: "./ai-sdk/dist/index.d.ts",
          import: "./ai-sdk/dist/index.mjs",
          module: "./ai-sdk/dist/index.mjs",
          require: "./ai-sdk/dist/index.js"
        }
      },
      scripts: {
        build: "tsup",
        watch: "tsup --watch",
        clean: "rm -r dist/*",
        docs: "npx typedoc --options typedoc.json src/index.ts",
        test: "vitest run",
        prepublishOnly: "../../scripts/node_prepublish_sdk.py",
        postpublish: "../../scripts/node_postpublish_sdk.py"
      },
      author: "",
      license: "MIT",
      devDependencies: {
        "@jest/globals": "^29.7.0",
        "@nodelib/fs.walk": "^1.2.8",
        "@types/argparse": "^2.0.14",
        "@types/async": "^3.2.24",
        "@types/cli-progress": "^3.11.5",
        "@types/graceful-fs": "^4.1.9",
        "@types/mustache": "^4.2.5",
        "@types/node": "^20.10.5",
        "@types/pluralize": "^0.0.30",
        "@types/uuid": "^9.0.7",
        async: "^3.2.5",
        autoevals: "^0.0.69",
        "npm-run-all": "^4.1.5",
        "ts-jest": "^29.1.4",
        tsup: "^8.0.1",
        typedoc: "^0.25.4",
        "typedoc-plugin-markdown": "^3.17.1",
        typescript: "^5.3.3",
        "vite-tsconfig-paths": "^4.3.2",
        vitest: "^1.6.0"
      },
      dependencies: {
        "@ai-sdk/provider": "^0.0.11",
        "@braintrust/core": "0.0.67",
        "@next/env": "^14.2.3",
        "@vercel/functions": "^1.0.2",
        ai: "^3.2.16",
        argparse: "^2.0.1",
        chalk: "^4.1.2",
        "cli-progress": "^3.12.0",
        dotenv: "^16.4.5",
        esbuild: "^0.18.20",
        "eventsource-parser": "^1.1.2",
        "graceful-fs": "^4.2.11",
        minimatch: "^9.0.3",
        mustache: "^4.2.0",
        pluralize: "^8.0.0",
        "simple-git": "^3.21.0",
        slugify: "^1.6.6",
        "source-map": "^0.7.4",
        uuid: "^9.0.1",
        zod: "^3.22.4",
        "zod-to-json-schema": "^3.22.5"
      },
      peerDependencies: {
        zod: "^3.0.0"
      }
    };
  }
});

// src/cli.ts
var cli_exports = {};
__export(cli_exports, {
  handleBuildFailure: () => handleBuildFailure,
  initializeHandles: () => initializeHandles
});
module.exports = __toCommonJS(cli_exports);
var esbuild = __toESM(require("esbuild"));
var dotenv2 = __toESM(require("dotenv"));
var import_fs2 = __toESM(require("fs"));
var import_os = __toESM(require("os"));
var import_path6 = __toESM(require("path"));
var import_util5 = __toESM(require("util"));
var fsWalk = __toESM(require_out3());
var import_minimatch = require("minimatch");
var import_argparse = require("argparse");
var import_uuid2 = require("uuid");
var import_pluralize4 = __toESM(require("pluralize"));

// src/logger.ts
var import_uuid = require("uuid");
var import_core = require("@braintrust/core");
var import_typespecs2 = require("@braintrust/core/typespecs");

// src/isomorph.ts
var DefaultAsyncLocalStorage = class {
  constructor() {
  }
  enterWith(_) {
  }
  run(_, callback) {
    return callback();
  }
  getStore() {
    return void 0;
  }
};
var iso = {
  getRepoInfo: async (_settings) => void 0,
  getPastNAncestors: async () => [],
  getEnv: (_name) => void 0,
  getCallerLocation: () => void 0,
  newAsyncLocalStorage: () => new DefaultAsyncLocalStorage(),
  processOn: (_0, _1) => {
  }
};
var isomorph_default = iso;

// src/util.ts
var GLOBAL_PROJECT = "Global";
function runCatchFinally(f, catchF, finallyF) {
  let runSyncCleanup = true;
  try {
    const ret = f();
    if (ret instanceof Promise) {
      runSyncCleanup = false;
      return ret.catch(catchF).finally(finallyF);
    } else {
      return ret;
    }
  } catch (e) {
    return catchF(e);
  } finally {
    if (runSyncCleanup) {
      finallyF();
    }
  }
}
function getCurrentUnixTimestamp() {
  return (/* @__PURE__ */ new Date()).getTime() / 1e3;
}
function isEmpty(a) {
  return a === void 0 || a === null;
}
var LazyValue = class {
  callable;
  value = {
    hasComputed: false
  };
  constructor(callable) {
    this.callable = callable;
  }
  get() {
    if (this.value.hasComputed) {
      return this.value.val;
    }
    this.value = { hasComputed: true, val: this.callable() };
    return this.value.val;
  }
  get hasComputed() {
    return this.value.hasComputed;
  }
};

// src/logger.ts
var import_mustache = __toESM(require("mustache"));
var import_zod2 = require("zod");

// src/functions/stream.ts
var import_typespecs = require("@braintrust/core/typespecs");
var import_eventsource_parser = require("eventsource-parser");
var import_zod = require("zod");
var braintrustStreamChunkSchema = import_zod.z.union([
  import_zod.z.object({
    type: import_zod.z.literal("text_delta"),
    data: import_zod.z.string()
  }),
  import_zod.z.object({
    type: import_zod.z.literal("json_delta"),
    data: import_zod.z.string()
  }),
  import_zod.z.object({
    type: import_zod.z.literal("error"),
    data: import_zod.z.string()
  }),
  import_zod.z.object({
    type: import_zod.z.literal("console"),
    data: import_typespecs.sseConsoleEventDataSchema
  }),
  import_zod.z.object({
    type: import_zod.z.literal("progress"),
    data: import_typespecs.sseProgressEventDataSchema
  }),
  import_zod.z.object({
    type: import_zod.z.literal("start"),
    data: import_zod.z.string()
  }),
  import_zod.z.object({
    type: import_zod.z.literal("done"),
    data: import_zod.z.string()
  })
]);
var BraintrustStream = class _BraintrustStream {
  stream;
  memoizedFinalValue;
  constructor(baseStream) {
    this.stream = baseStream.pipeThrough(btStreamParser());
  }
  /**
   * Copy the stream. This returns a new stream that shares the same underlying
   * stream (via `tee`). Since streams are consumed in Javascript, use `copy()` if you
   * need to use the stream multiple times.
   *
   * @returns A new stream that you can independently consume.
   */
  copy() {
    const [newStream, copyStream] = this.stream.tee();
    this.stream = copyStream;
    return new _BraintrustStream(newStream);
  }
  /**
   * Get the underlying ReadableStream.
   *
   * @returns The underlying ReadableStream<BraintrustStreamChunk>.
   */
  toReadableStream() {
    return this.stream;
  }
  /**
   * Returns an async iterator for the BraintrustStream.
   * This allows for easy consumption of the stream using a for-await...of loop.
   *
   * @returns An async iterator that yields BraintrustStreamChunk objects.
   */
  [Symbol.asyncIterator]() {
    const reader = this.stream.getReader();
    return {
      async next() {
        const { done, value } = await reader.read();
        if (done) {
          reader.releaseLock();
          return { done: true, value: void 0 };
        }
        return { done: false, value };
      },
      async return() {
        reader.releaseLock();
        return { done: true, value: void 0 };
      },
      async throw(error2) {
        reader.releaseLock();
        throw error2;
      }
    };
  }
  /**
   * Get the final value of the stream. The final value is the concatenation of all
   * the chunks in the stream, deserialized into a string or JSON object, depending on
   * the value's type.
   *
   * This function returns a promise that resolves when the stream is closed, and
   * contains the final value. Multiple calls to `finalValue()` will return the same
   * promise, so it is safe to call this multiple times.
   *
   * This function consumes the stream, so if you need to use the stream multiple
   * times, you should call `copy()` first.
   *
   * @returns A promise that resolves with the final value of the stream or `undefined` if the stream is empty.
   */
  finalValue() {
    if (this.memoizedFinalValue) {
      return this.memoizedFinalValue;
    }
    this.memoizedFinalValue = new Promise((resolve2, reject2) => {
      this.stream.pipeThrough(createFinalValuePassThroughStream(resolve2, reject2)).pipeTo(devNullWritableStream());
    });
    return this.memoizedFinalValue;
  }
};
function btStreamParser() {
  const decoder = new TextDecoder();
  let parser;
  return new TransformStream({
    async start(controller) {
      parser = (0, import_eventsource_parser.createParser)((event) => {
        if (event.type === "reconnect-interval") {
          return;
        }
        const parsed = import_typespecs.callEventSchema.safeParse(event);
        if (!parsed.success) {
          throw new Error(`Failed to parse event: ${parsed.error}`);
        }
        switch (parsed.data.event) {
          case "text_delta":
            controller.enqueue({
              type: "text_delta",
              data: JSON.parse(event.data)
            });
            break;
          case "json_delta":
            controller.enqueue({
              type: "json_delta",
              data: event.data
            });
            break;
          case "error":
            controller.enqueue({
              type: "error",
              data: JSON.parse(event.data)
            });
            break;
          case "progress":
            controller.enqueue({
              type: "progress",
              data: import_typespecs.sseProgressEventDataSchema.parse(JSON.parse(event.data))
            });
            break;
          case "console":
            controller.enqueue({
              type: "console",
              data: import_typespecs.sseConsoleEventDataSchema.parse(JSON.parse(event.data))
            });
            break;
          case "start":
            controller.enqueue({
              type: "start",
              data: ""
            });
            break;
          case "done":
            controller.enqueue({
              type: "done",
              data: ""
            });
            break;
          default: {
            const _event = parsed.data;
            throw new Error(`Unknown event type ${JSON.stringify(_event)}`);
          }
        }
      });
    },
    async transform(chunk, controller) {
      if (chunk instanceof Uint8Array) {
        parser.feed(decoder.decode(chunk));
      } else if (typeof chunk === "string") {
        parser.feed(chunk);
      } else {
        controller.enqueue(chunk);
      }
    },
    async flush(controller) {
      controller.terminate();
    }
  });
}
function createFinalValuePassThroughStream(onFinal, onError) {
  const decoder = new TextDecoder();
  const textChunks = [];
  const jsonChunks = [];
  const transformStream = new TransformStream({
    transform(chunk, controller) {
      if (typeof chunk === "string") {
        textChunks.push(chunk);
        controller.enqueue({
          type: "text_delta",
          data: chunk
        });
      } else if (chunk instanceof Uint8Array) {
        textChunks.push(decoder.decode(chunk));
        controller.enqueue({
          type: "text_delta",
          data: decoder.decode(chunk)
        });
      } else if (braintrustStreamChunkSchema.safeParse(chunk).success) {
        const chunkType = chunk.type;
        switch (chunkType) {
          case "text_delta":
            textChunks.push(chunk.data);
            break;
          case "json_delta":
            jsonChunks.push(chunk.data);
            break;
          case "error":
            onError(chunk.data);
            break;
          case "progress":
          case "start":
          case "done":
          case "console":
            break;
          default:
            const _type = chunkType;
            throw new Error(`Unknown chunk type ${_type}`);
        }
        controller.enqueue(chunk);
      } else {
        throw new Error(`Unknown chunk type ${chunk}`);
      }
    },
    flush(controller) {
      if (jsonChunks.length > 0) {
        onFinal(JSON.parse(jsonChunks.join("")));
      } else if (textChunks.length > 0) {
        onFinal(textChunks.join(""));
      } else {
        onFinal(void 0);
      }
      controller.terminate();
    }
  });
  return transformStream;
}
function devNullWritableStream() {
  return new WritableStream({
    write(chunk) {
    },
    close() {
    },
    abort(reason) {
    },
    start(controller) {
    }
  });
}

// src/logger.ts
var import_functions = require("@vercel/functions");
var NoopSpan = class {
  id;
  kind = "span";
  constructor() {
    this.id = "";
  }
  log(_) {
  }
  logFeedback(_event) {
  }
  traced(callback, _1) {
    return callback(this);
  }
  startSpan(_1) {
    return this;
  }
  end(args) {
    return args?.endTime ?? getCurrentUnixTimestamp();
  }
  async export() {
    return "";
  }
  async permalink() {
    return "";
  }
  async flush() {
  }
  close(args) {
    return this.end(args);
  }
  setAttributes(_args) {
  }
};
var NOOP_SPAN = new NoopSpan();
var loginSchema = import_zod2.z.strictObject({
  appUrl: import_zod2.z.string(),
  appPublicUrl: import_zod2.z.string(),
  orgName: import_zod2.z.string(),
  apiUrl: import_zod2.z.string(),
  proxyUrl: import_zod2.z.string(),
  loginToken: import_zod2.z.string(),
  orgId: import_zod2.z.string().nullish(),
  gitMetadataSettings: import_typespecs2.gitMetadataSettingsSchema.nullish()
});
var stateNonce = 0;
var BraintrustState = class _BraintrustState {
  constructor(loginParams) {
    this.loginParams = loginParams;
    this.id = `${(/* @__PURE__ */ new Date()).toLocaleString()}-${stateNonce++}`;
    this.currentExperiment = void 0;
    this.currentLogger = void 0;
    this.currentSpan = isomorph_default.newAsyncLocalStorage();
    if (loginParams.fetch) {
      this.fetch = loginParams.fetch;
    }
    const defaultGetLogConn = async () => {
      await this.login({});
      return this.apiConn();
    };
    this._bgLogger = new BackgroundLogger(
      new LazyValue(defaultGetLogConn),
      loginParams
    );
    this.resetLoginInfo();
  }
  id;
  currentExperiment;
  // Note: the value of IsAsyncFlush doesn't really matter here, since we
  // (safely) dynamically cast it whenever retrieving the logger.
  currentLogger;
  currentSpan;
  // Any time we re-log in, we directly update the apiConn inside the logger.
  // This is preferable to replacing the whole logger, which would create the
  // possibility of multiple loggers floating around, which may not log in a
  // deterministic order.
  _bgLogger;
  appUrl = null;
  appPublicUrl = null;
  loginToken = null;
  orgId = null;
  orgName = null;
  apiUrl = null;
  proxyUrl = null;
  loggedIn = false;
  gitMetadataSettings;
  fetch = globalThis.fetch;
  _appConn = null;
  _apiConn = null;
  _proxyConn = null;
  resetLoginInfo() {
    this.appUrl = null;
    this.appPublicUrl = null;
    this.loginToken = null;
    this.orgId = null;
    this.orgName = null;
    this.apiUrl = null;
    this.proxyUrl = null;
    this.loggedIn = false;
    this.gitMetadataSettings = void 0;
    this._appConn = null;
    this._apiConn = null;
    this._proxyConn = null;
  }
  copyLoginInfo(other) {
    this.appUrl = other.appUrl;
    this.appPublicUrl = other.appPublicUrl;
    this.loginToken = other.loginToken;
    this.orgId = other.orgId;
    this.orgName = other.orgName;
    this.apiUrl = other.apiUrl;
    this.proxyUrl = other.proxyUrl;
    this.loggedIn = other.loggedIn;
    this.gitMetadataSettings = other.gitMetadataSettings;
    this._appConn = other._appConn;
    this._apiConn = other._apiConn;
    this._proxyConn = other._proxyConn;
  }
  serialize() {
    if (!this.loggedIn) {
      throw new Error(
        "Cannot serialize BraintrustState without being logged in"
      );
    }
    if (!this.appUrl || !this.appPublicUrl || !this.apiUrl || !this.proxyUrl || !this.orgName || !this.loginToken || !this.loggedIn) {
      throw new Error(
        "Cannot serialize BraintrustState without all login attributes"
      );
    }
    return {
      appUrl: this.appUrl,
      appPublicUrl: this.appPublicUrl,
      loginToken: this.loginToken,
      orgId: this.orgId,
      orgName: this.orgName,
      apiUrl: this.apiUrl,
      proxyUrl: this.proxyUrl,
      gitMetadataSettings: this.gitMetadataSettings
    };
  }
  static deserialize(serialized, opts) {
    const serializedParsed = loginSchema.safeParse(serialized);
    if (!serializedParsed.success) {
      throw new Error(
        `Cannot deserialize BraintrustState: ${serializedParsed.error.errors}`
      );
    }
    const state = new _BraintrustState({ ...opts });
    for (const key of Object.keys(loginSchema.shape)) {
      state[key] = serializedParsed.data[key];
    }
    if (!state.loginToken) {
      throw new Error(
        "Cannot deserialize BraintrustState without a login token"
      );
    }
    state.apiConn().set_token(state.loginToken);
    state.apiConn().make_long_lived();
    state.appConn().set_token(state.loginToken);
    if (state.proxyUrl) {
      state.proxyConn().make_long_lived();
      state.proxyConn().set_token(state.loginToken);
    }
    state.loggedIn = true;
    state.loginReplaceApiConn(state.apiConn());
    return state;
  }
  setFetch(fetch2) {
    this.loginParams.fetch = fetch2;
    this.fetch = fetch2;
    this._apiConn?.setFetch(fetch2);
    this._appConn?.setFetch(fetch2);
  }
  async login(loginParams) {
    if (this.apiUrl && !loginParams.forceLogin) {
      return;
    }
    const newState = await loginToState({
      ...this.loginParams,
      ...Object.fromEntries(
        Object.entries(loginParams).filter(([k, v]) => !isEmpty(v))
      )
    });
    this.copyLoginInfo(newState);
  }
  appConn() {
    if (!this._appConn) {
      if (!this.appUrl) {
        throw new Error("Must initialize appUrl before requesting appConn");
      }
      this._appConn = new HTTPConnection(this.appUrl, this.fetch);
    }
    return this._appConn;
  }
  apiConn() {
    if (!this._apiConn) {
      if (!this.apiUrl) {
        throw new Error("Must initialize apiUrl before requesting apiConn");
      }
      this._apiConn = new HTTPConnection(this.apiUrl, this.fetch);
    }
    return this._apiConn;
  }
  proxyConn() {
    if (!this.proxyUrl) {
      return this.apiConn();
    }
    if (!this._proxyConn) {
      if (!this.proxyUrl) {
        throw new Error("Must initialize proxyUrl before requesting proxyConn");
      }
      this._proxyConn = new HTTPConnection(this.proxyUrl, this.fetch);
    }
    return this._proxyConn;
  }
  bgLogger() {
    return this._bgLogger;
  }
  // Should only be called by the login function.
  loginReplaceApiConn(apiConn) {
    this._bgLogger.internalReplaceApiConn(apiConn);
  }
};
var _globalState;
function _internalSetInitialState() {
  if (_globalState) {
    throw new Error("Cannot set initial state more than once");
  }
  _globalState = globalThis.__inherited_braintrust_state || new BraintrustState({
    /*empty login options*/
  });
}
var _internalGetGlobalState = () => _globalState;
var FailedHTTPResponse = class extends Error {
  status;
  text;
  data;
  constructor(status, text, data = null) {
    super(`${status}: ${text}`);
    this.status = status;
    this.text = text;
    this.data = data;
  }
};
async function checkResponse(resp) {
  if (resp.ok) {
    return resp;
  } else {
    throw new FailedHTTPResponse(
      resp.status,
      resp.statusText,
      await resp.text()
    );
  }
}
var HTTPConnection = class _HTTPConnection {
  base_url;
  token;
  headers;
  fetch;
  constructor(base_url, fetch2) {
    this.base_url = base_url;
    this.token = null;
    this.headers = {};
    this._reset();
    this.fetch = fetch2;
  }
  setFetch(fetch2) {
    this.fetch = fetch2;
  }
  async ping() {
    try {
      const resp = await this.get("ping");
      return resp.status === 200;
    } catch (e) {
      return false;
    }
  }
  make_long_lived() {
    this._reset();
  }
  static sanitize_token(token) {
    return token.trim();
  }
  set_token(token) {
    token = _HTTPConnection.sanitize_token(token);
    this.token = token;
    this._reset();
  }
  // As far as I can tell, you cannot set the retry/backoff factor here
  _reset() {
    this.headers = {};
    if (this.token) {
      this.headers["Authorization"] = `Bearer ${this.token}`;
    }
  }
  async get(path9, params = void 0, config3) {
    const { headers, ...rest } = config3 || {};
    const url = new URL((0, import_core._urljoin)(this.base_url, path9));
    url.search = new URLSearchParams(
      params ? Object.entries(params).filter(([_, v]) => v !== void 0).flatMap(
        ([k, v]) => v !== void 0 ? typeof v === "string" ? [[k, v]] : v.map((x) => [k, x]) : []
      ) : []
    ).toString();
    const this_fetch = this.fetch;
    const this_headers = this.headers;
    return await checkResponse(
      // Using toString() here makes it work with isomorphic fetch
      await this_fetch(url.toString(), {
        headers: {
          Accept: "application/json",
          ...this_headers,
          ...headers
        },
        keepalive: true,
        ...rest
      })
    );
  }
  async post(path9, params, config3) {
    const { headers, ...rest } = config3 || {};
    const this_fetch = this.fetch;
    const this_base_url = this.base_url;
    const this_headers = this.headers;
    return await checkResponse(
      await this_fetch((0, import_core._urljoin)(this_base_url, path9), {
        method: "POST",
        headers: {
          Accept: "application/json",
          "Content-Type": "application/json",
          ...this_headers,
          ...headers
        },
        body: typeof params === "string" ? params : params ? JSON.stringify(params) : void 0,
        keepalive: true,
        ...rest
      })
    );
  }
  async get_json(object_type, args = void 0, retries = 0) {
    const tries = retries + 1;
    for (let i = 0; i < tries; i++) {
      try {
        const resp = await this.get(`${object_type}`, args);
        return await resp.json();
      } catch (e) {
        if (i < tries - 1) {
          console.log(
            `Retrying API request ${object_type} ${JSON.stringify(args)} ${e.status} ${e.text}`
          );
          continue;
        }
        throw e;
      }
    }
  }
  async post_json(object_type, args = void 0) {
    const resp = await this.post(`${object_type}`, args, {
      headers: { "Content-Type": "application/json" }
    });
    return await resp.json();
  }
};
var Attachment = class {
  /**
   * The object that replaces this `Attachment` at upload time.
   */
  reference;
  uploader;
  _data;
  state;
  // For debug logging only.
  dataDebugString;
  /**
   * Construct an attachment.
   *
   * @param data A string representing the path of the file on disk, or a
   * `Blob`/`ArrayBuffer` with the file's contents. The caller is responsible
   * for ensuring the file/blob/buffer is not modified until upload is complete.
   *
   * @param filename The desired name of the file in Braintrust after uploading.
   * This parameter is for visualization purposes only and has no effect on
   * attachment storage.
   *
   * @param contentType The MIME type of the file.
   *
   * @param state (Optional) For internal use.
   */
  constructor({ data, filename, contentType, state }) {
    this.reference = {
      type: import_typespecs2.BRAINTRUST_ATTACHMENT,
      filename,
      content_type: contentType,
      key: newId()
    };
    this.state = state;
    this.dataDebugString = typeof data === "string" ? data : "<in-memory data>";
    this._data = this.initData(data);
    this.uploader = this.initUploader();
  }
  /**
   * On first access, (1) reads the attachment from disk if needed, (2)
   * authenticates with the data plane to request a signed URL, (3) uploads to
   * object store, and (4) updates the attachment.
   *
   * @returns The attachment status.
   */
  async upload() {
    return await this.uploader.get();
  }
  /**
   * The attachment contents. This is a lazy value that will read the attachment contents from disk or memory on first access.
   */
  async data() {
    return this._data.get();
  }
  /**
   * A human-readable description for logging and debugging.
   *
   * @returns The debug object. The return type is not stable and may change in
   * a future release.
   */
  debugInfo() {
    return {
      inputData: this.dataDebugString,
      reference: this.reference,
      state: this.state
    };
  }
  initUploader() {
    const doUpload = async (conn, orgId) => {
      const requestParams = {
        key: this.reference.key,
        filename: this.reference.filename,
        content_type: this.reference.content_type,
        org_id: orgId
      };
      const [metadataPromiseResult, dataPromiseResult] = await Promise.allSettled([
        conn.post("/attachment", requestParams),
        this._data.get()
      ]);
      if (metadataPromiseResult.status === "rejected") {
        const errorStr = JSON.stringify(metadataPromiseResult.reason);
        throw new Error(
          `Failed to request signed URL from API server: ${errorStr}`
        );
      }
      if (dataPromiseResult.status === "rejected") {
        const errorStr = JSON.stringify(dataPromiseResult.reason);
        throw new Error(`Failed to read file: ${errorStr}`);
      }
      const metadataResponse = metadataPromiseResult.value;
      const data = dataPromiseResult.value;
      let signedUrl;
      let headers;
      try {
        ({ signedUrl, headers } = import_zod2.z.object({
          signedUrl: import_zod2.z.string().url(),
          headers: import_zod2.z.record(import_zod2.z.string())
        }).parse(await metadataResponse.json()));
      } catch (error2) {
        if (error2 instanceof import_zod2.ZodError) {
          const errorStr = JSON.stringify(error2.flatten());
          throw new Error(`Invalid response from API server: ${errorStr}`);
        }
        throw error2;
      }
      let objectStoreResponse;
      try {
        objectStoreResponse = await checkResponse(
          await fetch(signedUrl, {
            method: "PUT",
            headers,
            body: data
          })
        );
      } catch (error2) {
        if (error2 instanceof FailedHTTPResponse) {
          throw new Error(
            `Failed to upload attachment to object store: ${error2.status} ${error2.text} ${error2.data}`
          );
        }
        throw error2;
      }
      return { signedUrl, metadataResponse, objectStoreResponse };
    };
    const errorWrapper = async () => {
      const status = { upload_status: "done" };
      const state = this.state ?? _globalState;
      await state.login({});
      const conn = state.apiConn();
      const orgId = state.orgId ?? "";
      try {
        await doUpload(conn, orgId);
      } catch (error2) {
        status.upload_status = "error";
        status.error_message = error2 instanceof Error ? error2.message : JSON.stringify(error2);
      }
      const requestParams = {
        key: this.reference.key,
        org_id: orgId,
        status
      };
      const statusResponse = await conn.post(
        "/attachment/status",
        requestParams
      );
      if (!statusResponse.ok) {
        const errorStr = JSON.stringify(statusResponse);
        throw new Error(`Couldn't log attachment status: ${errorStr}`);
      }
      return status;
    };
    return new LazyValue(errorWrapper);
  }
  initData(data) {
    if (typeof data === "string") {
      const readFile3 = isomorph_default.readFile;
      if (!readFile3) {
        throw new Error(
          `This platform does not support reading the filesystem. Construct the Attachment
with a Blob/ArrayBuffer, or run the program on Node.js.`
        );
      }
      return new LazyValue(async () => new Blob([await readFile3(data)]));
    } else {
      return new LazyValue(async () => new Blob([data]));
    }
  }
};
function logFeedbackImpl(state, parentObjectType, parentObjectId, {
  id,
  expected,
  scores,
  metadata: inputMetadata,
  tags,
  comment,
  source: inputSource
}) {
  const source = inputSource ?? "external";
  if (!import_core.VALID_SOURCES.includes(source)) {
    throw new Error(`source must be one of ${import_core.VALID_SOURCES}`);
  }
  if (isEmpty(scores) && isEmpty(expected) && isEmpty(tags) && isEmpty(comment)) {
    throw new Error(
      "At least one of scores, expected, tags, or comment must be specified"
    );
  }
  const validatedEvent = validateAndSanitizeExperimentLogPartialArgs({
    scores,
    metadata: inputMetadata,
    expected,
    tags
  });
  let { metadata, ...updateEvent } = deepCopyEvent(validatedEvent);
  updateEvent = Object.fromEntries(
    Object.entries(updateEvent).filter(([_, v]) => !isEmpty(v))
  );
  const parentIds = async () => new import_core.SpanComponentsV3({
    object_type: parentObjectType,
    object_id: await parentObjectId.get()
  }).objectIdFields();
  if (Object.keys(updateEvent).length > 0) {
    const record = new LazyValue(async () => {
      return {
        id,
        ...updateEvent,
        ...await parentIds(),
        [import_core.AUDIT_SOURCE_FIELD]: source,
        [import_core.AUDIT_METADATA_FIELD]: metadata,
        [import_core.IS_MERGE_FIELD]: true
      };
    });
    state.bgLogger().log([record]);
  }
  if (!isEmpty(comment)) {
    const record = new LazyValue(async () => {
      return {
        id: (0, import_uuid.v4)(),
        created: (/* @__PURE__ */ new Date()).toISOString(),
        origin: {
          // NOTE: We do not know (or care?) what the transaction id of the row that
          // we're commenting on is here, so we omit it.
          id
        },
        comment: {
          text: comment
        },
        ...await parentIds(),
        [import_core.AUDIT_SOURCE_FIELD]: source,
        [import_core.AUDIT_METADATA_FIELD]: metadata
      };
    });
    state.bgLogger().log([record]);
  }
}
function updateSpanImpl({
  state,
  parentObjectType,
  parentObjectId,
  id,
  event
}) {
  const updateEvent = deepCopyEvent(
    validateAndSanitizeExperimentLogPartialArgs({
      id,
      ...event
    })
  );
  const parentIds = async () => new import_core.SpanComponentsV3({
    object_type: parentObjectType,
    object_id: await parentObjectId.get()
  }).objectIdFields();
  const record = new LazyValue(async () => ({
    id,
    ...updateEvent,
    ...await parentIds(),
    [import_core.IS_MERGE_FIELD]: true
  }));
  state.bgLogger().log([record]);
}
function spanComponentsToObjectIdLambda(state, components) {
  if (components.data.object_id) {
    const ret = components.data.object_id;
    return async () => ret;
  }
  if (!components.data.compute_object_metadata_args) {
    throw new Error(
      "Impossible: must provide either objectId or computeObjectMetadataArgs"
    );
  }
  switch (components.data.object_type) {
    case import_core.SpanObjectTypeV3.EXPERIMENT:
      throw new Error(
        "Impossible: computeObjectMetadataArgs not supported for experiments"
      );
    case import_core.SpanObjectTypeV3.PROJECT_LOGS:
      return async () => (await computeLoggerMetadata(state, {
        ...components.data.compute_object_metadata_args
      })).project.id;
    default:
      const x = components.data.object_type;
      throw new Error(`Unknown object type: ${x}`);
  }
}
async function spanComponentsToObjectId({
  components,
  state
}) {
  return await spanComponentsToObjectIdLambda(
    state ?? _globalState,
    components
  )();
}
async function permalink(slug, opts) {
  const state = opts?.state ?? _globalState;
  const getOrgName = async () => {
    if (opts?.orgName) {
      return opts.orgName;
    }
    await state.login({});
    if (!state.orgName) {
      throw new Error(
        "Must either provide orgName explicitly or be logged in to a specific org"
      );
    }
    return state.orgName;
  };
  const getAppUrl = async () => {
    if (opts?.appUrl) {
      return opts.appUrl;
    }
    await state.login({});
    if (!state.appUrl) {
      throw new Error("Must either provide appUrl explicitly or be logged in");
    }
    return state.appUrl;
  };
  const components = import_core.SpanComponentsV3.fromStr(slug);
  const object_type = (0, import_core.spanObjectTypeV3ToString)(components.data.object_type);
  const [orgName, appUrl, object_id] = await Promise.all([
    getOrgName(),
    getAppUrl(),
    spanComponentsToObjectId({ components, state })
  ]);
  const id = components.data.row_id;
  if (!id) {
    throw new Error("Span slug does not refer to an individual row");
  }
  const urlParams = new URLSearchParams({ object_type, object_id, id });
  return `${appUrl}/app/${orgName}/object?${urlParams}`;
}
function startSpanParentArgs(args) {
  let argParentObjectId = void 0;
  let argParentSpanIds = void 0;
  let argPropagatedEvent = void 0;
  if (args.parent) {
    if (args.parentSpanIds) {
      throw new Error("Cannot specify both parent and parentSpanIds");
    }
    const parentComponents = import_core.SpanComponentsV3.fromStr(args.parent);
    if (args.parentObjectType !== parentComponents.data.object_type) {
      throw new Error(
        `Mismatch between expected span parent object type ${args.parentObjectType} and provided type ${parentComponents.data.object_type}`
      );
    }
    const parentComponentsObjectIdLambda = spanComponentsToObjectIdLambda(
      args.state,
      parentComponents
    );
    const computeParentObjectId = async () => {
      const parentComponentsObjectId = await parentComponentsObjectIdLambda();
      if (await args.parentObjectId.get() !== parentComponentsObjectId) {
        throw new Error(
          `Mismatch between expected span parent object id ${await args.parentObjectId.get()} and provided id ${parentComponentsObjectId}`
        );
      }
      return await args.parentObjectId.get();
    };
    argParentObjectId = new LazyValue(computeParentObjectId);
    if (parentComponents.data.row_id) {
      argParentSpanIds = {
        spanId: parentComponents.data.span_id,
        rootSpanId: parentComponents.data.root_span_id
      };
    }
    argPropagatedEvent = args.propagatedEvent ?? (parentComponents.data.propagated_event ?? void 0);
  } else {
    argParentObjectId = args.parentObjectId;
    argParentSpanIds = args.parentSpanIds;
    argPropagatedEvent = args.propagatedEvent;
  }
  return {
    parentObjectType: args.parentObjectType,
    parentObjectId: argParentObjectId,
    parentComputeObjectMetadataArgs: args.parentComputeObjectMetadataArgs,
    parentSpanIds: argParentSpanIds,
    propagatedEvent: argPropagatedEvent
  };
}
var Logger = class {
  state;
  lazyMetadata;
  _asyncFlush;
  computeMetadataArgs;
  lastStartTime;
  lazyId;
  calledStartSpan;
  // For type identification.
  kind = "logger";
  constructor(state, lazyMetadata, logOptions = {}) {
    this.lazyMetadata = lazyMetadata;
    this._asyncFlush = logOptions.asyncFlush;
    this.computeMetadataArgs = logOptions.computeMetadataArgs;
    this.lastStartTime = getCurrentUnixTimestamp();
    this.lazyId = new LazyValue(async () => await this.id);
    this.calledStartSpan = false;
    this.state = state;
  }
  get org_id() {
    return (async () => {
      return (await this.lazyMetadata.get()).org_id;
    })();
  }
  get project() {
    return (async () => {
      return (await this.lazyMetadata.get()).project;
    })();
  }
  get id() {
    return (async () => (await this.project).id)();
  }
  parentObjectType() {
    return import_core.SpanObjectTypeV3.PROJECT_LOGS;
  }
  /**
   * Log a single event. The event will be batched and uploaded behind the scenes if `logOptions.asyncFlush` is true.
   *
   * @param event The event to log.
   * @param event.input: (Optional) the arguments that uniquely define a user input (an arbitrary, JSON serializable object).
   * @param event.output: (Optional) the output of your application, including post-processing (an arbitrary, JSON serializable object), that allows you to determine whether the result is correct or not. For example, in an app that generates SQL queries, the `output` should be the _result_ of the SQL query generated by the model, not the query itself, because there may be multiple valid queries that answer a single question.
   * @param event.expected: (Optional) the ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not. Braintrust currently does not compare `output` to `expected` for you, since there are so many different ways to do that correctly. Instead, these values are just used to help you navigate while digging into analyses. However, we may later use these values to re-score outputs or fine-tune your models.
   * @param event.error: (Optional) The error that occurred, if any. If you use tracing to run an experiment, errors are automatically logged when your code throws an exception.
   * @param event.scores: (Optional) a dictionary of numeric values (between 0 and 1) to log. The scores should give you a variety of signals that help you determine how accurate the outputs are compared to what you expect and diagnose failures. For example, a summarization app might have one score that tells you how accurate the summary is, and another that measures the word similarity between the generated and grouth truth summary. The word similarity score could help you determine whether the summarization was covering similar concepts or not. You can use these scores to help you sort, filter, and compare logs.
   * @param event.metadata: (Optional) a dictionary with additional data about the test example, model outputs, or just about anything else that's relevant, that you can use to help find and analyze examples later. For example, you could log the `prompt`, example's `id`, or anything else that would be useful to slice/dice later. The values in `metadata` can be any JSON-serializable type, but its keys must be strings.
   * @param event.metrics: (Optional) a dictionary of metrics to log. The following keys are populated automatically: "start", "end".
   * @param event.id: (Optional) a unique identifier for the event. If you don't provide one, BrainTrust will generate one for you.
   * @param options Additional logging options
   * @param options.allowConcurrentWithSpans in rare cases where you need to log at the top level separately from spans on the logger elsewhere, set this to true.
   * @returns The `id` of the logged event.
   */
  log(event, options) {
    if (this.calledStartSpan && !options?.allowConcurrentWithSpans) {
      throw new Error(
        "Cannot run toplevel `log` method while using spans. To log to the span, call `logger.traced` and then log with `span.log`"
      );
    }
    const span = this.startSpanImpl({ startTime: this.lastStartTime, event });
    this.lastStartTime = span.end();
    const ret = span.id;
    if (this.asyncFlush === true) {
      return ret;
    } else {
      return (async () => {
        await this.flush();
        return ret;
      })();
    }
  }
  /**
   * Create a new toplevel span underneath the logger. The name defaults to "root".
   *
   * See {@link Span.traced} for full details.
   */
  traced(callback, args) {
    const { setCurrent, ...argsRest } = args ?? {};
    const span = this.startSpan(argsRest);
    const ret = runCatchFinally(
      () => {
        if (setCurrent ?? true) {
          return withCurrent(span, callback);
        } else {
          return callback(span);
        }
      },
      (e) => {
        logError(span, e);
        throw e;
      },
      () => span.end()
    );
    if (this.asyncFlush) {
      return ret;
    } else {
      return (async () => {
        const awaitedRet = await ret;
        await this.flush();
        return awaitedRet;
      })();
    }
  }
  /**
   * Lower-level alternative to `traced`. This allows you to start a span yourself, and can be useful in situations
   * where you cannot use callbacks. However, spans started with `startSpan` will not be marked as the "current span",
   * so `currentSpan()` and `traced()` will be no-ops. If you want to mark a span as current, use `traced` instead.
   *
   * See {@link traced} for full details.
   */
  startSpan(args) {
    this.calledStartSpan = true;
    return this.startSpanImpl(args);
  }
  startSpanImpl(args) {
    return new SpanImpl({
      state: this.state,
      ...args,
      ...startSpanParentArgs({
        state: this.state,
        parent: args?.parent,
        parentObjectType: this.parentObjectType(),
        parentObjectId: this.lazyId,
        parentComputeObjectMetadataArgs: this.computeMetadataArgs,
        parentSpanIds: void 0,
        propagatedEvent: args?.propagatedEvent
      }),
      defaultRootType: import_core.SpanTypeAttribute.TASK
    });
  }
  /**
   * Log feedback to an event. Feedback is used to save feedback scores, set an expected value, or add a comment.
   *
   * @param event
   * @param event.id The id of the event to log feedback for. This is the `id` returned by `log` or accessible as the `id` field of a span.
   * @param event.scores (Optional) a dictionary of numeric values (between 0 and 1) to log. These scores will be merged into the existing scores for the event.
   * @param event.expected (Optional) the ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not.
   * @param event.comment (Optional) an optional comment string to log about the event.
   * @param event.metadata (Optional) a dictionary with additional data about the feedback. If you have a `user_id`, you can log it here and access it in the Braintrust UI. Note, this metadata does not correspond to the main event itself, but rather the audit log attached to the event.
   * @param event.source (Optional) the source of the feedback. Must be one of "external" (default), "app", or "api".
   */
  logFeedback(event) {
    logFeedbackImpl(this.state, this.parentObjectType(), this.lazyId, event);
  }
  /**
   * Update a span in the experiment using its id. It is important that you only update a span once the original span has been fully written and flushed,
   * since otherwise updates to the span may conflict with the original span.
   *
   * @param event The event data to update the span with. Must include `id`. See {@link Experiment.log} for a full list of valid fields.
   */
  updateSpan(event) {
    const { id, ...eventRest } = event;
    if (!id) {
      throw new Error("Span id is required to update a span");
    }
    updateSpanImpl({
      state: this.state,
      parentObjectType: this.parentObjectType(),
      parentObjectId: this.lazyId,
      id,
      event: eventRest
    });
  }
  /**
   * Return a serialized representation of the logger that can be used to start subspans in other places.
   *
   * See {@link Span.startSpan} for more details.
   */
  async export() {
    return new import_core.SpanComponentsV3({
      object_type: this.parentObjectType(),
      ...this.computeMetadataArgs && !this.lazyId.hasComputed ? { compute_object_metadata_args: this.computeMetadataArgs } : { object_id: await this.lazyId.get() }
    }).toStr();
  }
  /*
   * Flush any pending logs to the server.
   */
  async flush() {
    return await this.state.bgLogger().flush();
  }
  get asyncFlush() {
    return this._asyncFlush;
  }
};
function castLogger(logger, asyncFlush) {
  if (logger === void 0)
    return void 0;
  if (asyncFlush !== void 0 && !!asyncFlush !== !!logger.asyncFlush) {
    throw new Error(
      `Asserted asyncFlush setting ${asyncFlush} does not match stored logger's setting ${logger.asyncFlush}`
    );
  }
  return logger;
}
function constructLogs3Data(items) {
  return `{"rows": ${(0, import_core.constructJsonArray)(items)}, "api_version": 2}`;
}
function now() {
  return (/* @__PURE__ */ new Date()).getTime();
}
var BackgroundLogger = class _BackgroundLogger {
  apiConn;
  items = [];
  activeFlush = Promise.resolve();
  activeFlushResolved = true;
  activeFlushError = void 0;
  onFlushError;
  syncFlush = false;
  // 6 MB for the AWS lambda gateway (from our own testing).
  maxRequestSize = 6 * 1024 * 1024;
  defaultBatchSize = 100;
  numTries = 3;
  queueDropExceedingMaxsize = void 0;
  queueDropLoggingPeriod = 60;
  failedPublishPayloadsDir = void 0;
  allPublishPayloadsDir = void 0;
  queueDropLoggingState = {
    numDropped: 0,
    lastLoggedTimestamp: 0
  };
  constructor(apiConn, opts) {
    opts = opts ?? {};
    this.apiConn = apiConn;
    const syncFlushEnv = Number(isomorph_default.getEnv("BRAINTRUST_SYNC_FLUSH"));
    if (!isNaN(syncFlushEnv)) {
      this.syncFlush = Boolean(syncFlushEnv);
    }
    const defaultBatchSizeEnv = Number(
      isomorph_default.getEnv("BRAINTRUST_DEFAULT_BATCH_SIZE")
    );
    if (!isNaN(defaultBatchSizeEnv)) {
      this.defaultBatchSize = defaultBatchSizeEnv;
    }
    const maxRequestSizeEnv = Number(isomorph_default.getEnv("BRAINTRUST_MAX_REQUEST_SIZE"));
    if (!isNaN(maxRequestSizeEnv)) {
      this.maxRequestSize = maxRequestSizeEnv;
    }
    const numTriesEnv = Number(isomorph_default.getEnv("BRAINTRUST_NUM_RETRIES"));
    if (!isNaN(numTriesEnv)) {
      this.numTries = numTriesEnv + 1;
    }
    const queueDropExceedingMaxsizeEnv = Number(
      isomorph_default.getEnv("BRAINTRUST_QUEUE_DROP_EXCEEDING_MAXSIZE")
    );
    if (!isNaN(queueDropExceedingMaxsizeEnv)) {
      this.queueDropExceedingMaxsize = queueDropExceedingMaxsizeEnv;
    }
    const queueDropLoggingPeriodEnv = Number(
      isomorph_default.getEnv("BRAINTRUST_QUEUE_DROP_LOGGING_PERIOD")
    );
    if (!isNaN(queueDropLoggingPeriodEnv)) {
      this.queueDropLoggingPeriod = queueDropLoggingPeriodEnv;
    }
    const failedPublishPayloadsDirEnv = isomorph_default.getEnv(
      "BRAINTRUST_FAILED_PUBLISH_PAYLOADS_DIR"
    );
    if (failedPublishPayloadsDirEnv) {
      this.failedPublishPayloadsDir = failedPublishPayloadsDirEnv;
    }
    const allPublishPayloadsDirEnv = isomorph_default.getEnv(
      "BRAINTRUST_ALL_PUBLISH_PAYLOADS_DIR"
    );
    if (allPublishPayloadsDirEnv) {
      this.allPublishPayloadsDir = allPublishPayloadsDirEnv;
    }
    if (!opts.noExitFlush) {
      isomorph_default.processOn("beforeExit", async () => {
        await this.flush();
      });
    }
    this.onFlushError = opts.onFlushError;
  }
  log(items) {
    const [addedItems, droppedItems] = (() => {
      if (this.queueDropExceedingMaxsize === void 0) {
        return [items, []];
      }
      const numElementsToAdd = Math.min(
        Math.max(this.queueDropExceedingMaxsize - this.items.length, 0),
        items.length
      );
      return [items.slice(0, numElementsToAdd), items.slice(numElementsToAdd)];
    })();
    this.items.push(...addedItems);
    if (!this.syncFlush) {
      this.triggerActiveFlush();
    }
    if (droppedItems.length) {
      this.registerDroppedItemCount(droppedItems.length);
      if (this.allPublishPayloadsDir || this.failedPublishPayloadsDir) {
        this.dumpDroppedEvents(droppedItems);
      }
    }
  }
  async flush() {
    if (this.syncFlush) {
      this.triggerActiveFlush();
    }
    await this.activeFlush;
    if (this.activeFlushError) {
      const err = this.activeFlushError;
      this.activeFlushError = void 0;
      if (this.syncFlush) {
        throw err;
      }
    }
  }
  async flushOnce(args) {
    const batchSize = args?.batchSize ?? this.defaultBatchSize;
    const wrappedItems = this.items;
    this.items = [];
    const [allItems, attachments] = await this.unwrapLazyValues(wrappedItems);
    if (allItems.length === 0) {
      return;
    }
    const allItemsStr = allItems.map(
      (bucket) => bucket.map((item) => JSON.stringify(item))
    );
    const batchSets = (0, import_core.batchItems)({
      items: allItemsStr,
      batchMaxNumItems: batchSize,
      batchMaxNumBytes: this.maxRequestSize / 2
    });
    for (const batchSet of batchSets) {
      const postPromises = batchSet.map(
        (batch) => (async () => {
          try {
            await this.submitLogsRequest(batch);
            return { type: "success" };
          } catch (e) {
            return { type: "error", value: e };
          }
        })()
      );
      const results = await Promise.all(postPromises);
      const failingResultErrors = results.map((r) => r.type === "success" ? void 0 : r.value).filter((r) => r !== void 0);
      if (failingResultErrors.length) {
        throw new AggregateError(
          failingResultErrors,
          `Encountered the following errors while logging:`
        );
      }
    }
    const attachmentErrors = [];
    for (const attachment of attachments) {
      try {
        const result = await attachment.upload();
        if (result.upload_status === "error") {
          throw new Error(result.error_message);
        }
      } catch (error2) {
        attachmentErrors.push(error2);
      }
    }
    if (attachmentErrors.length === 1) {
      throw attachmentErrors[0];
    } else if (attachmentErrors.length > 1) {
      throw new AggregateError(
        attachmentErrors,
        `Encountered the following errors while uploading attachments:`
      );
    }
    if (this.items.length > 0) {
      await this.flushOnce(args);
    }
  }
  async unwrapLazyValues(wrappedItems) {
    for (let i = 0; i < this.numTries; ++i) {
      try {
        const items = await Promise.all(wrappedItems.map((x) => x.get()));
        const attachments = [];
        items.forEach((item) => extractAttachments(item, attachments));
        return [(0, import_core.mergeRowBatch)(items), attachments];
      } catch (e) {
        let errmsg = "Encountered error when constructing records to flush";
        const isRetrying = i + 1 < this.numTries;
        if (isRetrying) {
          errmsg += ". Retrying";
        }
        console.warn(errmsg);
        if (!isRetrying) {
          console.warn(
            `Failed to construct log records to flush after ${this.numTries} attempts. Dropping batch`
          );
          throw e;
        } else {
          console.warn(e);
          await new Promise((resolve2) => setTimeout(resolve2, 100));
        }
      }
    }
    throw new Error("Impossible");
  }
  async submitLogsRequest(items) {
    const conn = await this.apiConn.get();
    const dataStr = constructLogs3Data(items);
    if (this.allPublishPayloadsDir) {
      await _BackgroundLogger.writePayloadToDir({
        payloadDir: this.allPublishPayloadsDir,
        payload: dataStr
      });
    }
    for (let i = 0; i < this.numTries; i++) {
      const startTime = now();
      let error2 = void 0;
      try {
        await conn.post_json("logs3", dataStr);
      } catch {
        try {
          const legacyDataS = (0, import_core.constructJsonArray)(
            items.map((r) => JSON.stringify((0, import_core.makeLegacyEvent)(JSON.parse(r))))
          );
          await conn.post_json("logs", legacyDataS);
        } catch (e) {
          error2 = e;
        }
      }
      if (error2 === void 0) {
        return;
      }
      const isRetrying = i + 1 < this.numTries;
      const retryingText = isRetrying ? "" : " Retrying";
      const errorText = (() => {
        if (error2 instanceof FailedHTTPResponse) {
          return `${error2.status} (${error2.text}): ${error2.data}`;
        } else {
          return `${error2}`;
        }
      })();
      const errMsg = `log request failed. Elapsed time: ${(now() - startTime) / 1e3} seconds. Payload size: ${dataStr.length}.${retryingText}
Error: ${errorText}`;
      if (!isRetrying && this.failedPublishPayloadsDir) {
        await _BackgroundLogger.writePayloadToDir({
          payloadDir: this.failedPublishPayloadsDir,
          payload: dataStr
        });
        this.logFailedPayloadsDir();
      }
      if (!isRetrying) {
        console.warn(
          `log request failed after ${this.numTries} retries. Dropping batch`
        );
        throw new Error(errMsg);
      } else {
        console.warn(errMsg);
        if (isRetrying) {
          await new Promise((resolve2) => setTimeout(resolve2, 100));
        }
      }
    }
  }
  registerDroppedItemCount(numItems) {
    if (numItems <= 0) {
      return;
    }
    this.queueDropLoggingState.numDropped += numItems;
    const timeNow = getCurrentUnixTimestamp();
    if (timeNow - this.queueDropLoggingState.lastLoggedTimestamp > this.queueDropLoggingPeriod) {
      console.warn(
        `Dropped ${this.queueDropLoggingState.numDropped} elements due to full queue`
      );
      if (this.failedPublishPayloadsDir) {
        this.logFailedPayloadsDir();
      }
      this.queueDropLoggingState.numDropped = 0;
      this.queueDropLoggingState.lastLoggedTimestamp = timeNow;
    }
  }
  async dumpDroppedEvents(wrappedItems) {
    const publishPayloadsDir = [
      this.allPublishPayloadsDir,
      this.failedPublishPayloadsDir
    ].reduce((acc, x) => x ? acc.concat([x]) : acc, new Array());
    if (!(wrappedItems.length && publishPayloadsDir.length)) {
      return;
    }
    try {
      const [allItems, allAttachments] = await this.unwrapLazyValues(wrappedItems);
      const dataStr = constructLogs3Data(
        allItems.map((x) => JSON.stringify(x))
      );
      const attachmentStr = JSON.stringify(
        allAttachments.map((a) => a.debugInfo())
      );
      const payload = `{"data": ${dataStr}, "attachments": ${attachmentStr}}
`;
      for (const payloadDir of publishPayloadsDir) {
        await _BackgroundLogger.writePayloadToDir({ payloadDir, payload });
      }
    } catch (e) {
      console.error(e);
    }
  }
  static async writePayloadToDir({
    payloadDir,
    payload
  }) {
    if (!(isomorph_default.pathJoin && isomorph_default.mkdir && isomorph_default.writeFile)) {
      console.warn(
        "Cannot dump payloads: filesystem-operations not supported on this platform"
      );
      return;
    }
    const payloadFile = isomorph_default.pathJoin(
      payloadDir,
      `payload_${getCurrentUnixTimestamp()}_${(0, import_uuid.v4)().slice(0, 8)}.json`
    );
    try {
      await isomorph_default.mkdir(payloadDir, { recursive: true });
      await isomorph_default.writeFile(payloadFile, payload);
    } catch (e) {
      console.error(
        `Failed to write failed payload to output file ${payloadFile}:
`,
        e
      );
    }
  }
  triggerActiveFlush() {
    if (this.activeFlushResolved) {
      this.activeFlushResolved = false;
      this.activeFlushError = void 0;
      this.activeFlush = (async () => {
        try {
          await this.flushOnce();
        } catch (err) {
          if (err instanceof AggregateError) {
            for (const e of err.errors) {
              this.onFlushError?.(e);
            }
          } else {
            this.onFlushError?.(err);
          }
          this.activeFlushError = err;
        } finally {
          this.activeFlushResolved = true;
        }
      })();
      (0, import_functions.waitUntil)(this.activeFlush);
    }
  }
  logFailedPayloadsDir() {
    console.warn(`Logging failed payloads to ${this.failedPublishPayloadsDir}`);
  }
  // Should only be called by BraintrustState.
  internalReplaceApiConn(apiConn) {
    this.apiConn = new LazyValue(async () => apiConn);
  }
};
function init(projectOrOptions, optionalOptions) {
  const options = (() => {
    if (typeof projectOrOptions === "string") {
      return { ...optionalOptions, project: projectOrOptions };
    } else {
      if (optionalOptions !== void 0) {
        throw new Error(
          "Cannot specify options struct as both parameters. Must call either init(project, options) or init(options)."
        );
      }
      return projectOrOptions;
    }
  })();
  const {
    project,
    experiment,
    description,
    dataset,
    baseExperiment,
    isPublic,
    open,
    update,
    appUrl,
    apiKey,
    orgName,
    forceLogin,
    fetch: fetch2,
    metadata,
    gitMetadataSettings,
    projectId,
    baseExperimentId,
    repoInfo: repoInfo2,
    state: stateArg
  } = options;
  if (open && update) {
    throw new Error("Cannot open and update an experiment at the same time");
  }
  const state = stateArg ?? _globalState;
  if (open) {
    if (isEmpty(experiment)) {
      throw new Error(`Cannot open an experiment without specifying its name`);
    }
    const lazyMetadata2 = new LazyValue(
      async () => {
        await state.login({ apiKey, appUrl, orgName, fetch: fetch2, forceLogin });
        const args = {
          project_name: project,
          project_id: projectId,
          org_name: state.orgName,
          experiment_name: experiment
        };
        const response = await state.appConn().post_json("api/experiment/get", args);
        if (response.length === 0) {
          throw new Error(
            `Experiment ${experiment} not found in project ${projectId ?? project}.`
          );
        }
        const info = response[0];
        return {
          project: {
            id: info.project_id,
            name: project ?? "UNKNOWN_PROJECT",
            fullInfo: {}
          },
          experiment: {
            id: info.id,
            name: info.name,
            fullInfo: info
          }
        };
      }
    );
    return new ReadonlyExperiment(
      stateArg ?? _globalState,
      lazyMetadata2
    );
  }
  const lazyMetadata = new LazyValue(
    async () => {
      await state.login({ apiKey, appUrl, orgName });
      const args = {
        project_name: project,
        project_id: projectId,
        org_id: state.orgId,
        update
      };
      if (experiment) {
        args["experiment_name"] = experiment;
      }
      if (description) {
        args["description"] = description;
      }
      const repoInfoArg = await (async () => {
        if (repoInfo2) {
          return repoInfo2;
        }
        let mergedGitMetadataSettings = {
          ...state.gitMetadataSettings || {
            collect: "all"
          }
        };
        if (gitMetadataSettings) {
          mergedGitMetadataSettings = (0, import_core.mergeGitMetadataSettings)(
            mergedGitMetadataSettings,
            gitMetadataSettings
          );
        }
        return await isomorph_default.getRepoInfo(mergedGitMetadataSettings);
      })();
      if (repoInfoArg) {
        args["repo_info"] = repoInfoArg;
      }
      if (baseExperimentId) {
        args["base_exp_id"] = baseExperimentId;
      } else if (baseExperiment) {
        args["base_experiment"] = baseExperiment;
      } else {
        args["ancestor_commits"] = await isomorph_default.getPastNAncestors();
      }
      if (dataset !== void 0) {
        args["dataset_id"] = await dataset.id;
        args["dataset_version"] = await dataset.version();
      }
      if (isPublic !== void 0) {
        args["public"] = isPublic;
      }
      if (metadata) {
        args["metadata"] = metadata;
      }
      let response = null;
      while (true) {
        try {
          response = await state.appConn().post_json("api/experiment/register", args);
          break;
        } catch (e) {
          if (args["base_experiment"] && `${"data" in e && e.data}`.includes("base experiment")) {
            console.warn(
              `Base experiment ${args["base_experiment"]} not found.`
            );
            delete args["base_experiment"];
          } else {
            throw e;
          }
        }
      }
      return {
        project: {
          id: response.project.id,
          name: response.project.name,
          fullInfo: response.project
        },
        experiment: {
          id: response.experiment.id,
          name: response.experiment.name,
          fullInfo: response.experiment
        }
      };
    }
  );
  const ret = new Experiment(state, lazyMetadata, dataset);
  if (options.setCurrent ?? true) {
    state.currentExperiment = ret;
  }
  return ret;
}
async function computeLoggerMetadata(state, {
  project_name,
  project_id
}) {
  await state.login({});
  const org_id = state.orgId;
  if (isEmpty(project_id)) {
    const response = await state.appConn().post_json("api/project/register", {
      project_name: project_name || GLOBAL_PROJECT,
      org_id
    });
    return {
      org_id,
      project: {
        id: response.project.id,
        name: response.project.name,
        fullInfo: response.project
      }
    };
  } else if (isEmpty(project_name)) {
    const response = await state.appConn().get_json("api/project", {
      id: project_id
    });
    return {
      org_id,
      project: {
        id: project_id,
        name: response.name,
        fullInfo: response.project
      }
    };
  } else {
    return {
      org_id,
      project: { id: project_id, name: project_name, fullInfo: {} }
    };
  }
}
async function login(options = {}) {
  const { forceLogin = false } = options || {};
  if (_globalState.loggedIn && !forceLogin) {
    let checkUpdatedParam2 = function(varname, arg, orig) {
      if (!isEmpty(arg) && !isEmpty(orig) && arg !== orig) {
        throw new Error(
          `Re-logging in with different ${varname} (${arg}) than original (${orig}). To force re-login, pass \`forceLogin: true\``
        );
      }
    };
    var checkUpdatedParam = checkUpdatedParam2;
    checkUpdatedParam2("appUrl", options.appUrl, _globalState.appUrl);
    checkUpdatedParam2(
      "apiKey",
      options.apiKey ? HTTPConnection.sanitize_token(options.apiKey) : void 0,
      _globalState.loginToken
    );
    checkUpdatedParam2("orgName", options.orgName, _globalState.orgName);
    return _globalState;
  }
  await _globalState.login(options);
  globalThis.__inherited_braintrust_state = _globalState;
  return _globalState;
}
async function loginToState(options = {}) {
  const {
    appUrl = isomorph_default.getEnv("BRAINTRUST_APP_URL") || "https://www.braintrust.dev",
    apiKey = isomorph_default.getEnv("BRAINTRUST_API_KEY"),
    orgName = isomorph_default.getEnv("BRAINTRUST_ORG_NAME"),
    fetch: fetch2 = globalThis.fetch
  } = options || {};
  const appPublicUrl = isomorph_default.getEnv("BRAINTRUST_APP_PUBLIC_URL") || appUrl;
  const state = new BraintrustState(options);
  state.resetLoginInfo();
  state.appUrl = appUrl;
  state.appPublicUrl = appPublicUrl;
  let conn = null;
  if (apiKey !== void 0) {
    const resp = await checkResponse(
      await fetch2((0, import_core._urljoin)(state.appUrl, `/api/apikey/login`), {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${apiKey}`
        }
      })
    );
    const info = await resp.json();
    _check_org_info(state, info.org_info, orgName);
    conn = state.apiConn();
    conn.set_token(apiKey);
  } else {
    throw new Error(
      "Please specify an api key (e.g. by setting BRAINTRUST_API_KEY)."
    );
  }
  if (!conn) {
    throw new Error("Conn should be set at this point (a bug)");
  }
  conn.make_long_lived();
  state.appConn().set_token(apiKey);
  if (state.proxyUrl) {
    state.proxyConn().set_token(apiKey);
  }
  state.loginToken = conn.token;
  state.loggedIn = true;
  state.loginReplaceApiConn(conn);
  return state;
}
function currentExperiment(options) {
  const state = options?.state ?? _globalState;
  return state.currentExperiment;
}
function currentLogger(options) {
  const state = options?.state ?? _globalState;
  return castLogger(state.currentLogger, options?.asyncFlush);
}
function currentSpan(options) {
  const state = options?.state ?? _globalState;
  return state.currentSpan.getStore() ?? NOOP_SPAN;
}
function getSpanParentObject(options) {
  const state = options?.state ?? _globalState;
  const parentSpan = currentSpan({ state });
  if (!Object.is(parentSpan, NOOP_SPAN)) {
    return parentSpan;
  }
  const experiment = currentExperiment();
  if (experiment) {
    return experiment;
  }
  const logger = currentLogger(options);
  if (logger) {
    return logger;
  }
  return NOOP_SPAN;
}
function logError(span, error2) {
  let errorMessage = "<error>";
  let stackTrace = "";
  if (error2 instanceof Error) {
    errorMessage = error2.message;
    stackTrace = error2.stack || "";
  } else {
    errorMessage = String(error2);
  }
  span.log({ error: `${errorMessage}

${stackTrace}` });
}
function startSpan(args) {
  return startSpanAndIsLogger(args).span;
}
function startSpanAndIsLogger(args) {
  const state = args?.state ?? _globalState;
  if (args?.parent) {
    const components = import_core.SpanComponentsV3.fromStr(args?.parent);
    const parentSpanIds = components.data.row_id ? {
      spanId: components.data.span_id,
      rootSpanId: components.data.root_span_id
    } : void 0;
    const span = new SpanImpl({
      state,
      ...args,
      parentObjectType: components.data.object_type,
      parentObjectId: new LazyValue(
        spanComponentsToObjectIdLambda(state, components)
      ),
      parentComputeObjectMetadataArgs: components.data.compute_object_metadata_args ?? void 0,
      parentSpanIds,
      propagatedEvent: args?.propagatedEvent ?? (components.data.propagated_event ?? void 0)
    });
    return {
      span,
      isSyncFlushLogger: components.data.object_type === import_core.SpanObjectTypeV3.PROJECT_LOGS && // Since there's no parent logger here, we're free to choose the async flush
      // behavior, and therefore propagate along whatever we get from the arguments
      !args?.asyncFlush
    };
  } else {
    const parentObject = getSpanParentObject({
      asyncFlush: args?.asyncFlush
    });
    const span = parentObject.startSpan(args);
    return {
      span,
      isSyncFlushLogger: parentObject.kind === "logger" && !parentObject.asyncFlush
    };
  }
}
function withCurrent(span, callback, state = _globalState) {
  return state.currentSpan.run(span, () => callback(span));
}
function _check_org_info(state, org_info, org_name) {
  if (org_info.length === 0) {
    throw new Error("This user is not part of any organizations.");
  }
  for (const org of org_info) {
    if (org_name === void 0 || org.name === org_name) {
      state.orgId = org.id;
      state.orgName = org.name;
      state.apiUrl = isomorph_default.getEnv("BRAINTRUST_API_URL") ?? org.api_url;
      state.proxyUrl = isomorph_default.getEnv("BRAINTRUST_PROXY_URL") ?? org.proxy_url;
      state.gitMetadataSettings = org.git_metadata || void 0;
      break;
    }
  }
  if (state.orgId === void 0) {
    throw new Error(
      `Organization ${org_name} not found. Must be one of ${org_info.map((x) => x.name).join(", ")}`
    );
  }
}
function validateTags(tags) {
  const seen = /* @__PURE__ */ new Set();
  for (const tag of tags) {
    if (typeof tag !== "string") {
      throw new Error("tags must be strings");
    }
    if (seen.has(tag)) {
      throw new Error(`duplicate tag: ${tag}`);
    }
  }
}
function validateAndSanitizeExperimentLogPartialArgs(event) {
  if (event.scores) {
    if (Array.isArray(event.scores)) {
      throw new Error("scores must be an object, not an array");
    }
    for (let [name, score] of Object.entries(event.scores)) {
      if (typeof name !== "string") {
        throw new Error("score names must be strings");
      }
      if (score === null || score === void 0) {
        continue;
      }
      if (typeof score === "boolean") {
        score = score ? 1 : 0;
        event.scores[name] = score;
      }
      if (typeof score !== "number") {
        throw new Error("score values must be numbers");
      }
      if (score < 0 || score > 1) {
        throw new Error("score values must be between 0 and 1");
      }
    }
  }
  if (event.metadata) {
    for (const key of Object.keys(event.metadata)) {
      if (typeof key !== "string") {
        throw new Error("metadata keys must be strings");
      }
    }
  }
  if (event.metrics) {
    for (const [key, value] of Object.entries(event.metrics)) {
      if (typeof key !== "string") {
        throw new Error("metric keys must be strings");
      }
      if (value !== void 0 && typeof value !== "number") {
        throw new Error("metric values must be numbers");
      }
    }
  }
  if ("input" in event && event.input && "inputs" in event && event.inputs) {
    throw new Error(
      "Only one of input or inputs (deprecated) can be specified. Prefer input."
    );
  }
  if ("tags" in event && event.tags) {
    validateTags(event.tags);
  }
  if ("inputs" in event) {
    const { inputs, ...rest } = event;
    return { input: inputs, ...rest };
  } else {
    return { ...event };
  }
}
function deepCopyEvent(event) {
  const attachments = [];
  const IDENTIFIER = "_bt_internal_saved_attachment";
  const savedAttachmentSchema = import_zod2.z.strictObject({ [IDENTIFIER]: import_zod2.z.number() });
  const serialized = JSON.stringify(event, (_k, v) => {
    if (v instanceof SpanImpl || v instanceof NoopSpan) {
      return `<span>`;
    } else if (v instanceof Experiment) {
      return `<experiment>`;
    } else if (v instanceof Dataset) {
      return `<dataset>`;
    } else if (v instanceof Logger) {
      return `<logger>`;
    } else if (v instanceof Attachment) {
      const idx = attachments.push(v);
      return { [IDENTIFIER]: idx - 1 };
    }
    return v;
  });
  const x = JSON.parse(serialized, (_k, v) => {
    const parsedAttachment = savedAttachmentSchema.safeParse(v);
    if (parsedAttachment.success) {
      return attachments[parsedAttachment.data[IDENTIFIER]];
    }
    return v;
  });
  return x;
}
function extractAttachments(event, attachments) {
  for (const [key, value] of Object.entries(event)) {
    if (value instanceof Attachment) {
      attachments.push(value);
      event[key] = value.reference;
      continue;
    }
    if (!(value instanceof Object)) {
      continue;
    }
    extractAttachments(value, attachments);
  }
}
function validateAndSanitizeExperimentLogFullArgs(event, hasDataset) {
  if ("input" in event && !isEmpty(event.input) && "inputs" in event && !isEmpty(event.inputs) || !("input" in event) && !("inputs" in event)) {
    throw new Error(
      "Exactly one of input or inputs (deprecated) must be specified. Prefer input."
    );
  }
  if (isEmpty(event.output)) {
    throw new Error("output must be specified");
  }
  if (isEmpty(event.scores)) {
    throw new Error("scores must be specified");
  }
  if (hasDataset && event.datasetRecordId === void 0) {
    throw new Error("datasetRecordId must be specified when using a dataset");
  } else if (!hasDataset && event.datasetRecordId !== void 0) {
    throw new Error(
      "datasetRecordId cannot be specified when not using a dataset"
    );
  }
  return event;
}
var ObjectFetcher = class {
  constructor(objectType, pinnedVersion, mutateRecord) {
    this.objectType = objectType;
    this.pinnedVersion = pinnedVersion;
    this.mutateRecord = mutateRecord;
  }
  _fetchedData = void 0;
  get id() {
    throw new Error("ObjectFetcher subclasses must have an 'id' attribute");
  }
  async getState() {
    throw new Error("ObjectFetcher subclasses must have a 'getState' method");
  }
  async *fetch() {
    const records = await this.fetchedData();
    for (const record of records) {
      yield record;
    }
  }
  [Symbol.asyncIterator]() {
    return this.fetch();
  }
  async fetchedData() {
    if (this._fetchedData === void 0) {
      const state = await this.getState();
      const resp = await state.apiConn().get(
        `v1/${this.objectType}/${await this.id}/fetch`,
        {
          version: this.pinnedVersion
        },
        { headers: { "Accept-Encoding": "gzip" } }
      );
      const data = (await resp.json()).events;
      this._fetchedData = this.mutateRecord ? data?.map(this.mutateRecord) : data;
    }
    return this._fetchedData || [];
  }
  clearCache() {
    this._fetchedData = void 0;
  }
  async version() {
    if (this.pinnedVersion !== void 0) {
      return this.pinnedVersion;
    } else {
      const fetchedData = await this.fetchedData();
      let maxVersion = void 0;
      for (const record of fetchedData) {
        const xactId = String(record[import_core.TRANSACTION_ID_FIELD] ?? "0");
        if (maxVersion === void 0 || xactId > maxVersion) {
          maxVersion = xactId;
        }
      }
      return maxVersion;
    }
  }
};
var Experiment = class extends ObjectFetcher {
  lazyMetadata;
  dataset;
  lastStartTime;
  lazyId;
  calledStartSpan;
  state;
  // For type identification.
  kind = "experiment";
  constructor(state, lazyMetadata, dataset) {
    super("experiment", void 0);
    this.lazyMetadata = lazyMetadata;
    this.dataset = dataset;
    this.lastStartTime = getCurrentUnixTimestamp();
    this.lazyId = new LazyValue(async () => await this.id);
    this.calledStartSpan = false;
    this.state = state;
  }
  get id() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.id;
    })();
  }
  get name() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.name;
    })();
  }
  get project() {
    return (async () => {
      return (await this.lazyMetadata.get()).project;
    })();
  }
  parentObjectType() {
    return import_core.SpanObjectTypeV3.EXPERIMENT;
  }
  async getState() {
    await this.lazyMetadata.get();
    return this.state;
  }
  /**
   * Log a single event to the experiment. The event will be batched and uploaded behind the scenes.
   *
   * @param event The event to log.
   * @param event.input: The arguments that uniquely define a test case (an arbitrary, JSON serializable object). Later on, Braintrust will use the `input` to know whether two test cases are the same between experiments, so they should not contain experiment-specific state. A simple rule of thumb is that if you run the same experiment twice, the `input` should be identical.
   * @param event.output: The output of your application, including post-processing (an arbitrary, JSON serializable object), that allows you to determine whether the result is correct or not. For example, in an app that generates SQL queries, the `output` should be the _result_ of the SQL query generated by the model, not the query itself, because there may be multiple valid queries that answer a single question.
   * @param event.expected: (Optional) The ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not. Braintrust currently does not compare `output` to `expected` for you, since there are so many different ways to do that correctly. Instead, these values are just used to help you navigate your experiments while digging into analyses. However, we may later use these values to re-score outputs or fine-tune your models.
   * @param event.error: (Optional) The error that occurred, if any. If you use tracing to run an experiment, errors are automatically logged when your code throws an exception.
   * @param event.scores: A dictionary of numeric values (between 0 and 1) to log. The scores should give you a variety of signals that help you determine how accurate the outputs are compared to what you expect and diagnose failures. For example, a summarization app might have one score that tells you how accurate the summary is, and another that measures the word similarity between the generated and grouth truth summary. The word similarity score could help you determine whether the summarization was covering similar concepts or not. You can use these scores to help you sort, filter, and compare experiments.
   * @param event.metadata: (Optional) a dictionary with additional data about the test example, model outputs, or just about anything else that's relevant, that you can use to help find and analyze examples later. For example, you could log the `prompt`, example's `id`, or anything else that would be useful to slice/dice later. The values in `metadata` can be any JSON-serializable type, but its keys must be strings.
   * @param event.metrics: (Optional) a dictionary of metrics to log. The following keys are populated automatically: "start", "end".
   * @param event.id: (Optional) a unique identifier for the event. If you don't provide one, BrainTrust will generate one for you.
   * @param event.dataset_record_id: (Optional) the id of the dataset record that this event is associated with. This field is required if and only if the experiment is associated with a dataset.
   * @param options Additional logging options
   * @param options.allowConcurrentWithSpans in rare cases where you need to log at the top level separately from spans on the experiment elsewhere, set this to true.
   * @returns The `id` of the logged event.
   */
  log(event, options) {
    if (this.calledStartSpan && !options?.allowConcurrentWithSpans) {
      throw new Error(
        "Cannot run toplevel `log` method while using spans. To log to the span, call `experiment.traced` and then log with `span.log`"
      );
    }
    event = validateAndSanitizeExperimentLogFullArgs(event, !!this.dataset);
    const span = this.startSpanImpl({ startTime: this.lastStartTime, event });
    this.lastStartTime = span.end();
    return span.id;
  }
  /**
   * Create a new toplevel span underneath the experiment. The name defaults to "root".
   *
   * See {@link Span.traced} for full details.
   */
  traced(callback, args) {
    const { setCurrent, ...argsRest } = args ?? {};
    const span = this.startSpan(argsRest);
    const ret = runCatchFinally(
      () => {
        if (setCurrent ?? true) {
          return withCurrent(span, callback);
        } else {
          return callback(span);
        }
      },
      (e) => {
        logError(span, e);
        throw e;
      },
      () => span.end()
    );
    return ret;
  }
  /**
   * Lower-level alternative to `traced`. This allows you to start a span yourself, and can be useful in situations
   * where you cannot use callbacks. However, spans started with `startSpan` will not be marked as the "current span",
   * so `currentSpan()` and `traced()` will be no-ops. If you want to mark a span as current, use `traced` instead.
   *
   * See {@link traced} for full details.
   */
  startSpan(args) {
    this.calledStartSpan = true;
    return this.startSpanImpl(args);
  }
  startSpanImpl(args) {
    return new SpanImpl({
      state: this.state,
      ...args,
      ...startSpanParentArgs({
        state: this.state,
        parent: args?.parent,
        parentObjectType: this.parentObjectType(),
        parentObjectId: this.lazyId,
        parentComputeObjectMetadataArgs: void 0,
        parentSpanIds: void 0,
        propagatedEvent: args?.propagatedEvent
      }),
      defaultRootType: import_core.SpanTypeAttribute.EVAL
    });
  }
  async fetchBaseExperiment() {
    const state = await this.getState();
    const conn = state.appConn();
    try {
      const resp = await conn.post("/api/base_experiment/get_id", {
        id: await this.id
      });
      const base = await resp.json();
      return {
        id: base["base_exp_id"],
        name: base["base_exp_name"]
      };
    } catch (e) {
      if (e instanceof FailedHTTPResponse && e.status === 400) {
        return null;
      } else {
        throw e;
      }
    }
  }
  /**
   * Summarize the experiment, including the scores (compared to the closest reference experiment) and metadata.
   *
   * @param options Options for summarizing the experiment.
   * @param options.summarizeScores Whether to summarize the scores. If False, only the metadata will be returned.
   * @param options.comparisonExperimentId The experiment to compare against. If None, the most recent experiment on the origin's main branch will be used.
   * @returns A summary of the experiment, including the scores (compared to the closest reference experiment) and metadata.
   */
  async summarize(options = {}) {
    let { summarizeScores = true, comparisonExperimentId = void 0 } = options || {};
    await this.flush();
    const state = await this.getState();
    const projectUrl = `${state.appPublicUrl}/app/${encodeURIComponent(
      state.orgName
    )}/p/${encodeURIComponent((await this.project).name)}`;
    const experimentUrl = `${projectUrl}/experiments/${encodeURIComponent(
      await this.name
    )}`;
    let scores = void 0;
    let metrics = void 0;
    let comparisonExperimentName = void 0;
    if (summarizeScores) {
      if (comparisonExperimentId === void 0) {
        const baseExperiment = await this.fetchBaseExperiment();
        if (baseExperiment !== null) {
          comparisonExperimentId = baseExperiment.id;
          comparisonExperimentName = baseExperiment.name;
        }
      }
      const results = await state.apiConn().get_json(
        "/experiment-comparison2",
        {
          experiment_id: await this.id,
          base_experiment_id: comparisonExperimentId
        },
        3
      );
      scores = results["scores"];
      metrics = results["metrics"];
    }
    return {
      projectName: (await this.project).name,
      experimentName: await this.name,
      projectId: (await this.project).id,
      experimentId: await this.id,
      projectUrl,
      experimentUrl,
      comparisonExperimentName,
      scores: scores ?? {},
      metrics
    };
  }
  /**
   * Log feedback to an event in the experiment. Feedback is used to save feedback scores, set an expected value, or add a comment.
   *
   * @param event
   * @param event.id The id of the event to log feedback for. This is the `id` returned by `log` or accessible as the `id` field of a span.
   * @param event.scores (Optional) a dictionary of numeric values (between 0 and 1) to log. These scores will be merged into the existing scores for the event.
   * @param event.expected (Optional) the ground truth value (an arbitrary, JSON serializable object) that you'd compare to `output` to determine if your `output` value is correct or not.
   * @param event.comment (Optional) an optional comment string to log about the event.
   * @param event.metadata (Optional) a dictionary with additional data about the feedback. If you have a `user_id`, you can log it here and access it in the Braintrust UI. Note, this metadata does not correspond to the main event itself, but rather the audit log attached to the event.
   * @param event.source (Optional) the source of the feedback. Must be one of "external" (default), "app", or "api".
   */
  logFeedback(event) {
    logFeedbackImpl(this.state, this.parentObjectType(), this.lazyId, event);
  }
  /**
   * Update a span in the experiment using its id. It is important that you only update a span once the original span has been fully written and flushed,
   * since otherwise updates to the span may conflict with the original span.
   *
   * @param event The event data to update the span with. Must include `id`. See {@link Experiment.log} for a full list of valid fields.
   */
  updateSpan(event) {
    const { id, ...eventRest } = event;
    if (!id) {
      throw new Error("Span id is required to update a span");
    }
    updateSpanImpl({
      state: this.state,
      parentObjectType: this.parentObjectType(),
      parentObjectId: this.lazyId,
      id,
      event: eventRest
    });
  }
  /**
   * Return a serialized representation of the experiment that can be used to start subspans in other places.
   *
   * See {@link Span.startSpan} for more details.
   */
  async export() {
    return new import_core.SpanComponentsV3({
      object_type: this.parentObjectType(),
      object_id: await this.id
    }).toStr();
  }
  /**
   * Flush any pending rows to the server.
   */
  async flush() {
    return await this.state.bgLogger().flush();
  }
  /**
   * @deprecated This function is deprecated. You can simply remove it from your code.
   */
  async close() {
    console.warn(
      "close is deprecated and will be removed in a future version of braintrust. It is now a no-op and can be removed"
    );
    return this.id;
  }
};
var ReadonlyExperiment = class extends ObjectFetcher {
  constructor(state, lazyMetadata) {
    super("experiment", void 0);
    this.state = state;
    this.lazyMetadata = lazyMetadata;
  }
  get id() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.id;
    })();
  }
  get name() {
    return (async () => {
      return (await this.lazyMetadata.get()).experiment.name;
    })();
  }
  async getState() {
    await this.lazyMetadata.get();
    return this.state;
  }
  async *asDataset() {
    const records = this.fetch();
    for await (const record of records) {
      if (record.root_span_id !== record.span_id) {
        continue;
      }
      const { output, expected: expectedRecord } = record;
      const expected = expectedRecord ?? output;
      if (isEmpty(expected)) {
        yield {
          input: record.input,
          tags: record.tags
        };
      } else {
        yield {
          input: record.input,
          expected,
          tags: record.tags
        };
      }
    }
  }
};
var executionCounter = 0;
function newId() {
  return (0, import_uuid.v4)();
}
var SpanImpl = class _SpanImpl {
  state;
  isMerge;
  loggedEndTime;
  propagatedEvent;
  // For internal use only.
  parentObjectType;
  parentObjectId;
  parentComputeObjectMetadataArgs;
  _id;
  spanId;
  rootSpanId;
  spanParents;
  kind = "span";
  constructor(args) {
    this.state = args.state;
    const spanAttributes = args.spanAttributes ?? {};
    const rawEvent = args.event ?? {};
    const type = args.type ?? (args.parentSpanIds ? void 0 : args.defaultRootType);
    this.loggedEndTime = void 0;
    this.parentObjectType = args.parentObjectType;
    this.parentObjectId = args.parentObjectId;
    this.parentComputeObjectMetadataArgs = args.parentComputeObjectMetadataArgs;
    this.propagatedEvent = args.propagatedEvent;
    if (this.propagatedEvent) {
      (0, import_core.mergeDicts)(rawEvent, this.propagatedEvent);
    }
    const { id: eventId, ...event } = rawEvent;
    const callerLocation = isomorph_default.getCallerLocation();
    const name = (() => {
      if (args.name)
        return args.name;
      if (!args.parentSpanIds)
        return "root";
      if (callerLocation) {
        const pathComponents = callerLocation.caller_filename.split("/");
        const filename = pathComponents[pathComponents.length - 1];
        return [callerLocation.caller_functionname].concat(
          filename ? [`${filename}:${callerLocation.caller_lineno}`] : []
        ).join(":");
      }
      return "subspan";
    })();
    const internalData = {
      metrics: {
        start: args.startTime ?? getCurrentUnixTimestamp()
      },
      context: { ...callerLocation },
      span_attributes: {
        name,
        type,
        ...spanAttributes,
        exec_counter: executionCounter++
      },
      created: (/* @__PURE__ */ new Date()).toISOString()
    };
    this._id = eventId ?? (0, import_uuid.v4)();
    this.spanId = (0, import_uuid.v4)();
    if (args.parentSpanIds) {
      this.rootSpanId = args.parentSpanIds.rootSpanId;
      this.spanParents = [args.parentSpanIds.spanId];
    } else {
      this.rootSpanId = this.spanId;
      this.spanParents = void 0;
    }
    this.isMerge = false;
    this.logInternal({ event, internalData });
    this.isMerge = true;
  }
  get id() {
    return this._id;
  }
  setAttributes(args) {
    this.logInternal({ internalData: { span_attributes: args } });
  }
  log(event) {
    this.logInternal({ event });
  }
  logInternal({
    event,
    internalData
  }) {
    const [serializableInternalData, lazyInternalData] = splitLoggingData({
      event,
      internalData
    });
    const partialRecord = deepCopyEvent({
      id: this.id,
      span_id: this.spanId,
      root_span_id: this.rootSpanId,
      span_parents: this.spanParents,
      ...serializableInternalData,
      [import_core.IS_MERGE_FIELD]: this.isMerge
    });
    if (partialRecord.metrics?.end) {
      this.loggedEndTime = partialRecord.metrics?.end;
    }
    if ((partialRecord.tags ?? []).length > 0 && this.spanParents?.length) {
      throw new Error("Tags can only be logged to the root span");
    }
    const computeRecord = async () => ({
      ...partialRecord,
      ...Object.fromEntries(
        await Promise.all(
          Object.entries(lazyInternalData).map(async ([key, value]) => [
            key,
            await value.get()
          ])
        )
      ),
      ...new import_core.SpanComponentsV3({
        object_type: this.parentObjectType,
        object_id: await this.parentObjectId.get()
      }).objectIdFields()
    });
    this.state.bgLogger().log([new LazyValue(computeRecord)]);
  }
  logFeedback(event) {
    logFeedbackImpl(this.state, this.parentObjectType, this.parentObjectId, {
      ...event,
      id: this.id
    });
  }
  traced(callback, args) {
    const { setCurrent, ...argsRest } = args ?? {};
    const span = this.startSpan(argsRest);
    return runCatchFinally(
      () => {
        if (setCurrent ?? true) {
          return withCurrent(span, callback);
        } else {
          return callback(span);
        }
      },
      (e) => {
        logError(span, e);
        throw e;
      },
      () => span.end()
    );
  }
  startSpan(args) {
    const parentSpanIds = args?.parent ? void 0 : { spanId: this.spanId, rootSpanId: this.rootSpanId };
    return new _SpanImpl({
      state: this.state,
      ...args,
      ...startSpanParentArgs({
        state: this.state,
        parent: args?.parent,
        parentObjectType: this.parentObjectType,
        parentObjectId: this.parentObjectId,
        parentComputeObjectMetadataArgs: this.parentComputeObjectMetadataArgs,
        parentSpanIds,
        propagatedEvent: args?.propagatedEvent ?? this.propagatedEvent
      })
    });
  }
  end(args) {
    let endTime;
    let internalData = {};
    if (!this.loggedEndTime) {
      endTime = args?.endTime ?? getCurrentUnixTimestamp();
      internalData = { metrics: { end: endTime } };
    } else {
      endTime = this.loggedEndTime;
    }
    this.logInternal({ internalData });
    return endTime;
  }
  async export() {
    return new import_core.SpanComponentsV3({
      object_type: this.parentObjectType,
      ...this.parentComputeObjectMetadataArgs && !this.parentObjectId.hasComputed ? { compute_object_metadata_args: this.parentComputeObjectMetadataArgs } : { object_id: await this.parentObjectId.get() },
      row_id: this.id,
      span_id: this.spanId,
      root_span_id: this.rootSpanId,
      propagated_event: this.propagatedEvent
    }).toStr();
  }
  async permalink() {
    return await permalink(await this.export(), {
      state: this.state
    });
  }
  async flush() {
    return await this.state.bgLogger().flush();
  }
  close(args) {
    return this.end(args);
  }
};
function splitLoggingData({
  event,
  internalData
}) {
  const sanitized = validateAndSanitizeExperimentLogPartialArgs(event ?? {});
  const sanitizedAndInternalData = {};
  (0, import_core.mergeDicts)(sanitizedAndInternalData, internalData || {});
  (0, import_core.mergeDicts)(sanitizedAndInternalData, sanitized);
  const serializableInternalData = {};
  const lazyInternalData = {};
  for (const [key, value] of Object.entries(sanitizedAndInternalData)) {
    if (value instanceof BraintrustStream) {
      const streamCopy = value.copy();
      lazyInternalData[key] = new LazyValue(async () => {
        return await new Promise((resolve2, reject2) => {
          streamCopy.toReadableStream().pipeThrough(createFinalValuePassThroughStream(resolve2, reject2)).pipeTo(devNullWritableStream());
        });
      });
    } else if (value instanceof ReadableStream) {
      lazyInternalData[key] = new LazyValue(async () => {
        return await new Promise((resolve2, reject2) => {
          value.pipeThrough(createFinalValuePassThroughStream(resolve2, reject2)).pipeTo(devNullWritableStream());
        });
      });
    } else {
      serializableInternalData[key] = value;
    }
  }
  return [serializableInternalData, lazyInternalData];
}
var Dataset = class extends ObjectFetcher {
  constructor(state, lazyMetadata, pinnedVersion, legacy) {
    const isLegacyDataset = legacy ?? import_core.DEFAULT_IS_LEGACY_DATASET;
    if (isLegacyDataset) {
      console.warn(
        `Records will be fetched from this dataset in the legacy format, with the "expected" field renamed to "output". Please update your code to use "expected", and use \`braintrust.initDataset()\` with \`{ useOutput: false }\`, which will become the default in a future version of Braintrust.`
      );
    }
    super(
      "dataset",
      pinnedVersion,
      (r) => (0, import_core.ensureDatasetRecord)(r, isLegacyDataset)
    );
    this.state = state;
    this.lazyMetadata = lazyMetadata;
  }
  lazyMetadata;
  get id() {
    return (async () => {
      return (await this.lazyMetadata.get()).dataset.id;
    })();
  }
  get name() {
    return (async () => {
      return (await this.lazyMetadata.get()).dataset.name;
    })();
  }
  get project() {
    return (async () => {
      return (await this.lazyMetadata.get()).project;
    })();
  }
  async getState() {
    await this.lazyMetadata.get();
    return this.state;
  }
  validateEvent({
    metadata,
    expected,
    output,
    tags
  }) {
    if (metadata !== void 0) {
      for (const key of Object.keys(metadata)) {
        if (typeof key !== "string") {
          throw new Error("metadata keys must be strings");
        }
      }
    }
    if (expected !== void 0 && output !== void 0) {
      throw new Error(
        "Only one of expected or output (deprecated) can be specified. Prefer expected."
      );
    }
    if (tags) {
      validateTags(tags);
    }
  }
  createArgs({
    id,
    input,
    expected,
    metadata,
    tags,
    output,
    isMerge
  }) {
    return new LazyValue(async () => {
      const dataset_id = await this.id;
      const expectedValue = expected === void 0 ? output : expected;
      const args = {
        id,
        input,
        expected: expectedValue,
        tags,
        dataset_id,
        created: !isMerge ? (/* @__PURE__ */ new Date()).toISOString() : void 0,
        //if we're merging/updating an event we will not add this ts
        metadata,
        ...!!isMerge ? {
          [import_core.IS_MERGE_FIELD]: true
        } : {}
      };
      return args;
    });
  }
  /**
   * Insert a single record to the dataset. The record will be batched and uploaded behind the scenes. If you pass in an `id`,
   * and a record with that `id` already exists, it will be overwritten (upsert).
   *
   * @param event The event to log.
   * @param event.input The argument that uniquely define an input case (an arbitrary, JSON serializable object).
   * @param event.expected The output of your application, including post-processing (an arbitrary, JSON serializable object).
   * @param event.tags (Optional) a list of strings that you can use to filter and group records later.
   * @param event.metadata (Optional) a dictionary with additional data about the test example, model outputs, or just
   * about anything else that's relevant, that you can use to help find and analyze examples later. For example, you could log the
   * `prompt`, example's `id`, or anything else that would be useful to slice/dice later. The values in `metadata` can be any
   * JSON-serializable type, but its keys must be strings.
   * @param event.id (Optional) a unique identifier for the event. If you don't provide one, Braintrust will generate one for you.
   * @param event.output: (Deprecated) The output of your application. Use `expected` instead.
   * @returns The `id` of the logged record.
   */
  insert({
    input,
    expected,
    metadata,
    tags,
    id,
    output
  }) {
    this.validateEvent({ metadata, expected, output, tags });
    const rowId = id || (0, import_uuid.v4)();
    const args = this.createArgs(
      deepCopyEvent({
        id: rowId,
        input,
        expected,
        metadata,
        tags,
        output,
        isMerge: false
      })
    );
    this.state.bgLogger().log([args]);
    return rowId;
  }
  /**
   * Update fields of a single record in the dataset. The updated fields will be batched and uploaded behind the scenes.
   * You must pass in an `id` of the record to update. Only the fields provided will be updated; other fields will remain unchanged.
   *
   * @param event The fields to update in the record.
   * @param event.id The unique identifier of the record to update.
   * @param event.input (Optional) The new input value for the record (an arbitrary, JSON serializable object).
   * @param event.expected (Optional) The new expected output value for the record (an arbitrary, JSON serializable object).
   * @param event.tags (Optional) A list of strings to update the tags of the record.
   * @param event.metadata (Optional) A dictionary to update the metadata of the record. The values in `metadata` can be any
   * JSON-serializable type, but its keys must be strings.
   * @returns The `id` of the updated record.
   */
  update({
    input,
    expected,
    metadata,
    tags,
    id
  }) {
    this.validateEvent({ metadata, expected, tags });
    const args = this.createArgs(
      deepCopyEvent({
        id,
        input,
        expected,
        metadata,
        tags,
        isMerge: true
      })
    );
    this.state.bgLogger().log([args]);
    return id;
  }
  delete(id) {
    const args = new LazyValue(async () => ({
      id,
      dataset_id: await this.id,
      created: (/* @__PURE__ */ new Date()).toISOString(),
      _object_delete: true
    }));
    this.state.bgLogger().log([args]);
    return id;
  }
  /**
   * Summarize the dataset, including high level metrics about its size and other metadata.
   * @param summarizeData Whether to summarize the data. If false, only the metadata will be returned.
   * @returns `DatasetSummary`
   * @returns A summary of the dataset.
   */
  async summarize(options = {}) {
    const { summarizeData = true } = options || {};
    await this.flush();
    const state = await this.getState();
    const projectUrl = `${state.appPublicUrl}/app/${encodeURIComponent(
      state.orgName
    )}/p/${encodeURIComponent((await this.project).name)}`;
    const datasetUrl = `${projectUrl}/datasets/${encodeURIComponent(
      await this.name
    )}`;
    let dataSummary = void 0;
    if (summarizeData) {
      dataSummary = await state.apiConn().get_json(
        "dataset-summary",
        {
          dataset_id: await this.id
        },
        3
      );
    }
    return {
      projectName: (await this.project).name,
      datasetName: await this.name,
      projectUrl,
      datasetUrl,
      dataSummary
    };
  }
  /**
   * Flush any pending rows to the server.
   */
  async flush() {
    return await this.state.bgLogger().flush();
  }
  /**
   * @deprecated This function is deprecated. You can simply remove it from your code.
   */
  async close() {
    console.warn(
      "close is deprecated and will be removed in a future version of braintrust. It is now a no-op and can be removed"
    );
    return this.id;
  }
};
function renderMessage(render, message) {
  return {
    ...message,
    ..."content" in message ? {
      content: isEmpty(message.content) ? void 0 : typeof message.content === "string" ? render(message.content) : message.content.map((c) => {
        switch (c.type) {
          case "text":
            return { ...c, text: render(c.text) };
          case "image_url":
            return {
              ...c,
              image_url: {
                ...c.image_url,
                url: render(c.image_url.url)
              }
            };
          default:
            const _exhaustiveCheck = c;
            return _exhaustiveCheck;
        }
      })
    } : {}
  };
}
var Prompt = class {
  constructor(metadata, defaults, noTrace) {
    this.metadata = metadata;
    this.defaults = defaults;
    this.noTrace = noTrace;
  }
  parsedPromptData;
  hasParsedPromptData = false;
  get id() {
    return this.metadata.id;
  }
  get projectId() {
    return this.metadata.project_id;
  }
  get name() {
    return "name" in this.metadata ? this.metadata.name : `Playground function ${this.metadata.id}`;
  }
  get slug() {
    return "slug" in this.metadata ? this.metadata.slug : this.metadata.id;
  }
  get prompt() {
    return this.getParsedPromptData()?.prompt;
  }
  get version() {
    return this.metadata[import_core.TRANSACTION_ID_FIELD];
  }
  get options() {
    return this.getParsedPromptData()?.options || {};
  }
  /**
   * Build the prompt with the given formatting options. The args you pass in will
   * be forwarded to the mustache template that defines the prompt and rendered with
   * the `mustache-js` library.
   *
   * @param buildArgs Args to forward along to the prompt template.
   */
  build(buildArgs, options = {}) {
    return this.runBuild(buildArgs, {
      flavor: options.flavor ?? "chat",
      messages: options.messages
    });
  }
  runBuild(buildArgs, options) {
    const { flavor } = options;
    const params = {
      ...this.defaults,
      ...Object.fromEntries(
        Object.entries(this.options.params || {}).filter(
          ([k, _v]) => !import_typespecs2.BRAINTRUST_PARAMS.includes(k)
        )
      ),
      ...!isEmpty(this.options.model) ? {
        model: this.options.model
      } : {}
    };
    if (!("model" in params) || isEmpty(params.model)) {
      throw new Error(
        "No model specified. Either specify it in the prompt or as a default"
      );
    }
    const spanInfo = this.noTrace ? {} : {
      span_info: {
        metadata: {
          prompt: this.id ? {
            variables: buildArgs,
            id: this.id,
            project_id: this.projectId,
            version: this.version,
            ..."prompt_session_id" in this.metadata ? { prompt_session_id: this.metadata.prompt_session_id } : {}
          } : void 0
        }
      }
    };
    const prompt = this.prompt;
    if (!prompt) {
      throw new Error("Empty prompt");
    }
    const dictArgParsed = import_zod2.z.record(import_zod2.z.unknown()).safeParse(buildArgs);
    const variables = {
      input: buildArgs,
      ...dictArgParsed.success ? dictArgParsed.data : {}
    };
    if (flavor === "chat") {
      if (prompt.type !== "chat") {
        throw new Error(
          "Prompt is a completion prompt. Use buildCompletion() instead"
        );
      }
      const render = (template) => import_mustache.default.render(template, variables, void 0, {
        escape: (v) => typeof v === "string" ? v : JSON.stringify(v)
      });
      const messages = [
        ...(prompt.messages || []).map((m) => renderMessage(render, m)),
        ...options.messages ?? []
      ];
      return {
        ...params,
        ...spanInfo,
        messages,
        ...prompt.tools?.trim() ? {
          tools: import_typespecs2.toolsSchema.parse(
            JSON.parse(import_mustache.default.render(prompt.tools, variables))
          )
        } : void 0
      };
    } else if (flavor === "completion") {
      if (prompt.type !== "completion") {
        throw new Error(`Prompt is a chat prompt. Use flavor: 'chat' instead`);
      }
      if (options.messages) {
        throw new Error(
          "extra messages are not supported for completion prompts"
        );
      }
      return {
        ...params,
        ...spanInfo,
        prompt: import_mustache.default.render(prompt.content, variables)
      };
    } else {
      throw new Error("never!");
    }
  }
  getParsedPromptData() {
    if (!this.hasParsedPromptData) {
      this.parsedPromptData = import_typespecs2.promptDataSchema.parse(this.metadata.prompt_data);
      this.hasParsedPromptData = true;
    }
    return this.parsedPromptData;
  }
};

// src/progress.ts
var cliProgress = __toESM(require("cli-progress"));
var MAX_NAME_LENGTH = 40;
function fitNameToSpaces(name, length) {
  const padded = name.padEnd(length);
  if (padded.length <= length) {
    return padded;
  }
  return padded.substring(0, length - 3) + "...";
}
var SimpleProgressReporter = class {
  start(name, _total) {
    console.log(`Running evaluator ${name}`);
  }
  stop() {
  }
  increment(_name) {
  }
};
var BarProgressReporter = class {
  multiBar;
  bars = {};
  constructor() {
    this.multiBar = new cliProgress.MultiBar(
      {
        clearOnComplete: false,
        format: " {bar} | {evaluator} | {percentage}% | {value}/{total} datapoints",
        autopadding: true
      },
      cliProgress.Presets.shades_grey
    );
  }
  start(name, total) {
    const bar = this.multiBar.create(total, 0);
    this.bars[name] = bar;
  }
  stop() {
    this.multiBar.stop();
  }
  increment(name) {
    this.bars[name].increment({
      evaluator: fitNameToSpaces(name, MAX_NAME_LENGTH)
    });
  }
};

// src/framework.ts
var import_chalk = __toESM(require("chalk"));
var import_core2 = require("@braintrust/core");
var import_pluralize = __toESM(require("pluralize"));

// ../../node_modules/.pnpm/async@3.2.5/node_modules/async/dist/async.mjs
function initialParams(fn) {
  return function(...args) {
    var callback = args.pop();
    return fn.call(this, args, callback);
  };
}
var hasQueueMicrotask = typeof queueMicrotask === "function" && queueMicrotask;
var hasSetImmediate = typeof setImmediate === "function" && setImmediate;
var hasNextTick = typeof process === "object" && typeof process.nextTick === "function";
function fallback(fn) {
  setTimeout(fn, 0);
}
function wrap(defer) {
  return (fn, ...args) => defer(() => fn(...args));
}
var _defer$1;
if (hasQueueMicrotask) {
  _defer$1 = queueMicrotask;
} else if (hasSetImmediate) {
  _defer$1 = setImmediate;
} else if (hasNextTick) {
  _defer$1 = process.nextTick;
} else {
  _defer$1 = fallback;
}
var setImmediate$1 = wrap(_defer$1);
function asyncify(func) {
  if (isAsync(func)) {
    return function(...args) {
      const callback = args.pop();
      const promise = func.apply(this, args);
      return handlePromise(promise, callback);
    };
  }
  return initialParams(function(args, callback) {
    var result;
    try {
      result = func.apply(this, args);
    } catch (e) {
      return callback(e);
    }
    if (result && typeof result.then === "function") {
      return handlePromise(result, callback);
    } else {
      callback(null, result);
    }
  });
}
function handlePromise(promise, callback) {
  return promise.then((value) => {
    invokeCallback(callback, null, value);
  }, (err) => {
    invokeCallback(callback, err && (err instanceof Error || err.message) ? err : new Error(err));
  });
}
function invokeCallback(callback, error2, value) {
  try {
    callback(error2, value);
  } catch (err) {
    setImmediate$1((e) => {
      throw e;
    }, err);
  }
}
function isAsync(fn) {
  return fn[Symbol.toStringTag] === "AsyncFunction";
}
function isAsyncGenerator(fn) {
  return fn[Symbol.toStringTag] === "AsyncGenerator";
}
function isAsyncIterable(obj) {
  return typeof obj[Symbol.asyncIterator] === "function";
}
function wrapAsync(asyncFn) {
  if (typeof asyncFn !== "function")
    throw new Error("expected a function");
  return isAsync(asyncFn) ? asyncify(asyncFn) : asyncFn;
}
function awaitify(asyncFn, arity) {
  if (!arity)
    arity = asyncFn.length;
  if (!arity)
    throw new Error("arity is undefined");
  function awaitable(...args) {
    if (typeof args[arity - 1] === "function") {
      return asyncFn.apply(this, args);
    }
    return new Promise((resolve2, reject2) => {
      args[arity - 1] = (err, ...cbArgs) => {
        if (err)
          return reject2(err);
        resolve2(cbArgs.length > 1 ? cbArgs : cbArgs[0]);
      };
      asyncFn.apply(this, args);
    });
  }
  return awaitable;
}
function applyEach$1(eachfn) {
  return function applyEach2(fns, ...callArgs) {
    const go = awaitify(function(callback) {
      var that = this;
      return eachfn(fns, (fn, cb) => {
        wrapAsync(fn).apply(that, callArgs.concat(cb));
      }, callback);
    });
    return go;
  };
}
function _asyncMap(eachfn, arr, iteratee, callback) {
  arr = arr || [];
  var results = [];
  var counter = 0;
  var _iteratee = wrapAsync(iteratee);
  return eachfn(arr, (value, _, iterCb) => {
    var index = counter++;
    _iteratee(value, (err, v) => {
      results[index] = v;
      iterCb(err);
    });
  }, (err) => {
    callback(err, results);
  });
}
function isArrayLike(value) {
  return value && typeof value.length === "number" && value.length >= 0 && value.length % 1 === 0;
}
var breakLoop = {};
var breakLoop$1 = breakLoop;
function once(fn) {
  function wrapper(...args) {
    if (fn === null)
      return;
    var callFn = fn;
    fn = null;
    callFn.apply(this, args);
  }
  Object.assign(wrapper, fn);
  return wrapper;
}
function getIterator(coll) {
  return coll[Symbol.iterator] && coll[Symbol.iterator]();
}
function createArrayIterator(coll) {
  var i = -1;
  var len = coll.length;
  return function next() {
    return ++i < len ? { value: coll[i], key: i } : null;
  };
}
function createES2015Iterator(iterator) {
  var i = -1;
  return function next() {
    var item = iterator.next();
    if (item.done)
      return null;
    i++;
    return { value: item.value, key: i };
  };
}
function createObjectIterator(obj) {
  var okeys = obj ? Object.keys(obj) : [];
  var i = -1;
  var len = okeys.length;
  return function next() {
    var key = okeys[++i];
    if (key === "__proto__") {
      return next();
    }
    return i < len ? { value: obj[key], key } : null;
  };
}
function createIterator(coll) {
  if (isArrayLike(coll)) {
    return createArrayIterator(coll);
  }
  var iterator = getIterator(coll);
  return iterator ? createES2015Iterator(iterator) : createObjectIterator(coll);
}
function onlyOnce(fn) {
  return function(...args) {
    if (fn === null)
      throw new Error("Callback was already called.");
    var callFn = fn;
    fn = null;
    callFn.apply(this, args);
  };
}
function asyncEachOfLimit(generator, limit, iteratee, callback) {
  let done = false;
  let canceled = false;
  let awaiting = false;
  let running = 0;
  let idx = 0;
  function replenish() {
    if (running >= limit || awaiting || done)
      return;
    awaiting = true;
    generator.next().then(({ value, done: iterDone }) => {
      if (canceled || done)
        return;
      awaiting = false;
      if (iterDone) {
        done = true;
        if (running <= 0) {
          callback(null);
        }
        return;
      }
      running++;
      iteratee(value, idx, iterateeCallback);
      idx++;
      replenish();
    }).catch(handleError);
  }
  function iterateeCallback(err, result) {
    running -= 1;
    if (canceled)
      return;
    if (err)
      return handleError(err);
    if (err === false) {
      done = true;
      canceled = true;
      return;
    }
    if (result === breakLoop$1 || done && running <= 0) {
      done = true;
      return callback(null);
    }
    replenish();
  }
  function handleError(err) {
    if (canceled)
      return;
    awaiting = false;
    done = true;
    callback(err);
  }
  replenish();
}
var eachOfLimit$2 = (limit) => {
  return (obj, iteratee, callback) => {
    callback = once(callback);
    if (limit <= 0) {
      throw new RangeError("concurrency limit cannot be less than 1");
    }
    if (!obj) {
      return callback(null);
    }
    if (isAsyncGenerator(obj)) {
      return asyncEachOfLimit(obj, limit, iteratee, callback);
    }
    if (isAsyncIterable(obj)) {
      return asyncEachOfLimit(obj[Symbol.asyncIterator](), limit, iteratee, callback);
    }
    var nextElem = createIterator(obj);
    var done = false;
    var canceled = false;
    var running = 0;
    var looping = false;
    function iterateeCallback(err, value) {
      if (canceled)
        return;
      running -= 1;
      if (err) {
        done = true;
        callback(err);
      } else if (err === false) {
        done = true;
        canceled = true;
      } else if (value === breakLoop$1 || done && running <= 0) {
        done = true;
        return callback(null);
      } else if (!looping) {
        replenish();
      }
    }
    function replenish() {
      looping = true;
      while (running < limit && !done) {
        var elem = nextElem();
        if (elem === null) {
          done = true;
          if (running <= 0) {
            callback(null);
          }
          return;
        }
        running += 1;
        iteratee(elem.value, elem.key, onlyOnce(iterateeCallback));
      }
      looping = false;
    }
    replenish();
  };
};
function eachOfLimit(coll, limit, iteratee, callback) {
  return eachOfLimit$2(limit)(coll, wrapAsync(iteratee), callback);
}
var eachOfLimit$1 = awaitify(eachOfLimit, 4);
function eachOfArrayLike(coll, iteratee, callback) {
  callback = once(callback);
  var index = 0, completed = 0, { length } = coll, canceled = false;
  if (length === 0) {
    callback(null);
  }
  function iteratorCallback(err, value) {
    if (err === false) {
      canceled = true;
    }
    if (canceled === true)
      return;
    if (err) {
      callback(err);
    } else if (++completed === length || value === breakLoop$1) {
      callback(null);
    }
  }
  for (; index < length; index++) {
    iteratee(coll[index], index, onlyOnce(iteratorCallback));
  }
}
function eachOfGeneric(coll, iteratee, callback) {
  return eachOfLimit$1(coll, Infinity, iteratee, callback);
}
function eachOf(coll, iteratee, callback) {
  var eachOfImplementation = isArrayLike(coll) ? eachOfArrayLike : eachOfGeneric;
  return eachOfImplementation(coll, wrapAsync(iteratee), callback);
}
var eachOf$1 = awaitify(eachOf, 3);
function map(coll, iteratee, callback) {
  return _asyncMap(eachOf$1, coll, iteratee, callback);
}
var map$1 = awaitify(map, 3);
var applyEach = applyEach$1(map$1);
function eachOfSeries(coll, iteratee, callback) {
  return eachOfLimit$1(coll, 1, iteratee, callback);
}
var eachOfSeries$1 = awaitify(eachOfSeries, 3);
function mapSeries(coll, iteratee, callback) {
  return _asyncMap(eachOfSeries$1, coll, iteratee, callback);
}
var mapSeries$1 = awaitify(mapSeries, 3);
var applyEachSeries = applyEach$1(mapSeries$1);
var PROMISE_SYMBOL = Symbol("promiseCallback");
var DLL = class {
  constructor() {
    this.head = this.tail = null;
    this.length = 0;
  }
  removeLink(node) {
    if (node.prev)
      node.prev.next = node.next;
    else
      this.head = node.next;
    if (node.next)
      node.next.prev = node.prev;
    else
      this.tail = node.prev;
    node.prev = node.next = null;
    this.length -= 1;
    return node;
  }
  empty() {
    while (this.head)
      this.shift();
    return this;
  }
  insertAfter(node, newNode) {
    newNode.prev = node;
    newNode.next = node.next;
    if (node.next)
      node.next.prev = newNode;
    else
      this.tail = newNode;
    node.next = newNode;
    this.length += 1;
  }
  insertBefore(node, newNode) {
    newNode.prev = node.prev;
    newNode.next = node;
    if (node.prev)
      node.prev.next = newNode;
    else
      this.head = newNode;
    node.prev = newNode;
    this.length += 1;
  }
  unshift(node) {
    if (this.head)
      this.insertBefore(this.head, node);
    else
      setInitial(this, node);
  }
  push(node) {
    if (this.tail)
      this.insertAfter(this.tail, node);
    else
      setInitial(this, node);
  }
  shift() {
    return this.head && this.removeLink(this.head);
  }
  pop() {
    return this.tail && this.removeLink(this.tail);
  }
  toArray() {
    return [...this];
  }
  *[Symbol.iterator]() {
    var cur = this.head;
    while (cur) {
      yield cur.data;
      cur = cur.next;
    }
  }
  remove(testFn) {
    var curr = this.head;
    while (curr) {
      var { next } = curr;
      if (testFn(curr)) {
        this.removeLink(curr);
      }
      curr = next;
    }
    return this;
  }
};
function setInitial(dll, node) {
  dll.length = 1;
  dll.head = dll.tail = node;
}
function queue$1(worker, concurrency, payload) {
  if (concurrency == null) {
    concurrency = 1;
  } else if (concurrency === 0) {
    throw new RangeError("Concurrency must not be zero");
  }
  var _worker = wrapAsync(worker);
  var numRunning = 0;
  var workersList = [];
  const events = {
    error: [],
    drain: [],
    saturated: [],
    unsaturated: [],
    empty: []
  };
  function on(event, handler) {
    events[event].push(handler);
  }
  function once2(event, handler) {
    const handleAndRemove = (...args) => {
      off(event, handleAndRemove);
      handler(...args);
    };
    events[event].push(handleAndRemove);
  }
  function off(event, handler) {
    if (!event)
      return Object.keys(events).forEach((ev) => events[ev] = []);
    if (!handler)
      return events[event] = [];
    events[event] = events[event].filter((ev) => ev !== handler);
  }
  function trigger(event, ...args) {
    events[event].forEach((handler) => handler(...args));
  }
  var processingScheduled = false;
  function _insert(data, insertAtFront, rejectOnError, callback) {
    if (callback != null && typeof callback !== "function") {
      throw new Error("task callback must be a function");
    }
    q.started = true;
    var res, rej;
    function promiseCallback(err, ...args) {
      if (err)
        return rejectOnError ? rej(err) : res();
      if (args.length <= 1)
        return res(args[0]);
      res(args);
    }
    var item = q._createTaskItem(
      data,
      rejectOnError ? promiseCallback : callback || promiseCallback
    );
    if (insertAtFront) {
      q._tasks.unshift(item);
    } else {
      q._tasks.push(item);
    }
    if (!processingScheduled) {
      processingScheduled = true;
      setImmediate$1(() => {
        processingScheduled = false;
        q.process();
      });
    }
    if (rejectOnError || !callback) {
      return new Promise((resolve2, reject2) => {
        res = resolve2;
        rej = reject2;
      });
    }
  }
  function _createCB(tasks) {
    return function(err, ...args) {
      numRunning -= 1;
      for (var i = 0, l = tasks.length; i < l; i++) {
        var task = tasks[i];
        var index = workersList.indexOf(task);
        if (index === 0) {
          workersList.shift();
        } else if (index > 0) {
          workersList.splice(index, 1);
        }
        task.callback(err, ...args);
        if (err != null) {
          trigger("error", err, task.data);
        }
      }
      if (numRunning <= q.concurrency - q.buffer) {
        trigger("unsaturated");
      }
      if (q.idle()) {
        trigger("drain");
      }
      q.process();
    };
  }
  function _maybeDrain(data) {
    if (data.length === 0 && q.idle()) {
      setImmediate$1(() => trigger("drain"));
      return true;
    }
    return false;
  }
  const eventMethod = (name) => (handler) => {
    if (!handler) {
      return new Promise((resolve2, reject2) => {
        once2(name, (err, data) => {
          if (err)
            return reject2(err);
          resolve2(data);
        });
      });
    }
    off(name);
    on(name, handler);
  };
  var isProcessing = false;
  var q = {
    _tasks: new DLL(),
    _createTaskItem(data, callback) {
      return {
        data,
        callback
      };
    },
    *[Symbol.iterator]() {
      yield* q._tasks[Symbol.iterator]();
    },
    concurrency,
    payload,
    buffer: concurrency / 4,
    started: false,
    paused: false,
    push(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, false, false, callback));
      }
      return _insert(data, false, false, callback);
    },
    pushAsync(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, false, true, callback));
      }
      return _insert(data, false, true, callback);
    },
    kill() {
      off();
      q._tasks.empty();
    },
    unshift(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, true, false, callback));
      }
      return _insert(data, true, false, callback);
    },
    unshiftAsync(data, callback) {
      if (Array.isArray(data)) {
        if (_maybeDrain(data))
          return;
        return data.map((datum) => _insert(datum, true, true, callback));
      }
      return _insert(data, true, true, callback);
    },
    remove(testFn) {
      q._tasks.remove(testFn);
    },
    process() {
      if (isProcessing) {
        return;
      }
      isProcessing = true;
      while (!q.paused && numRunning < q.concurrency && q._tasks.length) {
        var tasks = [], data = [];
        var l = q._tasks.length;
        if (q.payload)
          l = Math.min(l, q.payload);
        for (var i = 0; i < l; i++) {
          var node = q._tasks.shift();
          tasks.push(node);
          workersList.push(node);
          data.push(node.data);
        }
        numRunning += 1;
        if (q._tasks.length === 0) {
          trigger("empty");
        }
        if (numRunning === q.concurrency) {
          trigger("saturated");
        }
        var cb = onlyOnce(_createCB(tasks));
        _worker(data, cb);
      }
      isProcessing = false;
    },
    length() {
      return q._tasks.length;
    },
    running() {
      return numRunning;
    },
    workersList() {
      return workersList;
    },
    idle() {
      return q._tasks.length + numRunning === 0;
    },
    pause() {
      q.paused = true;
    },
    resume() {
      if (q.paused === false) {
        return;
      }
      q.paused = false;
      setImmediate$1(q.process);
    }
  };
  Object.defineProperties(q, {
    saturated: {
      writable: false,
      value: eventMethod("saturated")
    },
    unsaturated: {
      writable: false,
      value: eventMethod("unsaturated")
    },
    empty: {
      writable: false,
      value: eventMethod("empty")
    },
    drain: {
      writable: false,
      value: eventMethod("drain")
    },
    error: {
      writable: false,
      value: eventMethod("error")
    }
  });
  return q;
}
function reduce(coll, memo, iteratee, callback) {
  callback = once(callback);
  var _iteratee = wrapAsync(iteratee);
  return eachOfSeries$1(coll, (x, i, iterCb) => {
    _iteratee(memo, x, (err, v) => {
      memo = v;
      iterCb(err);
    });
  }, (err) => callback(err, memo));
}
var reduce$1 = awaitify(reduce, 4);
function mapLimit(coll, limit, iteratee, callback) {
  return _asyncMap(eachOfLimit$2(limit), coll, iteratee, callback);
}
var mapLimit$1 = awaitify(mapLimit, 4);
function concatLimit(coll, limit, iteratee, callback) {
  var _iteratee = wrapAsync(iteratee);
  return mapLimit$1(coll, limit, (val, iterCb) => {
    _iteratee(val, (err, ...args) => {
      if (err)
        return iterCb(err);
      return iterCb(err, args);
    });
  }, (err, mapResults) => {
    var result = [];
    for (var i = 0; i < mapResults.length; i++) {
      if (mapResults[i]) {
        result = result.concat(...mapResults[i]);
      }
    }
    return callback(err, result);
  });
}
var concatLimit$1 = awaitify(concatLimit, 4);
function concat(coll, iteratee, callback) {
  return concatLimit$1(coll, Infinity, iteratee, callback);
}
var concat$1 = awaitify(concat, 3);
function concatSeries(coll, iteratee, callback) {
  return concatLimit$1(coll, 1, iteratee, callback);
}
var concatSeries$1 = awaitify(concatSeries, 3);
function _createTester(check, getResult) {
  return (eachfn, arr, _iteratee, cb) => {
    var testPassed = false;
    var testResult;
    const iteratee = wrapAsync(_iteratee);
    eachfn(arr, (value, _, callback) => {
      iteratee(value, (err, result) => {
        if (err || err === false)
          return callback(err);
        if (check(result) && !testResult) {
          testPassed = true;
          testResult = getResult(true, value);
          return callback(null, breakLoop$1);
        }
        callback();
      });
    }, (err) => {
      if (err)
        return cb(err);
      cb(null, testPassed ? testResult : getResult(false));
    });
  };
}
function detect(coll, iteratee, callback) {
  return _createTester((bool) => bool, (res, item) => item)(eachOf$1, coll, iteratee, callback);
}
var detect$1 = awaitify(detect, 3);
function detectLimit(coll, limit, iteratee, callback) {
  return _createTester((bool) => bool, (res, item) => item)(eachOfLimit$2(limit), coll, iteratee, callback);
}
var detectLimit$1 = awaitify(detectLimit, 4);
function detectSeries(coll, iteratee, callback) {
  return _createTester((bool) => bool, (res, item) => item)(eachOfLimit$2(1), coll, iteratee, callback);
}
var detectSeries$1 = awaitify(detectSeries, 3);
function consoleFunc(name) {
  return (fn, ...args) => wrapAsync(fn)(...args, (err, ...resultArgs) => {
    if (typeof console === "object") {
      if (err) {
        if (console.error) {
          console.error(err);
        }
      } else if (console[name]) {
        resultArgs.forEach((x) => console[name](x));
      }
    }
  });
}
var dir = consoleFunc("dir");
function doWhilst(iteratee, test, callback) {
  callback = onlyOnce(callback);
  var _fn = wrapAsync(iteratee);
  var _test = wrapAsync(test);
  var results;
  function next(err, ...args) {
    if (err)
      return callback(err);
    if (err === false)
      return;
    results = args;
    _test(...args, check);
  }
  function check(err, truth) {
    if (err)
      return callback(err);
    if (err === false)
      return;
    if (!truth)
      return callback(null, ...results);
    _fn(next);
  }
  return check(null, true);
}
var doWhilst$1 = awaitify(doWhilst, 3);
function _withoutIndex(iteratee) {
  return (value, index, callback) => iteratee(value, callback);
}
function eachLimit$2(coll, iteratee, callback) {
  return eachOf$1(coll, _withoutIndex(wrapAsync(iteratee)), callback);
}
var each = awaitify(eachLimit$2, 3);
function eachLimit(coll, limit, iteratee, callback) {
  return eachOfLimit$2(limit)(coll, _withoutIndex(wrapAsync(iteratee)), callback);
}
var eachLimit$1 = awaitify(eachLimit, 4);
function eachSeries(coll, iteratee, callback) {
  return eachLimit$1(coll, 1, iteratee, callback);
}
var eachSeries$1 = awaitify(eachSeries, 3);
function ensureAsync(fn) {
  if (isAsync(fn))
    return fn;
  return function(...args) {
    var callback = args.pop();
    var sync = true;
    args.push((...innerArgs) => {
      if (sync) {
        setImmediate$1(() => callback(...innerArgs));
      } else {
        callback(...innerArgs);
      }
    });
    fn.apply(this, args);
    sync = false;
  };
}
function every(coll, iteratee, callback) {
  return _createTester((bool) => !bool, (res) => !res)(eachOf$1, coll, iteratee, callback);
}
var every$1 = awaitify(every, 3);
function everyLimit(coll, limit, iteratee, callback) {
  return _createTester((bool) => !bool, (res) => !res)(eachOfLimit$2(limit), coll, iteratee, callback);
}
var everyLimit$1 = awaitify(everyLimit, 4);
function everySeries(coll, iteratee, callback) {
  return _createTester((bool) => !bool, (res) => !res)(eachOfSeries$1, coll, iteratee, callback);
}
var everySeries$1 = awaitify(everySeries, 3);
function filterArray(eachfn, arr, iteratee, callback) {
  var truthValues = new Array(arr.length);
  eachfn(arr, (x, index, iterCb) => {
    iteratee(x, (err, v) => {
      truthValues[index] = !!v;
      iterCb(err);
    });
  }, (err) => {
    if (err)
      return callback(err);
    var results = [];
    for (var i = 0; i < arr.length; i++) {
      if (truthValues[i])
        results.push(arr[i]);
    }
    callback(null, results);
  });
}
function filterGeneric(eachfn, coll, iteratee, callback) {
  var results = [];
  eachfn(coll, (x, index, iterCb) => {
    iteratee(x, (err, v) => {
      if (err)
        return iterCb(err);
      if (v) {
        results.push({ index, value: x });
      }
      iterCb(err);
    });
  }, (err) => {
    if (err)
      return callback(err);
    callback(null, results.sort((a, b) => a.index - b.index).map((v) => v.value));
  });
}
function _filter(eachfn, coll, iteratee, callback) {
  var filter2 = isArrayLike(coll) ? filterArray : filterGeneric;
  return filter2(eachfn, coll, wrapAsync(iteratee), callback);
}
function filter(coll, iteratee, callback) {
  return _filter(eachOf$1, coll, iteratee, callback);
}
var filter$1 = awaitify(filter, 3);
function filterLimit(coll, limit, iteratee, callback) {
  return _filter(eachOfLimit$2(limit), coll, iteratee, callback);
}
var filterLimit$1 = awaitify(filterLimit, 4);
function filterSeries(coll, iteratee, callback) {
  return _filter(eachOfSeries$1, coll, iteratee, callback);
}
var filterSeries$1 = awaitify(filterSeries, 3);
function forever(fn, errback) {
  var done = onlyOnce(errback);
  var task = wrapAsync(ensureAsync(fn));
  function next(err) {
    if (err)
      return done(err);
    if (err === false)
      return;
    task(next);
  }
  return next();
}
var forever$1 = awaitify(forever, 2);
function groupByLimit(coll, limit, iteratee, callback) {
  var _iteratee = wrapAsync(iteratee);
  return mapLimit$1(coll, limit, (val, iterCb) => {
    _iteratee(val, (err, key) => {
      if (err)
        return iterCb(err);
      return iterCb(err, { key, val });
    });
  }, (err, mapResults) => {
    var result = {};
    var { hasOwnProperty } = Object.prototype;
    for (var i = 0; i < mapResults.length; i++) {
      if (mapResults[i]) {
        var { key } = mapResults[i];
        var { val } = mapResults[i];
        if (hasOwnProperty.call(result, key)) {
          result[key].push(val);
        } else {
          result[key] = [val];
        }
      }
    }
    return callback(err, result);
  });
}
var groupByLimit$1 = awaitify(groupByLimit, 4);
var log = consoleFunc("log");
function mapValuesLimit(obj, limit, iteratee, callback) {
  callback = once(callback);
  var newObj = {};
  var _iteratee = wrapAsync(iteratee);
  return eachOfLimit$2(limit)(obj, (val, key, next) => {
    _iteratee(val, key, (err, result) => {
      if (err)
        return next(err);
      newObj[key] = result;
      next(err);
    });
  }, (err) => callback(err, newObj));
}
var mapValuesLimit$1 = awaitify(mapValuesLimit, 4);
var _defer;
if (hasNextTick) {
  _defer = process.nextTick;
} else if (hasSetImmediate) {
  _defer = setImmediate;
} else {
  _defer = fallback;
}
var nextTick = wrap(_defer);
var _parallel = awaitify((eachfn, tasks, callback) => {
  var results = isArrayLike(tasks) ? [] : {};
  eachfn(tasks, (task, key, taskCb) => {
    wrapAsync(task)((err, ...result) => {
      if (result.length < 2) {
        [result] = result;
      }
      results[key] = result;
      taskCb(err);
    });
  }, (err) => callback(err, results));
}, 3);
function queue(worker, concurrency) {
  var _worker = wrapAsync(worker);
  return queue$1((items, cb) => {
    _worker(items[0], cb);
  }, concurrency, 1);
}
function race(tasks, callback) {
  callback = once(callback);
  if (!Array.isArray(tasks))
    return callback(new TypeError("First argument to race must be an array of functions"));
  if (!tasks.length)
    return callback();
  for (var i = 0, l = tasks.length; i < l; i++) {
    wrapAsync(tasks[i])(callback);
  }
}
var race$1 = awaitify(race, 2);
function reject$2(eachfn, arr, _iteratee, callback) {
  const iteratee = wrapAsync(_iteratee);
  return _filter(eachfn, arr, (value, cb) => {
    iteratee(value, (err, v) => {
      cb(err, !v);
    });
  }, callback);
}
function reject(coll, iteratee, callback) {
  return reject$2(eachOf$1, coll, iteratee, callback);
}
var reject$1 = awaitify(reject, 3);
function rejectLimit(coll, limit, iteratee, callback) {
  return reject$2(eachOfLimit$2(limit), coll, iteratee, callback);
}
var rejectLimit$1 = awaitify(rejectLimit, 4);
function rejectSeries(coll, iteratee, callback) {
  return reject$2(eachOfSeries$1, coll, iteratee, callback);
}
var rejectSeries$1 = awaitify(rejectSeries, 3);
function some(coll, iteratee, callback) {
  return _createTester(Boolean, (res) => res)(eachOf$1, coll, iteratee, callback);
}
var some$1 = awaitify(some, 3);
function someLimit(coll, limit, iteratee, callback) {
  return _createTester(Boolean, (res) => res)(eachOfLimit$2(limit), coll, iteratee, callback);
}
var someLimit$1 = awaitify(someLimit, 4);
function someSeries(coll, iteratee, callback) {
  return _createTester(Boolean, (res) => res)(eachOfSeries$1, coll, iteratee, callback);
}
var someSeries$1 = awaitify(someSeries, 3);
function sortBy(coll, iteratee, callback) {
  var _iteratee = wrapAsync(iteratee);
  return map$1(coll, (x, iterCb) => {
    _iteratee(x, (err, criteria) => {
      if (err)
        return iterCb(err);
      iterCb(err, { value: x, criteria });
    });
  }, (err, results) => {
    if (err)
      return callback(err);
    callback(null, results.sort(comparator).map((v) => v.value));
  });
  function comparator(left, right) {
    var a = left.criteria, b = right.criteria;
    return a < b ? -1 : a > b ? 1 : 0;
  }
}
var sortBy$1 = awaitify(sortBy, 3);
function tryEach(tasks, callback) {
  var error2 = null;
  var result;
  return eachSeries$1(tasks, (task, taskCb) => {
    wrapAsync(task)((err, ...args) => {
      if (err === false)
        return taskCb(err);
      if (args.length < 2) {
        [result] = args;
      } else {
        result = args;
      }
      error2 = err;
      taskCb(err ? null : {});
    });
  }, () => callback(error2, result));
}
var tryEach$1 = awaitify(tryEach);
function whilst(test, iteratee, callback) {
  callback = onlyOnce(callback);
  var _fn = wrapAsync(iteratee);
  var _test = wrapAsync(test);
  var results = [];
  function next(err, ...rest) {
    if (err)
      return callback(err);
    results = rest;
    if (err === false)
      return;
    _test(check);
  }
  function check(err, truth) {
    if (err)
      return callback(err);
    if (err === false)
      return;
    if (!truth)
      return callback(null, ...results);
    _fn(next);
  }
  return _test(check);
}
var whilst$1 = awaitify(whilst, 3);
function waterfall(tasks, callback) {
  callback = once(callback);
  if (!Array.isArray(tasks))
    return callback(new Error("First argument to waterfall must be an array of functions"));
  if (!tasks.length)
    return callback();
  var taskIndex = 0;
  function nextTask(args) {
    var task = wrapAsync(tasks[taskIndex++]);
    task(...args, onlyOnce(next));
  }
  function next(err, ...args) {
    if (err === false)
      return;
    if (err || taskIndex === tasks.length) {
      return callback(err, ...args);
    }
    nextTask(args);
  }
  nextTask([]);
}
var waterfall$1 = awaitify(waterfall);

// src/framework.ts
var EvalResultWithSummary = class {
  constructor(summary, results) {
    this.summary = summary;
    this.results = results;
  }
  toString() {
    return formatExperimentSummary(this.summary);
  }
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `EvalResultWithSummary(summary="...", results=[...])`;
  }
  toJSON() {
    return {
      summary: this.summary,
      results: this.results
    };
  }
};
function initExperiment(state, options = {}) {
  return init({
    state,
    ...options,
    setCurrent: false
  });
}
function callEvaluatorData(data) {
  const dataResult = typeof data === "function" ? data() : data;
  let baseExperiment = void 0;
  if ("_type" in dataResult && dataResult._type === "BaseExperiment") {
    baseExperiment = dataResult.name;
  }
  return {
    data: dataResult,
    baseExperiment
  };
}
globalThis._evals = {
  functions: [],
  prompts: [],
  evaluators: {},
  reporters: {}
};
function _initializeSpanContext() {
  globalThis._spanContext = { currentSpan, withCurrent, startSpan, NOOP_SPAN };
}
function serializeJSONWithPlainString(v) {
  if (typeof v === "string") {
    return v;
  } else {
    return JSON.stringify(v);
  }
}
function deserializePlainStringAsJSON(s) {
  try {
    return { value: JSON.parse(s), error: void 0 };
  } catch (e) {
    return { value: s, error: e };
  }
}
function parseFilters(filters) {
  const result = [];
  for (const f of filters) {
    const equalsIdx = f.indexOf("=");
    if (equalsIdx === -1) {
      throw new Error(`Invalid filter ${f}`);
    }
    const [path9, value] = [f.slice(0, equalsIdx), f.slice(equalsIdx + 1)];
    let deserializedValue = deserializePlainStringAsJSON(value).value;
    if (typeof deserializedValue !== "string") {
      deserializedValue = value;
    }
    result.push({
      path: path9.split("."),
      pattern: new RegExp(deserializedValue)
    });
  }
  return result;
}
function evaluateFilter(object, filter2) {
  const { path: path9, pattern } = filter2;
  const key = path9.reduce(
    (acc, p) => typeof acc === "object" && acc !== null ? (
      // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
      acc[p]
    ) : void 0,
    object
  );
  if (key === void 0) {
    return false;
  }
  return pattern.test(serializeJSONWithPlainString(key));
}
function scorerName(scorer, scorer_idx) {
  return scorer.name || `scorer_${scorer_idx}`;
}
async function runEvaluator(experiment, evaluator, progressReporter, filters) {
  const result = runEvaluatorInternal(
    experiment,
    evaluator,
    progressReporter,
    filters
  );
  const timer = async () => {
    await new Promise((_, reject2) => {
      if (evaluator.timeout) {
        setTimeout(() => {
          reject2("evaluator timed out");
        }, evaluator.timeout);
      }
    });
    return null;
  };
  const winner = await Promise.race([result, timer()]);
  if (!winner) {
    throw new Error("unreachable");
  }
  return winner;
}
async function runEvaluatorInternal(experiment, evaluator, progressReporter, filters) {
  if (typeof evaluator.data === "string") {
    throw new Error("Unimplemented: string data paths");
  }
  let dataResult = typeof evaluator.data === "function" ? evaluator.data() : evaluator.data;
  if ("_type" in dataResult) {
    if (dataResult._type !== "BaseExperiment") {
      throw new Error("Invalid _type");
    }
    if (!experiment) {
      throw new Error(
        "Cannot use BaseExperiment() without connecting to Braintrust (you most likely set --no-send-logs)"
      );
    }
    let name = dataResult.name;
    if (isEmpty(name)) {
      const baseExperiment = await experiment.fetchBaseExperiment();
      if (!baseExperiment) {
        throw new Error("BaseExperiment() failed to fetch base experiment");
      }
      name = baseExperiment.name;
    }
    dataResult = initExperiment(evaluator.state, {
      ...evaluator.projectId ? { projectId: evaluator.projectId } : { project: evaluator.projectName },
      experiment: name,
      open: true
    }).asDataset();
  }
  let data = [];
  if (dataResult instanceof Promise) {
    data = await dataResult;
  } else if (Symbol.asyncIterator in dataResult) {
    data = [];
    for await (const d of dataResult) {
      data.push(d);
    }
  } else {
    data = dataResult;
  }
  data = data.filter((d) => filters.every((f) => evaluateFilter(d, f))).flatMap(
    (datum) => [...Array(evaluator.trialCount ?? 1).keys()].map(() => datum)
  );
  progressReporter.start(evaluator.evalName, data.length);
  const results = [];
  const q = queue(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    async (datum) => {
      const callback = async (rootSpan) => {
        let metadata = {
          ..."metadata" in datum ? datum.metadata : {}
        };
        let output = void 0;
        let error2 = void 0;
        const scores = {};
        try {
          const meta = (o) => metadata = { ...metadata, ...o };
          await rootSpan.traced(
            async (span) => {
              const outputResult = evaluator.task(datum.input, { meta, span });
              if (outputResult instanceof Promise) {
                output = await outputResult;
              } else {
                output = outputResult;
              }
              span.log({ output });
            },
            {
              name: "task",
              spanAttributes: { type: import_core2.SpanTypeAttribute.TASK },
              event: { input: datum.input }
            }
          );
          rootSpan.log({ output, metadata });
          const scoringArgs = {
            input: datum.input,
            expected: "expected" in datum ? datum.expected : void 0,
            metadata,
            output
          };
          const scorerNames = evaluator.scores.map(scorerName);
          const scoreResults = await Promise.all(
            evaluator.scores.map(async (score, score_idx) => {
              try {
                const results2 = await rootSpan.traced(
                  async (span) => {
                    const scoreResult = score(scoringArgs);
                    const scoreValue = scoreResult instanceof Promise ? await scoreResult : scoreResult;
                    if (scoreValue === null) {
                      return null;
                    }
                    if (Array.isArray(scoreValue)) {
                      for (const s of scoreValue) {
                        if (!(typeof s === "object" && !isEmpty(s))) {
                          throw new Error(
                            `When returning an array of scores, each score must be a non-empty object. Got: ${JSON.stringify(
                              s
                            )}`
                          );
                        }
                      }
                    }
                    const results3 = Array.isArray(scoreValue) ? scoreValue : typeof scoreValue === "object" && !isEmpty(scoreValue) ? [scoreValue] : [
                      {
                        name: scorerNames[score_idx],
                        score: scoreValue
                      }
                    ];
                    const getOtherFields = (s) => {
                      const { metadata: _metadata, name: _name, ...rest } = s;
                      return rest;
                    };
                    const resultMetadata = results3.length === 1 ? results3[0].metadata : results3.reduce(
                      (prev, s) => (0, import_core2.mergeDicts)(prev, {
                        [s.name]: s.metadata
                      }),
                      {}
                    );
                    const resultOutput = results3.length === 1 ? getOtherFields(results3[0]) : results3.reduce(
                      (prev, s) => (0, import_core2.mergeDicts)(prev, { [s.name]: getOtherFields(s) }),
                      {}
                    );
                    const scores2 = results3.reduce(
                      (prev, s) => (0, import_core2.mergeDicts)(prev, { [s.name]: s.score }),
                      {}
                    );
                    span.log({
                      output: resultOutput,
                      metadata: resultMetadata,
                      scores: scores2
                    });
                    return results3;
                  },
                  {
                    name: scorerNames[score_idx],
                    spanAttributes: {
                      type: import_core2.SpanTypeAttribute.SCORE
                    },
                    event: { input: scoringArgs }
                  }
                );
                return { kind: "score", value: results2 };
              } catch (e) {
                return { kind: "error", value: e };
              }
            })
          );
          const passingScorersAndResults = [];
          const failingScorersAndResults = [];
          scoreResults.forEach((results2, i) => {
            const name = scorerNames[i];
            if (results2.kind === "score") {
              (results2.value || []).forEach((result) => {
                passingScorersAndResults.push({
                  name: result.name,
                  score: result
                });
                scores[result.name] = result.score;
              });
            } else {
              failingScorersAndResults.push({ name, error: results2.value });
            }
          });
          if (failingScorersAndResults.length) {
            const scorerErrors = Object.fromEntries(
              failingScorersAndResults.map(({ name, error: error3 }) => [
                name,
                error3 instanceof Error ? error3.stack : `${error3}`
              ])
            );
            metadata["scorer_errors"] = scorerErrors;
            rootSpan.log({ metadata: { scorer_errors: scorerErrors } });
            const names = Object.keys(scorerErrors).join(", ");
            const errors = failingScorersAndResults.map((item) => item.error);
            throw new AggregateError(
              errors,
              `Found exceptions for the following scorers: ${names}`
            );
          }
        } catch (e) {
          logError(rootSpan, e);
          error2 = e;
        } finally {
          progressReporter.increment(evaluator.evalName);
        }
        results.push({
          input: datum.input,
          ..."expected" in datum ? { expected: datum.expected } : {},
          output,
          tags: datum.tags,
          metadata,
          scores,
          error: error2
        });
      };
      if (!experiment) {
        return await callback(NOOP_SPAN);
      } else {
        return await experiment.traced(callback, {
          name: "eval",
          spanAttributes: {
            type: import_core2.SpanTypeAttribute.EVAL
          },
          event: {
            input: datum.input,
            expected: "expected" in datum ? datum.expected : void 0,
            tags: datum.tags,
            origin: experiment.dataset && datum.id && datum._xact_id ? {
              object_type: "dataset",
              object_id: await experiment.dataset.id,
              id: datum.id,
              _xact_id: datum._xact_id
            } : void 0
          }
        });
      }
    },
    Math.max(evaluator.maxConcurrency ?? data.length, 1)
  );
  q.push(data);
  await q.drain();
  const summary = experiment ? await experiment.summarize() : buildLocalSummary(evaluator, results);
  return new EvalResultWithSummary(summary, results);
}
var error = import_chalk.default.bold.red;
var warning = import_chalk.default.hex("#FFA500");
function logError2(e, verbose) {
  if (!verbose) {
    console.error(`${e}`);
  } else {
    console.error(e);
  }
}
function buildLocalSummary(evaluator, results) {
  const scoresByName = {};
  for (const result of results) {
    for (const [name, score] of Object.entries(result.scores)) {
      const { total, count } = scoresByName[name] || { total: 0, count: 0 };
      if (score === null) {
        continue;
      }
      scoresByName[name] = { total: total + score, count: count + 1 };
    }
  }
  return {
    projectName: evaluator.projectName,
    experimentName: evaluator.evalName,
    scores: Object.fromEntries(
      Object.entries(scoresByName).map(([name, { total, count }]) => [
        name,
        {
          name,
          score: total / count,
          improvements: 0,
          regressions: 0
        }
      ])
    )
  };
}
function reportFailures(evaluator, failingResults, { verbose, jsonl }) {
  if (failingResults.length > 0) {
    console.error(
      warning(
        `Evaluator ${evaluator.evalName} failed with ${(0, import_pluralize.default)(
          "error",
          failingResults.length,
          true
        )}. This evaluation ("${evaluator.evalName}") will not be fully logged.`
      )
    );
    if (jsonl) {
      console.log(
        JSON.stringify({
          evaluatorName: evaluator.evalName,
          errors: failingResults.map(
            (r) => `${r.error instanceof Error ? r.error.stack : r.error}`
          )
        })
      );
    } else {
      for (const result of failingResults) {
        logError2(result.error, verbose);
      }
    }
    if (!verbose && !jsonl) {
      console.error(warning("Add --verbose to see full stack traces."));
    }
  }
}
var defaultReporter = {
  name: "Braintrust default reporter",
  async reportEval(evaluator, result, { verbose, jsonl }) {
    const { results, summary } = result;
    const failingResults = results.filter(
      (r) => r.error !== void 0
    );
    if (failingResults.length > 0) {
      reportFailures(evaluator, failingResults, { verbose, jsonl });
    }
    process.stdout.write(
      jsonl ? JSON.stringify(summary) : formatExperimentSummary(summary)
    );
    process.stdout.write("\n");
    return failingResults.length === 0;
  },
  async reportRun(evalReports) {
    return evalReports.every((r) => r);
  }
};
function formatExperimentSummary(summary) {
  let comparisonLine = "";
  if (summary.comparisonExperimentName) {
    comparisonLine = `${summary.experimentName} compared to ${summary.comparisonExperimentName}:
`;
  }
  const longestScoreName = Math.max(
    ...Object.values(summary.scores).map((score) => score.name.length)
  );
  const longestMetricName = Math.max(
    ...Object.values(summary.metrics ?? {}).map((metric) => metric.name.length)
  );
  return `
=========================SUMMARY=========================
${comparisonLine}` + Object.values(summary.scores).map((score) => formatScoreSummary(score, longestScoreName)).join("\n") + (Object.keys(summary.scores).length ? "\n\n" : "") + Object.values(summary.metrics ?? {}).map((metric) => formatMetricSummary(metric, longestMetricName)).join("\n") + (Object.keys(summary.metrics ?? {}).length ? "\n\n" : "") + (summary.experimentUrl ? `See results for ${summary.experimentName} at ${summary.experimentUrl}` : "");
}
function formatScoreSummary(summary, longestScoreName) {
  const diffString = isEmpty(summary.diff) ? "" : ` (${summary.diff > 0 ? "+" : ""}${(summary.diff * 100).toFixed(2)}%)`;
  const scoreName = `'${summary.name}'`.padEnd(longestScoreName + 2);
  return `${(summary.score * 100).toFixed(
    2
  )}%${diffString} ${scoreName} score	(${summary.improvements} improvements, ${summary.regressions} regressions)`;
}
function formatMetricSummary(summary, longestMetricName) {
  const fractionDigits = Number.isInteger(summary.metric) ? 0 : 2;
  const metricName = `'${summary.name}'`.padEnd(longestMetricName + 2);
  return `${summary.metric.toFixed(fractionDigits)}${summary.unit} ${metricName}	(${summary.improvements} improvements, ${summary.regressions} regressions)`;
}

// src/node.ts
var import_node_async_hooks = require("async_hooks");
var path = __toESM(require("path"));
var fs = __toESM(require("fs/promises"));

// src/gitutil.ts
var import_simple_git = require("simple-git");
var COMMON_BASE_BRANCHES = ["main", "master", "develop"];
async function currentRepo() {
  try {
    const git = (0, import_simple_git.simpleGit)();
    if (await git.checkIsRepo()) {
      return git;
    } else {
      return null;
    }
  } catch (e) {
    return null;
  }
}
var _baseBranch = null;
async function getBaseBranch(remote = void 0) {
  if (_baseBranch === null) {
    const git = await currentRepo();
    if (git === null) {
      throw new Error("Not in a git repo");
    }
    const remoteName = remote ?? (await git.getRemotes())[0]?.name;
    if (!remoteName) {
      throw new Error("No remote found");
    }
    let branch = null;
    const repoBranches = new Set((await git.branchLocal()).all);
    const matchingBaseBranches = COMMON_BASE_BRANCHES.filter(
      (b) => repoBranches.has(b)
    );
    if (matchingBaseBranches.length === 1) {
      branch = matchingBaseBranches[0];
    } else {
      try {
        const remoteInfo = await git.remote(["show", remoteName]);
        if (!remoteInfo) {
          throw new Error(`Could not find remote ${remoteName}`);
        }
        const match = remoteInfo.match(/\s*HEAD branch:\s*(.*)$/m);
        if (!match) {
          throw new Error(`Could not find HEAD branch in remote ${remoteName}`);
        }
        branch = match[1];
      } catch {
        branch = "main";
      }
    }
    _baseBranch = { remote: remoteName, branch };
  }
  return _baseBranch;
}
async function getBaseBranchAncestor(remote = void 0) {
  const git = await currentRepo();
  if (git === null) {
    throw new Error("Not in a git repo");
  }
  const { remote: remoteName, branch: baseBranch } = await getBaseBranch(remote);
  const isDirty = (await git.diffSummary()).files.length > 0;
  const head = isDirty ? "HEAD" : "HEAD^";
  try {
    const ancestor = await git.raw([
      "merge-base",
      head,
      `${remoteName}/${baseBranch}`
    ]);
    return ancestor.trim();
  } catch (e) {
    return void 0;
  }
}
async function getPastNAncestors(n = 10, remote = void 0) {
  const git = await currentRepo();
  if (git === null) {
    return [];
  }
  let ancestor = void 0;
  try {
    ancestor = await getBaseBranchAncestor(remote);
  } catch (e) {
    console.warn(
      "Skipping git metadata. This is likely because the repository has not been published to a remote yet.",
      `${e}`
    );
  }
  if (!ancestor) {
    return [];
  }
  const commits = await git.log({ from: ancestor, to: "HEAD" });
  return commits.all.map((c) => c.hash);
}
async function attempt(fn) {
  try {
    return await fn();
  } catch (e) {
    return void 0;
  }
}
function truncateToByteLimit(s, byteLimit = 65536) {
  const encoded = new TextEncoder().encode(s);
  if (encoded.length <= byteLimit) {
    return s;
  }
  const truncated = encoded.subarray(0, byteLimit);
  return new TextDecoder().decode(truncated);
}
async function getRepoInfo(settings) {
  if (settings && settings.collect === "none") {
    return void 0;
  }
  const repo = await repoInfo();
  if (!repo || !settings || settings.collect === "all") {
    return repo;
  }
  let sanitized = {};
  settings.fields?.forEach((field) => {
    sanitized = { ...sanitized, [field]: repo[field] };
  });
  return sanitized;
}
async function repoInfo() {
  const git = await currentRepo();
  if (git === null) {
    return void 0;
  }
  let commit = void 0;
  let commit_message = void 0;
  let commit_time = void 0;
  let author_name = void 0;
  let author_email = void 0;
  let tag = void 0;
  let branch = void 0;
  let git_diff = void 0;
  const dirty = (await git.diffSummary()).files.length > 0;
  commit = await attempt(async () => await git.revparse(["HEAD"]));
  commit_message = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%B"])).trim()
  );
  commit_time = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%cI"])).trim()
  );
  author_name = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%aN"])).trim()
  );
  author_email = await attempt(
    async () => (await git.raw(["log", "-1", "--pretty=%aE"])).trim()
  );
  tag = await attempt(
    async () => (await git.raw(["describe", "--tags", "--exact-match", "--always"])).trim()
  );
  branch = await attempt(
    async () => (await git.raw(["rev-parse", "--abbrev-ref", "HEAD"])).trim()
  );
  if (dirty) {
    git_diff = await attempt(
      async () => truncateToByteLimit(await git.raw(["diff", "HEAD"]))
    );
  }
  return {
    commit,
    branch,
    tag,
    dirty,
    author_name,
    author_email,
    commit_message,
    commit_time,
    git_diff
  };
}

// src/stackutil.ts
function getStackTrace() {
  const trace = new Error().stack;
  if (trace === void 0) {
    return [];
  }
  const traceLines = trace.split("\n");
  const out = [];
  const stackFrameRegex = /at(.*)\((.*):(\d+):(\d+)\)/;
  for (const traceLine of traceLines.slice(1)) {
    const matches = traceLine.match(stackFrameRegex);
    if (matches === null || matches.length !== 5) {
      continue;
    }
    const entry = {
      functionName: matches[1].trim(),
      fileName: matches[2],
      lineNo: parseInt(matches[3])
    };
    if (!isNaN(entry.lineNo)) {
      out.push(entry);
    }
  }
  return out;
}
function getCallerLocation() {
  let thisDir = void 0;
  const entries = getStackTrace();
  for (const frame of entries) {
    if (thisDir === void 0) {
      thisDir = isomorph_default.pathDirname?.(frame.fileName);
    }
    if (isomorph_default.pathDirname?.(frame.fileName) !== thisDir) {
      return {
        caller_functionname: frame.functionName,
        caller_filename: frame.fileName,
        caller_lineno: frame.lineNo
      };
    }
  }
  return void 0;
}

// src/node.ts
function configureNode() {
  isomorph_default.getRepoInfo = getRepoInfo;
  isomorph_default.getPastNAncestors = getPastNAncestors;
  isomorph_default.getEnv = (name) => process.env[name];
  isomorph_default.getCallerLocation = getCallerLocation;
  isomorph_default.newAsyncLocalStorage = () => new import_node_async_hooks.AsyncLocalStorage();
  isomorph_default.processOn = (event, handler) => {
    process.on(event, handler);
  };
  isomorph_default.pathJoin = path.join;
  isomorph_default.pathDirname = path.dirname;
  isomorph_default.mkdir = fs.mkdir;
  isomorph_default.writeFile = fs.writeFile;
  isomorph_default.readFile = fs.readFile;
  _internalSetInitialState();
}

// src/cli.ts
var import_env2 = require("@next/env");

// src/functions/upload.ts
var import_typespecs3 = require("@braintrust/core/typespecs");
var import_fs = __toESM(require("fs"));
var import_path3 = __toESM(require("path"));
var import_zlib = require("zlib");
var import_zod3 = require("zod");
var import_core3 = require("@braintrust/core");

// src/functions/infer-source.ts
var import_source_map = require("source-map");
var fs2 = __toESM(require("fs/promises"));

// src/jest/nodeModulesPaths.ts
var path2 = __toESM(require("path"));

// src/jest/tryRealpath.ts
var import_graceful_fs = require("graceful-fs");
function tryRealpath(path9) {
  try {
    path9 = import_graceful_fs.realpathSync.native(path9);
  } catch (error2) {
    if (error2.code !== "ENOENT" && error2.code !== "EISDIR") {
      throw error2;
    }
  }
  return path9;
}

// src/jest/nodeModulesPaths.ts
function nodeModulesPaths(basedir, options) {
  const modules = options && options.moduleDirectory ? Array.from(options.moduleDirectory) : ["node_modules"];
  const basedirAbs = path2.resolve(basedir);
  let prefix = "/";
  if (/^([A-Za-z]:)/.test(basedirAbs)) {
    prefix = "";
  } else if (/^\\\\/.test(basedirAbs)) {
    prefix = "\\\\";
  }
  let physicalBasedir;
  try {
    physicalBasedir = tryRealpath(basedirAbs);
  } catch {
    physicalBasedir = basedirAbs;
  }
  const paths = [physicalBasedir];
  let parsed = path2.parse(physicalBasedir);
  while (parsed.dir !== paths[paths.length - 1]) {
    paths.push(parsed.dir);
    parsed = path2.parse(parsed.dir);
  }
  const dirs = paths.reduce((dirs2, aPath) => {
    for (const moduleDir of modules) {
      if (path2.isAbsolute(moduleDir)) {
        if (aPath === basedirAbs && moduleDir) {
          dirs2.push(moduleDir);
        }
      } else {
        dirs2.push(path2.join(prefix, aPath, moduleDir));
      }
    }
    return dirs2;
  }, []);
  if (options.paths) {
    dirs.push(...options.paths);
  }
  return dirs;
}
function findGlobalPaths() {
  const { root } = path2.parse(process.cwd());
  const globalPath = path2.join(root, "node_modules");
  const resolvePaths = require.resolve.paths("/");
  if (resolvePaths) {
    const rootIndex = resolvePaths.indexOf(globalPath);
    return rootIndex > -1 ? resolvePaths.slice(rootIndex + 1) : [];
  }
  return [];
}
var GlobalPaths = findGlobalPaths();

// src/functions/load-module.ts
var import_path = __toESM(require("path"));
function evalWithModuleContext(inFile, evalFn) {
  const modulePaths = [...module.paths];
  try {
    module.paths = nodeModulesPaths(import_path.default.dirname(inFile), {});
    return evalFn();
  } finally {
    module.paths = modulePaths;
  }
}
function loadModule({
  inFile,
  moduleText
}) {
  return evalWithModuleContext(inFile, () => {
    globalThis._evals = {
      functions: [],
      prompts: [],
      evaluators: {},
      reporters: {}
    };
    globalThis._lazy_load = true;
    globalThis.__inherited_braintrust_state = _internalGetGlobalState();
    const __filename2 = inFile;
    const __dirname = (0, import_path.dirname)(__filename2);
    new Function("require", "module", "__filename", "__dirname", moduleText)(
      require,
      module,
      __filename2,
      __dirname
    );
    return { ...globalThis._evals };
  });
}

// src/functions/infer-source.ts
var import_path2 = __toESM(require("path"));
async function makeSourceMapContext({
  inFile,
  outFile,
  sourceMapFile
}) {
  const [inFileContents, outFileContents, sourceMap] = await Promise.all([
    fs2.readFile(inFile, "utf8"),
    fs2.readFile(outFile, "utf8"),
    (async () => {
      const sourceMap2 = await fs2.readFile(sourceMapFile, "utf8");
      const sourceMapJSON = JSON.parse(sourceMap2);
      return new import_source_map.SourceMapConsumer(sourceMapJSON);
    })()
  ]);
  return {
    inFiles: { [inFile]: inFileContents.split("\n") },
    outFileModule: loadModule({ inFile, moduleText: outFileContents }),
    outFileLines: outFileContents.split("\n"),
    sourceMapDir: import_path2.default.dirname(sourceMapFile),
    sourceMap
  };
}
function isNative(fn) {
  return /\{\s*\[native code\]\s*\}/.test(Function.prototype.toString.call(fn));
}
function locationToString(location) {
  if (location.type === "experiment") {
    return `eval ${location.eval_name} -> ${location.position.type}`;
  } else {
    return `task ${location.index}`;
  }
}
async function findCodeDefinition({
  location,
  ctx: { inFiles, outFileModule, outFileLines, sourceMapDir, sourceMap }
}) {
  let fn = void 0;
  if (location.type === "experiment") {
    const evaluator = outFileModule.evaluators[location.eval_name]?.evaluator;
    if (!evaluator) {
      console.warn(
        warning(
          `Failed to find evaluator for ${location.eval_name}. Will not display preview.`
        )
      );
      return void 0;
    }
    fn = location.position.type === "task" ? evaluator.task : evaluator.scores[location.position.index];
  } else {
    fn = outFileModule.functions[location.index].handler;
  }
  if (!fn) {
    console.warn(
      warning(
        `Failed to find ${locationToString(location)}. Will not display preview.`
      )
    );
    return void 0;
  }
  const sourceCode = fn.toString();
  if (isNative(fn)) {
    return void 0;
  }
  let lineNumber = 0;
  let columnNumber = -1;
  for (const line of outFileLines) {
    const sourceDefinition = line.indexOf(sourceCode);
    if (sourceDefinition !== -1) {
      columnNumber = sourceDefinition;
      break;
    }
    lineNumber++;
  }
  if (columnNumber === -1) {
    console.warn(warning(`Failed to find code definition for ${fn.name}`));
    return void 0;
  }
  const originalPosition = sourceMap.originalPositionFor({
    line: lineNumber + 1,
    column: columnNumber + 1
  });
  if (originalPosition.source === null || originalPosition.line === null) {
    return void 0;
  }
  if (!inFiles[originalPosition.source]) {
    const originalFile = import_path2.default.join(sourceMapDir, originalPosition.source);
    inFiles[originalPosition.source] = (await fs2.readFile(originalFile, "utf-8")).split("\n");
  }
  const originalLines = inFiles[originalPosition.source];
  const ts = await getTsModule();
  if (!ts) {
    return void 0;
  }
  const sourceFile = ts.createSourceFile(
    originalPosition.source,
    originalLines.join("\n"),
    ts.ScriptTarget.Latest,
    true
  );
  let functionNode = void 0;
  const targetPosition = ts.getPositionOfLineAndCharacter(
    sourceFile,
    originalPosition.line - 1,
    originalPosition.column || 0
  );
  ts.forEachChild(sourceFile, function visit(node) {
    if (node.pos <= targetPosition && targetPosition < node.end) {
      if (ts.isFunctionDeclaration(node) || ts.isFunctionExpression(node) || ts.isArrowFunction(node)) {
        functionNode = node;
      } else {
        ts.forEachChild(node, visit);
      }
    }
  });
  if (!functionNode) {
    return void 0;
  }
  const printer = ts.createPrinter();
  const functionDefinition = printer.printNode(
    ts.EmitHint.Unspecified,
    functionNode,
    sourceFile
  );
  return functionDefinition;
}
var tsModule = void 0;
async function getTsModule() {
  if (!tsModule) {
    try {
      tsModule = require("typescript");
    } catch (e) {
      console.warn(
        warning(
          "Failed to load TypeScript module. Will not use TypeScript to derive preview."
        )
      );
    }
  }
  return tsModule;
}

// src/functions/upload.ts
var import_slugify = __toESM(require("slugify"));
var import_zod_to_json_schema = require("zod-to-json-schema");
var import_pluralize2 = __toESM(require("pluralize"));
var pathInfoSchema = import_zod3.z.strictObject({
  url: import_zod3.z.string(),
  bundleId: import_zod3.z.string()
}).strip();
async function uploadHandleBundles({
  buildResults,
  evalToExperiment,
  bundlePromises,
  handles,
  setCurrent,
  verbose,
  defaultIfExists
}) {
  console.error(
    `Processing ${buildResults.length} ${(0, import_pluralize2.default)("file", buildResults.length)}...`
  );
  const projectNameToId = new ProjectNameIdMap();
  const resolveProjectId = async (project) => {
    if (project.id) {
      return project.id;
    }
    return projectNameToId.getId(project.name);
  };
  const uploadPromises = buildResults.map(async (result) => {
    if (result.type !== "success") {
      return;
    }
    const sourceFile = result.sourceFile;
    const bundleSpecs = [];
    const prompts = [];
    if (setCurrent) {
      for (let i = 0; i < result.evaluator.functions.length; i++) {
        const fn = result.evaluator.functions[i];
        const project_id = await resolveProjectId(fn.project);
        bundleSpecs.push({
          project_id,
          name: fn.name,
          slug: fn.slug,
          description: fn.description ?? "",
          function_type: fn.type,
          location: {
            type: "function",
            index: i
          },
          function_schema: fn.parameters || fn.returns ? {
            parameters: fn.parameters ? (0, import_zod_to_json_schema.zodToJsonSchema)(fn.parameters) : void 0,
            returns: fn.returns ? (0, import_zod_to_json_schema.zodToJsonSchema)(fn.returns) : void 0
          } : void 0,
          if_exists: fn.ifExists
        });
      }
      for (const prompt of result.evaluator.prompts) {
        const prompt_data = {
          ...prompt.prompt
        };
        if (prompt.toolFunctions.length > 0) {
          const resolvableToolFunctions = await Promise.all(
            prompt.toolFunctions.map(async (fn) => {
              if ("slug" in fn) {
                return {
                  type: "slug",
                  project_id: await resolveProjectId(fn.project),
                  slug: fn.slug
                };
              } else {
                return fn;
              }
            })
          );
          prompt_data.tool_functions = // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
          resolvableToolFunctions;
        }
        prompts.push({
          project_id: await resolveProjectId(prompt.project),
          name: prompt.name,
          slug: prompt.slug,
          description: prompt.description ?? "",
          function_data: {
            type: "prompt"
          },
          prompt_data,
          if_exists: prompt.ifExists
        });
      }
    }
    for (const evaluator of Object.values(result.evaluator.evaluators)) {
      const experiment = evalToExperiment?.[sourceFile]?.[evaluator.evaluator.evalName];
      const baseInfo = {
        project_id: experiment ? (await experiment.project).id : await projectNameToId.getId(evaluator.evaluator.projectName)
      };
      const namePrefix = setCurrent ? evaluator.evaluator.experimentName ? `${evaluator.evaluator.experimentName}` : evaluator.evaluator.evalName : experiment ? `${await experiment.name}` : evaluator.evaluator.evalName;
      const experimentId = experiment ? await experiment.id : void 0;
      const origin = experimentId ? {
        object_type: "experiment",
        object_id: experimentId,
        internal: !setCurrent
      } : void 0;
      const fileSpecs = [
        {
          ...baseInfo,
          // There is a very small chance that someone names a function with the same convention, but
          // let's assume it's low enough that it doesn't matter.
          ...formatNameAndSlug(["eval", namePrefix, "task"]),
          description: `Task for eval ${namePrefix}`,
          location: {
            type: "experiment",
            eval_name: evaluator.evaluator.evalName,
            position: { type: "task" }
          },
          function_type: "task",
          origin
        },
        ...evaluator.evaluator.scores.map((score, i) => {
          const name = scorerName(score, i);
          return {
            ...baseInfo,
            // There is a very small chance that someone names a function with the same convention, but
            // let's assume it's low enough that it doesn't matter.
            ...formatNameAndSlug(["eval", namePrefix, "scorer", name]),
            description: `Score ${name} for eval ${namePrefix}`,
            location: {
              type: "experiment",
              eval_name: evaluator.evaluator.evalName,
              position: { type: "scorer", index: i }
            },
            function_type: "scorer",
            origin
          };
        })
      ];
      bundleSpecs.push(...fileSpecs);
    }
    const slugs = /* @__PURE__ */ new Set();
    for (const spec of bundleSpecs) {
      if (slugs.has(spec.slug)) {
        throw new Error(`Duplicate slug: ${spec.slug}`);
      }
      slugs.add(spec.slug);
    }
    for (const prompt of prompts) {
      if (slugs.has(prompt.slug)) {
        throw new Error(`Duplicate slug: ${prompt.slug}`);
      }
      slugs.add(prompt.slug);
    }
    return await uploadBundles({
      sourceFile,
      prompts,
      bundleSpecs,
      bundlePromises,
      handles,
      defaultIfExists,
      verbose
    });
  });
  const uploadResults = await Promise.all(uploadPromises);
  const numUploaded = uploadResults.length;
  const numFailed = uploadResults.filter((result) => !result).length;
  console.error(
    `${numUploaded} ${(0, import_pluralize2.default)("file", numUploaded)} uploaded ${numFailed > 0 ? `with ${numFailed} error${numFailed > 1 ? "s" : ""}` : "successfully"}.`
  );
  return {
    numTotal: buildResults.length,
    numUploaded,
    numFailed
  };
}
async function uploadBundles({
  sourceFile,
  prompts,
  bundleSpecs,
  bundlePromises,
  handles,
  defaultIfExists,
  verbose
}) {
  const orgId = _internalGetGlobalState().orgId;
  if (!orgId) {
    throw new Error("No organization ID found");
  }
  const loggerConn = _internalGetGlobalState().apiConn();
  const runtime_context = {
    runtime: "node",
    version: process.version.slice(1)
  };
  const bundle = await bundlePromises[sourceFile];
  if (!bundle || !handles[sourceFile].bundleFile) {
    return false;
  }
  const sourceMapContextPromise = makeSourceMapContext({
    inFile: sourceFile,
    outFile: handles[sourceFile].bundleFile,
    sourceMapFile: handles[sourceFile].bundleFile + ".map"
  });
  let pathInfo = void 0;
  if (bundleSpecs.length > 0) {
    try {
      pathInfo = pathInfoSchema.parse(
        await loggerConn.post_json("function/code", {
          org_id: orgId,
          runtime_context
        })
      );
    } catch (e) {
      if (verbose) {
        console.error(e);
      }
      const msg = e instanceof FailedHTTPResponse ? `Unable to upload your code. ${e.status} (${e.text}): ${e.data}` : `Unable to upload your code. You most likely need to update the API: ${e}`;
      console.error(warning(msg));
      return false;
    }
  }
  const bundleFileName = handles[sourceFile].bundleFile;
  if (isEmpty(bundleFileName)) {
    throw new Error("No bundle file found");
  }
  const bundleFile = import_path3.default.resolve(bundleFileName);
  const uploadPromise = (async () => {
    if (!pathInfo) {
      return true;
    }
    const bundleStream = import_fs.default.createReadStream(bundleFile).pipe((0, import_zlib.createGzip)());
    const bundleData = await new Promise((resolve2, reject2) => {
      const chunks = [];
      bundleStream.on("data", (chunk) => {
        chunks.push(chunk);
      });
      bundleStream.on("end", () => {
        resolve2(Buffer.concat(chunks));
      });
      bundleStream.on("error", reject2);
    });
    const resp = await fetch(pathInfo.url, {
      method: "PUT",
      body: bundleData,
      headers: {
        "Content-Encoding": "gzip"
      }
    });
    if (!resp.ok) {
      throw new Error(
        `Failed to upload bundle: ${resp.status} ${await resp.text()}`
      );
    }
    return true;
  })();
  const sourceMapContext = await sourceMapContextPromise;
  const functionEntries = [
    ...prompts,
    // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
    ...await Promise.all(
      bundleSpecs.map(async (spec) => ({
        project_id: spec.project_id,
        name: spec.name,
        slug: spec.slug,
        description: spec.description,
        function_data: {
          type: "code",
          data: {
            type: "bundle",
            runtime_context,
            location: spec.location,
            bundle_id: pathInfo.bundleId,
            preview: await findCodeDefinition({
              location: spec.location,
              ctx: sourceMapContext
            })
          }
        },
        origin: spec.origin,
        function_type: spec.function_type,
        function_schema: spec.function_schema,
        if_exists: spec.if_exists
      }))
    )
  ].map((fn) => ({
    ...fn,
    if_exists: fn.if_exists ?? defaultIfExists
  }));
  const logPromise = (async () => {
    try {
      await _internalGetGlobalState().apiConn().post_json("insert-functions", {
        functions: functionEntries
      });
    } catch (e) {
      if (verbose) {
        console.error(e);
      }
      const msg = e instanceof FailedHTTPResponse ? `Failed to save function definitions for '${sourceFile}'. ${e.status} (${e.text}): ${e.data}` : `Failed to save function definitions for '${sourceFile}'. You most likely need to update the API: ${e}`;
      console.warn(warning(msg));
      return false;
    }
    return true;
  })();
  const [uploadSuccess, logSuccess] = await Promise.all([
    uploadPromise,
    logPromise
  ]);
  return uploadSuccess && logSuccess;
}
function formatNameAndSlug(pieces) {
  const nonEmptyPieces = pieces.filter((piece) => piece.trim() !== "");
  return {
    name: (0, import_core3.capitalize)(nonEmptyPieces.join(" ")),
    slug: (0, import_slugify.default)(nonEmptyPieces.join("-"))
  };
}
var ProjectNameIdMap = class {
  nameToId = {};
  idToName = {};
  async getId(projectName) {
    if (!(projectName in this.nameToId)) {
      const response = await _internalGetGlobalState().appConn().post_json("api/project/register", {
        project_name: projectName
      });
      const result = import_zod3.z.object({
        project: import_typespecs3.projectSchema
      }).parse(response);
      const projectId = result.project.id;
      this.nameToId[projectName] = projectId;
      this.idToName[projectId] = projectName;
    }
    return this.nameToId[projectName];
  }
  async getName(projectId) {
    if (!(projectId in this.idToName)) {
      const response = await _internalGetGlobalState().appConn().post_json("api/project/get", {
        id: projectId
      });
      const result = import_zod3.z.array(import_typespecs3.projectSchema).nonempty().parse(response);
      const projectName = result[0].name;
      this.idToName[projectId] = projectName;
      this.nameToId[projectName] = projectId;
    }
    return this.idToName[projectId];
  }
};

// src/cli-util/bundle.ts
var import_env = require("@next/env");
var dotenv = __toESM(require("dotenv"));
async function loadCLIEnv(args) {
  (0, import_env.loadEnvConfig)(process.cwd(), true);
  if (args.env_file) {
    const loaded = dotenv.config({ path: args.env_file });
    if (loaded.error) {
      console.error(error(`Error loading ${args.env_file}: ${loaded.error}`));
      process.exit(1);
    }
  }
  await login({
    apiKey: args.api_key,
    orgName: args.org_name,
    appUrl: args.app_url
  });
}
async function bundleCommand(args) {
  await loadCLIEnv(args);
  const handles = await initializeHandles({
    mode: "bundle",
    files: args.files,
    tsconfig: args.tsconfig
  });
  try {
    const allBuildResultsP = Object.values(
      handles
    ).map((handle) => handle.rebuild());
    const bundlePromises = Object.fromEntries(
      Object.entries(handles).map(([inFile, handle]) => [
        inFile,
        handle.bundle()
      ])
    );
    const allBuildResults = await Promise.all(allBuildResultsP);
    const buildResults = [];
    for (const buildResult of allBuildResults) {
      if (buildResult.type === "failure") {
        handleBuildFailure({
          result: buildResult,
          terminateOnFailure: args.terminate_on_failure,
          verbose: args.verbose
        });
      } else {
        buildResults.push(buildResult);
      }
    }
    const { numFailed } = await uploadHandleBundles({
      buildResults,
      bundlePromises,
      handles,
      setCurrent: true,
      verbose: args.verbose,
      defaultIfExists: args.if_exists
    });
    if (numFailed > 0) {
      process.exit(1);
    }
  } finally {
    for (const handle of Object.values(handles)) {
      await handle.destroy();
    }
  }
}

// src/cli-util/pull.ts
var import_typespecs4 = require("@braintrust/core/typespecs");
var import_zod5 = require("zod");
var import_promises = __toESM(require("fs/promises"));
var import_util4 = __toESM(require("util"));
var import_slugify3 = __toESM(require("slugify"));
var import_path5 = __toESM(require("path"));
var import_core4 = require("@braintrust/core");

// src/framework2.ts
var import_path4 = __toESM(require("path"));
var import_slugify2 = __toESM(require("slugify"));
var import_zod4 = require("zod");
var ProjectBuilder = class {
  create(opts) {
    return new Project(opts);
  }
};
var projects = new ProjectBuilder();
var Project = class {
  name;
  id;
  tools;
  prompts;
  constructor(args) {
    _initializeSpanContext();
    this.name = "name" in args ? args.name : void 0;
    this.id = "id" in args ? args.id : void 0;
    this.tools = new ToolBuilder(this);
    this.prompts = new PromptBuilder(this);
  }
};
var ToolBuilder = class {
  constructor(project) {
    this.project = project;
  }
  taskCounter = 0;
  create(opts) {
    this.taskCounter++;
    opts = opts ?? {};
    const { handler, name, slug, ...rest } = opts;
    let resolvedName = name ?? handler.name;
    if (resolvedName.trim().length === 0) {
      resolvedName = `Tool ${import_path4.default.basename(__filename)} ${this.taskCounter}`;
    }
    const tool = new CodeFunction(
      this.project,
      {
        handler,
        name: resolvedName,
        slug: slug ?? (0, import_slugify2.default)(resolvedName, { lower: true, strict: true }),
        type: "tool",
        ...rest
      }
    );
    if (globalThis._lazy_load) {
      globalThis._evals.functions.push(
        tool
      );
    }
    return tool;
  }
};
var CodeFunction = class {
  constructor(project, opts) {
    this.project = project;
    this.handler = opts.handler;
    this.name = opts.name;
    this.slug = opts.slug;
    this.description = opts.description;
    this.type = opts.type;
    this.ifExists = opts.ifExists;
    this.parameters = opts.parameters;
    this.returns = opts.returns;
    if (this.returns && !this.parameters) {
      throw new Error("parameters are required if return type is defined");
    }
  }
  handler;
  name;
  slug;
  type;
  description;
  parameters;
  returns;
  ifExists;
  key() {
    return JSON.stringify([
      this.project.id ?? "",
      this.project.name ?? "",
      this.slug
    ]);
  }
};
var CodePrompt = class {
  project;
  name;
  slug;
  prompt;
  ifExists;
  description;
  id;
  toolFunctions;
  constructor(project, prompt, toolFunctions, opts) {
    this.project = project;
    this.name = opts.name;
    this.slug = opts.slug;
    this.prompt = prompt;
    this.toolFunctions = toolFunctions;
    this.ifExists = opts.ifExists;
    this.description = opts.description;
    this.id = opts.id;
  }
};
var toolFunctionDefinitionSchema = import_zod4.z.object({
  type: import_zod4.z.literal("function"),
  function: import_zod4.z.object({
    name: import_zod4.z.string(),
    description: import_zod4.z.string().optional(),
    parameters: import_zod4.z.record(import_zod4.z.unknown()).optional(),
    strict: import_zod4.z.boolean().optional()
  })
});
var PromptBuilder = class {
  constructor(project) {
    this.project = project;
  }
  create(opts) {
    const toolFunctions = [];
    const rawTools = [];
    for (const tool of opts.tools ?? []) {
      if (tool instanceof CodeFunction) {
        toolFunctions.push(tool);
      } else if ("type" in tool && !("function" in tool)) {
        toolFunctions.push(tool);
      } else {
        rawTools.push(tool);
      }
    }
    const promptBlock = "messages" in opts ? {
      type: "chat",
      messages: opts.messages,
      tools: rawTools && rawTools.length > 0 ? JSON.stringify(rawTools) : void 0
    } : {
      type: "completion",
      content: opts.prompt
    };
    const slug = opts.slug ?? (0, import_slugify2.default)(opts.name, { lower: true, strict: true });
    const promptData = {
      prompt: promptBlock,
      options: {
        model: opts.model,
        params: opts.params
      }
    };
    const promptRow = {
      id: opts.id,
      _xact_id: opts.version,
      name: opts.name,
      slug,
      prompt_data: promptData
    };
    const prompt = new Prompt(
      promptRow,
      {},
      // It doesn't make sense to specify defaults here.
      opts.noTrace ?? false
    );
    const codePrompt = new CodePrompt(this.project, promptData, toolFunctions, {
      ...opts,
      slug
    });
    if (globalThis._lazy_load) {
      globalThis._evals.prompts.push(codePrompt);
    }
    return prompt;
  }
};

// src/cli-util/pull.ts
var import_pluralize3 = __toESM(require("pluralize"));
async function pullCommand(args) {
  await loadCLIEnv(args);
  const loggerConn = _internalGetGlobalState().apiConn();
  const functions = await loggerConn.get_json("/v1/function", {
    ...args.project_id ? { project_id: args.project_id } : {},
    ...args.project_name ? { project_name: args.project_name } : {},
    ...args.slug ? { slug: args.slug } : {},
    ...args.id ? { ids: [args.id] } : {},
    ...args.version ? { version: (0, import_core4.loadPrettyXact)(args.version) } : {}
  });
  const functionObjects = import_zod5.z.object({ objects: import_zod5.z.array(import_zod5.z.unknown()) }).parse(functions);
  const projectNameToFunctions = {};
  const projectNameIdMap = new ProjectNameIdMap();
  for (const rawFunc of functionObjects.objects) {
    const parsedFunc = import_typespecs4.functionSchema.safeParse(rawFunc);
    if (!parsedFunc.success) {
      const id = typeof rawFunc === "object" && rawFunc && "id" in rawFunc ? ` ${rawFunc.id}` : "";
      console.warn(
        warning(`Failed to parse function${id}: ${parsedFunc.error.message}`)
      );
      continue;
    }
    const func = parsedFunc.data;
    const projectName = await projectNameIdMap.getName(func.project_id);
    if (!projectNameToFunctions[projectName]) {
      projectNameToFunctions[projectName] = [];
    }
    projectNameToFunctions[projectName].push(func);
  }
  console.log("Found functions in the following projects:");
  for (const projectName of Object.keys(projectNameToFunctions)) {
    console.log(` * ${projectName}`);
  }
  const outputDir = args.output_dir ?? "./braintrust";
  await import_promises.default.mkdir(outputDir, { recursive: true });
  const git = await currentRepo();
  const diffSummary = await git?.diffSummary("HEAD");
  const repoRoot = await git?.revparse(["--show-toplevel"]);
  const dirtyFiles = new Set(
    (diffSummary?.files ?? []).map(
      (f) => import_path5.default.resolve(repoRoot ?? ".", f.file)
    )
  );
  for (const projectName of Object.keys(projectNameToFunctions)) {
    const projectFile = import_path5.default.join(
      outputDir,
      `${(0, import_slugify3.default)(projectName, { lower: true, strict: true, trim: true })}.ts`
    );
    const resolvedProjectFile = import_path5.default.resolve(projectFile);
    const fileExists = await import_promises.default.stat(projectFile).then(
      () => true,
      () => false
    );
    if (args.force) {
      if (fileExists) {
        console.warn(
          warning(
            `Overwriting ${doubleQuote(projectFile)} because --force is set.`
          )
        );
      }
    } else if (dirtyFiles.has(resolvedProjectFile)) {
      console.warn(
        warning(
          `Skipping project ${projectName} because ${doubleQuote(projectFile)} has uncommitted changes.`
        )
      );
      continue;
    } else if (fileExists) {
      if (!git) {
        console.warn(
          warning(
            `Project ${projectName} already exists in ${doubleQuote(projectFile)}. Skipping since this is not a git repository...`
          )
        );
        continue;
      } else {
        console.warn(
          warning(
            `Project ${projectName} already exists in ${doubleQuote(projectFile)}. Overwriting...`
          )
        );
      }
    }
    const projectFileContents = await makeProjectFile({
      projectName,
      fileName: projectFile,
      functions: projectNameToFunctions[projectName],
      hasSpecifiedFunction: !!args.slug || !!args.id
    });
    await import_promises.default.writeFile(projectFile, projectFileContents);
    console.log(`Wrote ${projectName} to ${doubleQuote(projectFile)}`);
  }
}
async function makeProjectFile({
  projectName,
  fileName,
  functions,
  hasSpecifiedFunction
}) {
  const varNames = {};
  const functionDefinitions = functions.map(
    (f) => makeFunctionDefinition({ func: f, varNames, hasSpecifiedFunction })
  ).filter((f) => f !== null);
  const fileDef = `// This file was automatically generated by braintrust pull. You can
// generate it again by running:
//  $ braintrust pull --project-name ${doubleQuote(projectName)}
// Feel free to edit this file manually, but once you do, you should make sure to
// sync your changes with Braintrust by running:
//  $ braintrust push ${doubleQuote(fileName)}

import braintrust from "braintrust";

const project = braintrust.projects.create({
  name: ${doubleQuote(projectName)},
});

${functionDefinitions.join("\n")}
`;
  const prettier = await getPrettierModule();
  if (prettier) {
    const formatted = prettier.format(fileDef, {
      parser: "typescript"
    });
    return formatted;
  } else {
    return fileDef;
  }
}
function makeFunctionDefinition({
  func,
  varNames,
  hasSpecifiedFunction
}) {
  if (func.function_data.type !== "prompt") {
    if (hasSpecifiedFunction) {
      console.warn(
        warning(
          `Skipping function ${doubleQuote(func.name)} because it is not a prompt.`
        )
      );
    }
    return null;
  }
  const baseVarName = slugToVarName(func.slug);
  let varName = baseVarName;
  let suffix = 1;
  while (varName in varNames) {
    varName = `${varName}${suffix}`;
    suffix++;
  }
  varNames[varName] = func.slug;
  if (!func.prompt_data || !func.prompt_data.prompt) {
    console.warn(
      warning(
        `Prompt ${doubleQuote(func.name)} has an invalid (empty) prompt definition.`
      )
    );
    return null;
  }
  const objectType = "prompt";
  const prompt = func.prompt_data.prompt;
  const promptContents = prompt.type === "completion" ? `prompt: ${doubleQuote(prompt.content)}` : `messages: ${import_util4.default.inspect(prompt.messages, { depth: null }).trimStart()}`;
  const rawToolsParsed = prompt.type === "chat" && prompt.tools && prompt.tools.length > 0 ? import_zod5.z.array(toolFunctionDefinitionSchema).safeParse(JSON.parse(prompt.tools)) : void 0;
  if (rawToolsParsed && !rawToolsParsed.success) {
    console.warn(
      warning(
        `Prompt ${doubleQuote(func.name)} has an invalid tools definition: ${rawToolsParsed.error.message}. Skipping...`
      )
    );
    return null;
  }
  const rawTools = rawToolsParsed ? rawToolsParsed.data : [];
  const { model, params } = func.prompt_data.options ?? {};
  const paramsString = params && Object.keys(params).length > 0 ? `params: ${import_util4.default.inspect(params, { depth: null }).trimStart()},` : "";
  const tools = [
    ...func.prompt_data.tool_functions ?? [],
    ...rawTools
  ];
  const toolsString = tools.length > 0 ? `tools: ${import_util4.default.inspect(tools, { depth: null }).trimStart()},` : "";
  return `export const ${varName} = project.${(0, import_pluralize3.default)(objectType)}.create({
  name: ${doubleQuote(func.name)},
  slug: ${doubleQuote(func.slug)},${printOptionalField("description", func.description)}${printOptionalField("model", model)}
${indent(promptContents, 2)},
${indent(paramsString, 2)}
${indent(toolsString, 2)}
});
`;
}
function doubleQuote(str) {
  return JSON.stringify(str);
}
function slugToVarName(slug) {
  let varName = slug.replace(/^[^a-zA-Z_$]|[^a-zA-Z0-9_$]/g, "_");
  varName = varName.replace(/_([a-z])/g, (_, letter) => letter.toUpperCase());
  varName = varName.charAt(0).toLowerCase() + varName.slice(1);
  return varName;
}
function indent(str, numSpaces) {
  return str.replace(/^/gm, " ".repeat(numSpaces));
}
function printOptionalField(fieldName, fieldValue) {
  return !(0, import_core4.isEmpty)(fieldValue) ? `
  ${fieldName}: ${doubleQuote(fieldValue)},` : "";
}
var prettierModule = void 0;
async function getPrettierModule() {
  if (!prettierModule) {
    try {
      prettierModule = await import("prettier");
    } catch (e) {
      console.warn(
        warning(
          "Failed to load prettier module. Will not use prettier to format output."
        )
      );
    }
  }
  return prettierModule;
}

// src/cli.ts
var { version } = require_package();
var INCLUDE_EVAL = [
  "**/*.eval.ts",
  "**/*.eval.tsx",
  "**/*.eval.js",
  "**/*.eval.jsx"
];
var INCLUDE_BUNDLE = ["**/*.ts", "**/*.tsx", "**/*.js", "**/*.jsx"];
var EXCLUDE = ["**/node_modules/**", "**/dist/**", "**/build/**"];
var OUT_EXT = "js";
configureNode();
function evaluateBuildResults(inFile, buildResult) {
  if (!buildResult.outputFiles) {
    return null;
  }
  const moduleText = buildResult.outputFiles[0].text;
  return loadModule({ inFile, moduleText });
}
async function initLogger(projectName, experimentName, metadata, baseExperiment) {
  const logger = init(projectName, {
    experiment: experimentName,
    metadata,
    baseExperiment
  });
  const info = await logger.summarize({ summarizeScores: false });
  console.error(
    `Experiment ${info.experimentName} is running at ${info.experimentUrl}`
  );
  return logger;
}
function resolveReporter(reporter, reporters) {
  if (typeof reporter === "string") {
    if (!reporters[reporter]) {
      throw new Error(`Reporter ${reporter} not found`);
    }
    return reporters[reporter];
  } else if (!isEmpty(reporter)) {
    return reporter;
  } else if (Object.keys(reporters).length === 0) {
    return defaultReporter;
  } else if (Object.keys(reporters).length === 1) {
    return reporters[Object.keys(reporters)[0]];
  } else {
    const reporterNames = Object.keys(reporters).join(", ");
    throw new Error(
      `Multiple reporters found (${reporterNames}). Please specify a reporter explicitly.`
    );
  }
}
function addReport(evalReports, reporter, report) {
  if (!evalReports[reporter.name]) {
    evalReports[reporter.name] = {
      reporter,
      results: []
    };
  }
  evalReports[reporter.name].results.push(report);
}
function buildWatchPluginForEvaluator(inFile, opts) {
  const evaluators = {
    evaluators: [],
    reporters: {}
  };
  const plugin = {
    name: "run-evalutator-on-end",
    setup(build2) {
      build2.onEnd(async (result) => {
        console.error(`Done building ${inFile}`);
        if (!result.outputFiles) {
          if (opts.verbose) {
            console.warn(`Failed to compile ${inFile}`);
            console.warn(result.errors);
          } else {
            console.warn(`Failed to compile ${inFile}: ${result.errors}`);
          }
          return;
        }
        const evalResult = evaluateBuildResults(inFile, result);
        if (!evalResult) {
          return;
        }
        evaluators.evaluators = evaluators.evaluators.filter(
          (e) => e.sourceFile !== inFile
        );
        for (const evaluator of Object.values(evalResult.evaluators)) {
          evaluators.evaluators.push({
            sourceFile: inFile,
            evaluator: evaluator.evaluator,
            reporter: evaluator.reporter
          });
        }
        for (const [reporterName, reporter] of Object.entries(
          evalResult.reporters
        )) {
          evaluators.reporters[reporterName] = reporter;
        }
        const evalReports = {};
        for (const evaluatorDef of Object.values(evalResult.evaluators)) {
          const { evaluator, reporter } = evaluatorDef;
          const logger = opts.noSendLogs ? null : await initLogger(
            evaluator.projectName,
            evaluator.experimentName,
            evaluator.metadata
          );
          const evaluatorResult = await runEvaluator(
            logger,
            evaluator,
            opts.progressReporter,
            opts.filters
          );
          const resolvedReporter = resolveReporter(
            reporter,
            evaluators.reporters
            // Let these accumulate across all files.
          );
          const report = resolvedReporter.reportEval(
            evaluator,
            evaluatorResult,
            {
              verbose: opts.verbose,
              jsonl: opts.jsonl
            }
          );
          addReport(evalReports, resolvedReporter, report);
        }
        for (const [reporterName, { reporter, results }] of Object.entries(
          evalReports
        )) {
          const success = await reporter.reportRun(await Promise.all(results));
          if (!success) {
            console.error(error(`Reporter ${reporterName} failed.`));
          }
        }
      });
    }
  };
  return plugin;
}
async function initFile({
  inFile,
  outFile,
  bundleFile,
  tsconfig,
  plugins
}) {
  const buildOptions = buildOpts({
    fileName: inFile,
    outFile,
    tsconfig,
    plugins
  });
  const ctx = await esbuild.context(buildOptions);
  return {
    inFile,
    outFile,
    bundleFile,
    rebuild: async () => {
      try {
        const result = await ctx.rebuild();
        if (!result.outputFiles) {
          return {
            type: "failure",
            error: new Error("No output file generated"),
            sourceFile: inFile
          };
        }
        const evaluator = evaluateBuildResults(inFile, result) || {
          functions: [],
          prompts: [],
          evaluators: {},
          reporters: {}
        };
        return { type: "success", result, evaluator, sourceFile: inFile };
      } catch (e) {
        return { type: "failure", error: e, sourceFile: inFile };
      }
    },
    bundle: async () => {
      const buildOptions2 = {
        ...buildOpts({
          fileName: inFile,
          outFile: bundleFile,
          tsconfig,
          plugins
        }),
        external: [],
        write: true,
        plugins: [],
        minify: true,
        sourcemap: true
      };
      return await esbuild.build(buildOptions2);
    },
    watch: () => {
      ctx.watch();
    },
    destroy: async () => {
      await ctx.dispose();
    }
  };
}
function handleBuildFailure({
  result,
  terminateOnFailure,
  verbose
}) {
  if (terminateOnFailure) {
    throw result.error;
  } else if (verbose) {
    console.warn(`Failed to compile ${result.sourceFile}`);
    console.warn(result.error);
  } else {
    console.warn(
      `Failed to compile ${result.sourceFile}: ${result.error.message}`
    );
  }
}
function updateEvaluators(evaluators, buildResults, opts) {
  for (const result of buildResults) {
    if (result.type === "failure") {
      handleBuildFailure({
        result,
        terminateOnFailure: opts.terminateOnFailure,
        verbose: opts.verbose
      });
      continue;
    }
    for (const evaluator of Object.values(result.evaluator.evaluators)) {
      evaluators.evaluators.push({
        sourceFile: result.sourceFile,
        evaluator: evaluator.evaluator,
        reporter: evaluator.reporter
      });
    }
    for (const [reporterName, reporter] of Object.entries(
      result.evaluator.reporters
    )) {
      if (evaluators.reporters[reporterName] && evaluators.reporters[reporterName] !== reporter) {
        console.warn(
          warning(
            `Reporter '${reporterName}' already exists. Will skip '${reporterName}' from ${result.sourceFile}.`
          )
        );
        continue;
      }
      evaluators.reporters[reporterName] = reporter;
    }
  }
}
async function runAndWatch({
  handles,
  onExit
}) {
  const count = Object.keys(handles).length;
  console.error(`Watching ${(0, import_pluralize4.default)("file", count, true)}...`);
  Object.values(handles).map((handle) => handle.watch());
  ["SIGINT", "SIGTERM"].forEach((signal) => {
    process.on(signal, function() {
      console.error("Stopped watching.");
      for (const handle of Object.values(handles)) {
        handle.destroy();
      }
      onExit?.();
      process.exit(0);
    });
  });
  await new Promise(() => {
  });
}
async function runOnce(handles, opts) {
  const buildPromises = Object.values(handles).map(
    (handle) => handle.rebuild()
  );
  const buildResults = await Promise.all(buildPromises);
  const bundlePromises = opts.bundle ? Object.fromEntries(
    Object.entries(handles).map(([inFile, handle]) => [
      inFile,
      handle.bundle()
    ])
  ) : null;
  const evaluators = {
    evaluators: [],
    reporters: {}
  };
  updateEvaluators(evaluators, buildResults, opts);
  if (opts.list) {
    for (const evaluator of evaluators.evaluators) {
      console.log(evaluator.evaluator.evalName);
    }
    return true;
  }
  const evalToExperiment = {};
  const resultPromises = evaluators.evaluators.map(async (evaluator) => {
    const { data, baseExperiment } = callEvaluatorData(
      evaluator.evaluator.data
    );
    const logger = opts.noSendLogs ? null : await initLogger(
      evaluator.evaluator.projectName,
      evaluator.evaluator.experimentName,
      evaluator.evaluator.metadata,
      baseExperiment
    );
    try {
      return await runEvaluator(
        logger,
        {
          ...evaluator.evaluator,
          data
        },
        opts.progressReporter,
        opts.filters
      );
    } finally {
      if (logger) {
        if (!evalToExperiment[evaluator.sourceFile]) {
          evalToExperiment[evaluator.sourceFile] = {};
        }
        evalToExperiment[evaluator.sourceFile][evaluator.evaluator.evalName] = logger;
        await logger.flush();
      }
    }
  });
  console.error(`Processing ${resultPromises.length} evaluators...`);
  const allEvalsResults = await Promise.all(resultPromises);
  opts.progressReporter.stop();
  console.error("");
  const evalReports = {};
  for (let idx = 0; idx < evaluators.evaluators.length; idx++) {
    const evaluator = evaluators.evaluators[idx];
    const resolvedReporter = resolveReporter(
      evaluator.reporter,
      evaluators.reporters
    );
    const report = resolvedReporter.reportEval(
      evaluator.evaluator,
      allEvalsResults[idx],
      {
        verbose: opts.verbose,
        jsonl: opts.jsonl
      }
    );
    addReport(evalReports, resolvedReporter, report);
  }
  if (bundlePromises !== null && Object.entries(evalToExperiment).length > 0) {
    await uploadHandleBundles({
      buildResults: buildResults.filter(
        // We handle errors above, so it's fine to filter down to successes here.
        (result) => result.type === "success"
      ),
      evalToExperiment,
      bundlePromises,
      handles,
      setCurrent: opts.setCurrent,
      defaultIfExists: "replace",
      verbose: opts.verbose
    });
  }
  let allSuccess = true;
  for (const [_reporterName, { reporter, results }] of Object.entries(
    evalReports
  )) {
    const success = await reporter.reportRun(await Promise.all(results));
    allSuccess = allSuccess && success;
  }
  return allSuccess;
}
function checkMatch(pathInput, include_patterns, exclude_patterns) {
  const p = import_path6.default.resolve(pathInput);
  if (include_patterns !== null) {
    let include = false;
    for (const pattern of include_patterns) {
      if ((0, import_minimatch.minimatch)(p, pattern)) {
        include = true;
        break;
      }
    }
    if (!include) {
      return false;
    }
  }
  if (exclude_patterns !== null) {
    let exclude = false;
    for (const pattern of exclude_patterns) {
      if ((0, import_minimatch.minimatch)(p, pattern)) {
        exclude = true;
        break;
      }
    }
    return !exclude;
  }
  return true;
}
async function collectFiles(inputPath, mode) {
  let pathStat = null;
  try {
    pathStat = import_fs2.default.lstatSync(inputPath);
  } catch (e) {
    console.error(error(`Error reading ${inputPath}: ${e}`));
    process.exit(1);
  }
  let files = [];
  if (!pathStat.isDirectory()) {
    if (!checkMatch(
      inputPath,
      mode === "eval" ? INCLUDE_EVAL : INCLUDE_BUNDLE,
      EXCLUDE
    )) {
      const prefix = mode === "eval" ? ".eval" : "";
      console.warn(
        warning(
          `Reading ${inputPath} because it was specified directly. Rename it to end in ${prefix}.ts or .${prefix}.js to include it automatically when you specify a directory.`
        )
      );
    }
    files.push(inputPath);
  } else {
    const walked = await import_util5.default.promisify(fsWalk.walk)(inputPath, {
      deepFilter: (entry) => {
        return checkMatch(entry.path, null, EXCLUDE);
      },
      entryFilter: (entry) => {
        return entry.dirent.isFile() && checkMatch(
          entry.path,
          mode === "eval" ? INCLUDE_EVAL : INCLUDE_BUNDLE,
          EXCLUDE
        );
      }
    });
    files = files.concat(walked.map((entry) => entry.path));
  }
  return files;
}
var markOurPackagesExternalPlugin = {
  name: "make-all-packages-external",
  setup(build2) {
    const filter2 = /^(braintrust|autoevals|@braintrust\/)/;
    build2.onResolve({ filter: filter2 }, (args) => ({
      path: args.path,
      external: true
    }));
  }
};
function buildOpts({
  fileName,
  outFile,
  tsconfig,
  plugins: argPlugins
}) {
  const plugins = [
    markOurPackagesExternalPlugin,
    ...(argPlugins || []).map((fn) => fn(fileName))
  ];
  return {
    entryPoints: [fileName],
    bundle: true,
    treeShaking: true,
    outfile: outFile,
    platform: "node",
    write: false,
    // Remove the leading "v" from process.version
    target: `node${process.version.slice(1)}`,
    tsconfig,
    external: ["node_modules/*", "fsevents"],
    plugins
  };
}
async function initializeHandles({
  files: inputFiles,
  mode,
  plugins,
  tsconfig
}) {
  const files = {};
  const inputPaths = inputFiles.length > 0 ? inputFiles : ["."];
  for (const inputPath of inputPaths) {
    const newFiles = await collectFiles(inputPath, mode);
    if (newFiles.length == 0) {
      console.warn(
        warning(
          `Provided path ${inputPath} is not an eval file or a directory containing eval files, skipping...`
        )
      );
    }
    for (const file of newFiles) {
      files[import_path6.default.resolve(file)] = true;
    }
  }
  if (Object.keys(files).length == 0) {
    console.warn(
      warning("No eval files were found in any of the provided paths.")
    );
    process.exit(0);
  }
  const tmpDir = import_path6.default.join(import_os.default.tmpdir(), `btevals-${(0, import_uuid2.v4)().slice(0, 8)}`);
  const initPromises = [];
  for (const file of Object.keys(files)) {
    const baseName = `${import_path6.default.basename(
      file,
      import_path6.default.extname(file)
    )}-${(0, import_uuid2.v4)().slice(0, 8)}`;
    const outFile = import_path6.default.join(tmpDir, `${baseName}.${OUT_EXT}`);
    const bundleFile = import_path6.default.join(tmpDir, `${baseName}.bundle.js`);
    initPromises.push(
      initFile({
        inFile: file,
        outFile,
        bundleFile,
        plugins,
        tsconfig
      })
    );
  }
  const handles = {};
  const initResults = await Promise.all(initPromises);
  for (const result of initResults) {
    handles[result.inFile] = result;
  }
  return handles;
}
async function run(args) {
  (0, import_env2.loadEnvConfig)(process.cwd(), true);
  if (args.env_file) {
    const loaded = dotenv2.config({ path: args.env_file });
    if (loaded.error) {
      console.error(error(`Error loading ${args.env_file}: ${loaded.error}`));
      process.exit(1);
    }
  }
  const evaluatorOpts = {
    verbose: args.verbose,
    apiKey: args.api_key,
    orgName: args.org_name,
    appUrl: args.app_url,
    noSendLogs: !!args.no_send_logs,
    bundle: !!args.bundle || !!args.push,
    setCurrent: !!args.push,
    terminateOnFailure: !!args.terminate_on_failure,
    watch: !!args.watch,
    jsonl: args.jsonl,
    progressReporter: args.no_progress_bars ? new SimpleProgressReporter() : new BarProgressReporter(),
    filters: args.filter ? parseFilters(args.filter) : [],
    list: !!args.list
  };
  if (args.list && args.watch) {
    console.error(error("Cannot specify both --list and --watch."));
    process.exit(1);
  }
  const plugins = evaluatorOpts.watch ? [
    (fileName) => buildWatchPluginForEvaluator(fileName, evaluatorOpts)
  ] : [];
  const handles = await initializeHandles({
    files: args.files,
    mode: "eval",
    tsconfig: args.tsconfig,
    plugins
  });
  let success = true;
  try {
    if (!evaluatorOpts.noSendLogs) {
      await login({
        apiKey: args.api_key,
        orgName: args.org_name,
        appUrl: args.app_url
      });
    }
    if (args.watch) {
      await runAndWatch({
        handles,
        onExit: () => {
          evaluatorOpts.progressReporter.stop();
        }
      });
    } else {
      success = await runOnce(handles, evaluatorOpts);
    }
  } finally {
    for (const handle of Object.values(handles)) {
      await handle.destroy();
    }
  }
  if (!success) {
    process.exit(1);
  }
}
function addAuthArgs(parser) {
  parser.add_argument("--api-key", {
    help: "Specify a braintrust api key. If the parameter is not specified, the BRAINTRUST_API_KEY environment variable will be used."
  });
  parser.add_argument("--org-name", {
    help: "The name of a specific organization to connect to. This is useful if you belong to multiple."
  });
  parser.add_argument("--app-url", {
    help: "Specify a custom braintrust app url. Defaults to https://www.braintrust.dev. This is only necessary if you are using an experimental version of Braintrust"
  });
  parser.add_argument("--env-file", {
    help: "A path to a .env file containing environment variables to load (via dotenv)."
  });
}
function addCompileArgs(parser) {
  parser.add_argument("--terminate-on-failure", {
    action: "store_true",
    help: "If provided, terminates on a failing eval, instead of the default (moving onto the next one)."
  });
  parser.add_argument("--tsconfig", {
    help: "Specify a custom tsconfig.json file to use."
  });
}
async function main() {
  const parser = new import_argparse.ArgumentParser({
    description: "Braintrust CLI"
  });
  parser.add_argument("-v", "--version", { action: "version", version });
  const parentParser = new import_argparse.ArgumentParser({ add_help: false });
  parentParser.add_argument("--verbose", {
    action: "store_true",
    help: "Include additional details, including full stack traces on errors."
  });
  const subparser = parser.add_subparsers({
    required: true
  });
  const parser_run = subparser.add_parser("eval", {
    help: "Run evals locally.",
    parents: [parentParser]
  });
  addAuthArgs(parser_run);
  parser_run.add_argument("--filter", {
    help: "Only run evaluators that match these filters. Each filter is a regular expression (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp). For example, --filter metadata.priority='^P0$' input.name='foo.*bar' will only run evaluators that have metadata.priority equal to 'P0' and input.name matching the regular expression 'foo.*bar'.",
    nargs: "*"
  });
  parser_run.add_argument("--list", {
    help: "List, but do not execute, evaluators.",
    action: "store_true"
  });
  parser_run.add_argument("--jsonl", {
    action: "store_true",
    help: "Format score summaries as jsonl, i.e. one JSON-formatted line per summary."
  });
  addCompileArgs(parser_run);
  parser_run.add_argument("--watch", {
    action: "store_true",
    help: "Watch files for changes and rerun evals when changes are detected"
  });
  parser_run.add_argument("--no-send-logs", {
    action: "store_true",
    help: "Do not send logs to Braintrust. Useful for testing evaluators without uploading results."
  });
  parser_run.add_argument("--no-progress-bars", {
    action: "store_true",
    help: "Do not show progress bars when processing evaluators."
  });
  parser_run.add_argument("--bundle", {
    action: "store_true",
    help: "Experimental (do not use unless you know what you're doing)"
  });
  parser_run.add_argument("--push", {
    action: "store_true",
    help: "Push the scorers from the current run to Braintrust. This will mark the current run's scorers as the latest version in the project."
  });
  parser_run.add_argument("files", {
    nargs: "*",
    help: "A list of files or directories to run. If no files are specified, the current directory is used."
  });
  parser_run.set_defaults({ func: run });
  const parser_push = subparser.add_parser("push", {
    help: "Bundle prompts, tools, scorers, and other resources into Braintrust"
  });
  addAuthArgs(parser_push);
  addCompileArgs(parser_push);
  parser_push.add_argument("files", {
    nargs: "*",
    help: "A list of files or directories containing functions to bundle. If no files are specified, the current directory is used."
  });
  parser_push.add_argument("--if-exists", {
    choices: ["error", "replace", "ignore"],
    default: "error",
    help: "What to do if a function with the same slug already exists. 'error' will cause an error and abort. 'replace' will overwrite the existing function. 'ignore' will ignore the push for this function and continue."
  });
  parser_push.set_defaults({ func: bundleCommand });
  const parser_pull = subparser.add_parser("pull", {
    help: "Pull prompts, tools, scorers, and other resources from Braintrust to save in your codebase."
  });
  parser_pull.add_argument("--output-dir", {
    help: "The directory to output the pulled resources to. If not specified, the current directory is used."
  });
  parser_pull.add_argument("--project-name", {
    help: "The name of the project to pull from. If not specified, all projects are pulled."
  });
  parser_pull.add_argument("--project-id", {
    help: "The id of the project to pull from. If not specified, all projects are pulled."
  });
  parser_pull.add_argument("--id", {
    help: "The id of a specific function to pull."
  });
  parser_pull.add_argument("--slug", {
    help: "The slug of a specific function to pull."
  });
  parser_pull.add_argument("--version", {
    help: "The version to pull. Will pull the latest version of each prompt that is at or before this version."
  });
  parser_pull.add_argument("--force", {
    action: "store_true",
    help: "Overwrite local files if they have uncommitted changes."
  });
  parser_pull.set_defaults({ func: pullCommand });
  const parsed = parser.parse_args();
  try {
    await parsed.func(parsed);
  } catch (e) {
    logError2(e, parsed.verbose);
    process.exit(1);
  }
}
main();
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  handleBuildFailure,
  initializeHandles
});
/*! Bundled license information:

queue-microtask/index.js:
  (*! queue-microtask. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> *)

run-parallel/index.js:
  (*! run-parallel. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> *)
*/
